#--------------------------------------------------------------------------------------------------##------------------------PREPARE SOILWAT SIMULATIONSif(!be.quiet) print(paste("SWSF is executed for:", sQuote(basename(dir.prj)), "and started at", Sys.time())).Last <- function() { #Properly end mpi slaves before quitting R (e.g., at a crash)	if (is.loaded("mpi_initialize") && exists("mpi.comm.size")){		if (mpi.comm.size(1) > 0) mpi.close.Rslaves()		.Call("mpi_finalize")	}}#------actionWithSoilWat <- any(actions == "create") || any(actions == "execute") || any(actions == "aggregate")actionWithSWSFOutput <- any(actions == "concatenate") || any(actions == "ensemble")#--order output_aggregate_daily--#if(length(output_aggregate_daily) > 0) output_aggregate_daily <- output_aggregate_daily[order(output_aggregate_daily)]#------ow <- options("warn", "error")if(print.debug){	if(interactive()){		options(warn=1, error=quote({dump.frames(to.file=TRUE)}))	} else {		options(warn=2, error=quote({dump.frames(to.file=TRUE); q("no")}))	#turns all warnings into errors, dumps all to a file, and quits	}} else {	options(warn=0, error=traceback)	#catches all warnings and on error returns a traceback()}#custom list.dirs function because the ones in 2.13 and 2.15 are different... this function will behave like the one in 2.15 no matter which version you are using...#note: should work on any system where the directory seperator is .Platform$file.sep (ie Unix)list.dirs2 <- function(path, full.names=TRUE, recursive=TRUE) {	dir.list <- list.dirs(path, full.names)	if(is.null(dir.list))		return (dir.list)	if(length(dir.list) == 0)		return (dir.list)	if(recursive == TRUE)		return (dir.list)	nSlash = length(strsplit(dir.list[1], .Platform$file.sep)[[1]]) + 1	if(nSlash == 1)		return(dir.list[-1])	n = length(dir.list)	for(i in n:1)		if(length(strsplit(dir.list[i], .Platform$file.sep)[[1]]) != nSlash)			dir.list <- dir.list[-i]	return (dir.list)}#custom file.copy2 function, b/c it was giving errors on JANUS when run with MPIfile.copy2 <- function(from="", to="", overwrite=TRUE, copy.mode=TRUE, times=0) {	file.copy(from, to, overwrite, FALSE, copy.mode)	if(times < 24)		if(file.exists(from))			if(!file.exists(to)) {				print("trying to copy the file again")				file.copy2(from, to, overwrite, copy.mode, (times+1))	#recursively call the function again because when run with MPI the file copying doesn't seem to work everytime...			}	#else { #this commented out part copies the file via the system command cp	#	if(any(grepl("/", to, fixed=TRUE))) { #this part makes the to directory if it doesn't exist... so pretty much this can copy files to places that don't exist, which generally isn't what you want to do but in this case it might help solve an error I keep getting.	#		y <- to	#		while(substr(y, nchar(y), nchar(y)) != '/')	#			y <- substr(y, 1, nchar(y)-1)	#		y <- substr(y, 1, nchar(y)-1)	#		if(y != "")	#			system(paste("mkdir -p", y), ignore.stdout=FALSE, ignore.stderr=FALSE)	#	}	#	command <- "cp" #this just calls the system command cp...	#	if(overwrite == TRUE) command <- paste(command, "-f")	#	if(copy.mode == TRUE) command <- paste(command, "-p")	#	system(paste(command, from, to), ignore.stdout=FALSE, ignore.stderr=FALSE)	#}}#copy directory and content as in system(paste("cp -R", shQuote(from), shQuote(to)))dir.copy <- function(dir.from, dir.to, overwrite=FALSE){	dir.create2(dir.to, recursive=TRUE)	dir.list <- basename(list.dirs2(dir.from, full.names=FALSE, recursive=FALSE))	file.list <- list.files(dir.from)	if(length(dir.list) > 0) {		sapply(dir.list, function(x) {dir.copy(dir.from=file.path(dir.from, x), dir.to=file.path(dir.to, x), overwrite=overwrite)})		#file.list <- file.list[-match(dir.list, table=file.list)] #this line gives an error when run in R v. 2.13		file.list <- file.list[file.list != dir.list] #this line does the same as the other line, but does not throw the error	}	if(length(file.list) > 0) {		sapply(file.list, function(x) {file.copy2(from=file.path(dir.from, x), to=file.path(dir.to, x), overwrite=overwrite, copy.mode=TRUE)})	}	invisible(1)}#remove directory and contentdir.remove <- function(dir){	file.list <- try(list.files(dir, all.files=TRUE))	file.list <- file.list[-which(file.list %in% c(".", ".."))]	dir.list <- basename(list.dirs2(dir, full.names=FALSE, recursive=FALSE))	if(length(dir.list) > 0) {		sapply(dir.list, function(x) {dir.remove(dir=file.path(dir, x))})		file.list <- file.list[-match(dir.list, table=file.list)]	}	if(length(file.list) > 0) {		sapply(file.list, function(x) {file.remove(file.path(dir, x))})	}	return(file.remove(dir))}#made this function b/c dir.create wasn't always working correctly on JANUS for some reason... so if the simulations are being run on JANUS then it uses the system mkdir call to make the directories.dir.create2 <- function(path, showWarnings = TRUE, recursive = FALSE, mode = "0777", times = 0) {	dir.create(path, showWarnings, recursive, mode)	if(times < 24)		if(!file.exists(path)) {			print("trying to make directory again")			dir.create2(path, showWarnings, TRUE, mode, (times+1)) #recursively call the function b/c when run on JANUS with MPI it doesn't seem to make the directories everytime... quite aggravating.		}	#else if(recursive == TRUE) #this commented out part makes the directory via the system call mkdir	#	system(paste("mkdir -p", path), ignore.stdout=TRUE, ignore.stderr=FALSE)	#else	#	system(paste("mkdir", path), ignore.stdout=TRUE, ignore.stderr=FALSE)}#create simulation directory structuredir.sw.in <- normalizePath(dir.sw.in)if(makeInputForExperimentalDesign) dir.out.experimentalInput <- file.path(dir.out, "Experimentals_Input_Data")dir.out.temp <- file.path(dir.out, "temp")dir.create2(dir.out, showWarnings=FALSE, recursive=TRUE)dir.create2(dir.big, showWarnings=FALSE, recursive=TRUE)if(saveRsoilwatInput || saveRsoilwatOutput) dir.create2(dir.sw.runs, showWarnings=FALSE, recursive=TRUE)dir.create2(dir.out.temp, showWarnings=FALSE, recursive=TRUE)if(makeInputForExperimentalDesign) dir.create2(dir.out.experimentalInput, showWarnings=FALSE, recursive=TRUE)#timing: basis for estimated time of arrival, ETAtimerfile <- "temp_timer.csv"temp <- file.path(dir.out, timerfile)if (file.exists(temp) && !continueAfterAbort) {	try(file.remove(temp), silent=TRUE)}if (!file.exists(temp)) {	write.table(t(c(0,NA)), file=temp, append=TRUE, sep=",", dec=".", col.names=FALSE, row.names=FALSE)	runIDs_done <- NULL} else {	ttemp <- read.csv(file = temp, header = FALSE)	runIDs_done <- if (nrow(ttemp) > 1) sort(ttemp[-1, 1]) else NULL	rm(ttemp)}#timing: output for overall timing informationtimerfile2 <- "Timing_Simulation.csv"if(file.exists(temp <- file.path(dir.out, timerfile2))) try(file.remove(temp), silent=TRUE)write.table(t(c("", "Time_s", "Number")), file=temp, append=TRUE, sep=",", dec=".", col.names=FALSE, row.names=FALSE)#concatenate file keeps track of sql files inserted into dataconcatFile <- "sqlFilesInserted.csv"concatFileProblemLines <- "sqlFilesProblemLines.csv"#------load librariesdir.libraries <- .libPaths()[1]if (.Platform$OS.type == "windows") {	#test if user has write permission to standard library path	err <- try(write.table(1, file=ftemp <- file.path(dir.libraries, "testPermission.txt")))	if(inherits(err, "try-error")){		print(paste("User has no write permission for:", dir.libraries, ". A local path is attempted instead, but this is known to likely fail for the setup of 'snow' under Windows XP"))		dir.create2(path=dir.libraries <- file.path(dir.in, "RLibrary"),showWarnings=FALSE,recursive=FALSE)		if(!any(.libPaths() == dir.libraries)) .libPaths(dir.libraries)	} else {		file.remove(ftemp)	}}if(!require(Rsoilwat31,quietly = TRUE) || (require(Rsoilwat31,quietly = TRUE) && packageVersion("Rsoilwat31") < minVersionRsoilwat)) {	print("Going to try to install Rsoilwat library")	installed <- FALSE	if(.Platform$OS.type == "unix" && Sys.info()[1] == "Darwin" && sessionInfo()$R.version$major == 3){		#try to install mac binary for R version 3		installed<-tryCatch(install.packages(file.path(dir.in, "Rsoilwat", "Rsoilwat_osx_r3.zip"),repos=NULL, type="mac.binary",lib=dir.libraries), warning=function(w) { print(w); print("FAILED"); return(FALSE) })		installed<-is.null(installed)	} else if (.Platform$OS.type == "windows" && sessionInfo()$R.version$major == 3){		#try to install windows binary for R version 3		installed<-tryCatch(install.packages(file.path(dir.in, "Rsoilwat", "Rsoilwat_windows_r3.zip"),repos=NULL, type="win.binary",lib=dir.libraries), warning=function(w) { print(w); print("FAILED"); return(FALSE) })		installed<-is.null(installed)	}	if(!installed){#attempt to compile package from source because so far neither mac or windows binary attempted to install or successfully installed		installed <- tryCatch(install.packages(file.path(dir.in, "Rsoilwat", "SoilWat_v27_R.tar.gz"),repos=NULL, type="source",lib=dir.libraries), warning=function(w) { print(w); print("FAILED"); return(FALSE) })		installed <- is.null(installed)	}	if(!installed) stop("Could not install package Rsoilwat please contact admin.")	stopifnot(require(Rsoilwat31,quietly = TRUE) && packageVersion("Rsoilwat31") >= minVersionRsoilwat)}if(!require(circular, quietly=TRUE)) {	tryCatch(install.packages("circular",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("circular failed to install"); stop("Stopping") })	stopifnot(require(circular, quietly=TRUE))}if(!require(SPEI, quietly=TRUE)) {	tryCatch(install.packages("SPEI",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("circular failed to install"); stop("Stopping") })	stopifnot(require(SPEI, quietly=TRUE))}if(!require(RSQLite,quietly = TRUE)) {	tryCatch(install.packages("RSQLite",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("RSQLite failed to install"); stop("Stopping") })	stopifnot(require(RSQLite, quietly = TRUE))}if(parallel_runs && identical(parallel_backend, "mpi")) {	if(!require(Rmpi,quietly = TRUE)) {		tryCatch(install.packages("Rmpi",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("Rmpi failed to install"); stop("Stopping") })		stopifnot(require(Rmpi, quietly = TRUE))	}}if(parallel_runs && identical(parallel_backend, "snow")) {	if(!require(doSNOW,quietly = TRUE)) {#requires: foreach, iterators, snow		tryCatch(install.packages("doSNOW",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("doSNOW failed to install"); stop("Stopping") })		stopifnot(require(doSNOW, quietly = TRUE))	}}if(parallel_runs && identical(parallel_backend, "multicore")) {	if(!require(doMC,quietly = TRUE)) {	#requires: foreach, iterators, codetools, and attaches: multicore		tryCatch(install.packages("doMC",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("doMC failed to install"); stop("Stopping") })		stopifnot(require(doMC, quietly = TRUE))	}}if(!parallel_runs) {	if(!require(foreach,quietly = TRUE)) {		tryCatch(install.packages("foreach",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("foreach failed to install"); stop("Stopping") })		stopifnot(require(foreach, quietly = TRUE))	}}#if(print.debug) trace(what=circular:::SdCircularRad, tracer=quote({print(x); print(sys.calls()[[6]]); print(paste(rbar, circsd))}), at=4)#------prepare outputaon.help <- matrix(data=output_aggregates, ncol=2, nrow=length(output_aggregates)/2, byrow=TRUE)aon <- data.frame(t(as.numeric(aon.help[,-1])))names(aon) <- aon.help[,1]#------constantsoutput_timescales_maxNo <- 4SoilLayer_MaxNo <- 20lmax <- 1:SoilLayer_MaxNodirname.sw.runs.weather <- "WeatherData"SoilWat.windspeedAtHeightAboveGround <- 2	#mst_mo <- 1:12isLeapYear <- function(y) y %% 4 == 0 & (y %% 100 != 0 | y %% 400 == 0)	#from package: tis#------import dataif(!be.quiet) print(paste("SWSF reads input data: started at", t1 <- Sys.time()))if (usePreProcessedInput && file.exists(file.path(dir.in, datafile.SWRWinputs_preprocessed))) {	load(file = file.path(dir.in, datafile.SWRWinputs_preprocessed),		envir = .GlobalEnv) # This however annihilates all objects in .GlobalEnv with the same names !} else {	# Read data from files	SWRunInformation <- tryCatch(read.csv(file.path(dir.in, datafile.SWRunInformation), as.is=TRUE),error=function(e) { print("datafile.SWRunInformation: Bad Path"); print(e)})	stopifnot(sapply(c("Label", "site_id", "WeatherFolder", "X_WGS84", "Y_WGS84", "ELEV_m", "Include_YN"),		function(x) x %in% colnames(SWRunInformation)),		# required columns		all(SWRunInformation$site_id == seq_len(nrow(SWRunInformation))),	# consecutive site_id		!grepl("[[:space:]]", SWRunInformation$Label),	# no space-characters in label		!grepl("[[:space:]]", SWRunInformation$WeatherFolder)	# no space-characters in weather-data names	)	include_YN <- SWRunInformation$Include_YN	labels <- SWRunInformation$Label	sw_input_soillayers <- tryCatch(read.csv(file.path(dir.in, datafile.soillayers)),error=function(e) { print("datafile.soillayers: Bad Path"); print(e)})	sw_input_treatments_use <- tryCatch(read.csv(temp <- file.path(dir.in, datafile.treatments), nrows=1),error=function(e) { print("datafile.treatments: Bad Path"); print(e)})	sw_input_treatments <- read.csv(temp, skip=1, as.is=TRUE)	colnames(sw_input_treatments) <- colnames(sw_input_treatments_use)	stopifnot(		!grepl("[[:space:]]", sw_input_treatments$LookupWeatherFolder)	# no space-characters in weather-data names	)	sw_input_experimentals_use <- tryCatch(read.csv(temp <- file.path(dir.in, datafile.Experimentals), nrows=1),error=function(e) { print("datafile.Experimentals: Bad Path"); print(e)})	sw_input_experimentals <- read.csv(temp, skip=1, as.is=TRUE)	colnames(sw_input_experimentals) <- colnames(sw_input_experimentals_use)	create_experimentals <- names(sw_input_experimentals_use[-1][which(sw_input_experimentals_use[-1] > 0 & is.finite(as.numeric(sw_input_experimentals_use[-1])))])	stopifnot(		!grepl("[[:space:]]", sw_input_experimentals$LookupWeatherFolder)	# no space-characters in weather-data names	)	#update treatment specifications based on experimental design	sw_input_treatments_use_combined <- ifelse(sw_input_treatments_use[-1] == 1 | names(sw_input_treatments_use[-1]) %in% create_experimentals, 1, 0)	temp<-which(!(create_experimentals %in% names(sw_input_treatments_use[-1])))	if(length(temp) != 0) sw_input_treatments_use_combined <- cbind(sw_input_treatments_use_combined, matrix(data=1,nrow=1,ncol=length(temp),dimnames=list(NA, c(create_experimentals[temp]))))	create_treatments <- names(sw_input_treatments_use_combined[,which(sw_input_treatments_use_combined > 0 & is.finite(as.numeric(sw_input_treatments_use_combined)))])	if(dim(SWRunInformation)[2] == 1) stop("SWRunInformation might be tab separated instead of comma.")	if(dim(sw_input_soillayers)[2] == 1) stop("SoilLayers might be tab separated instead of comma.")	if(dim(sw_input_treatments_use)[2] == 1) stop("Treatments might be tab separated instead of comma.")	if(dim(sw_input_experimentals_use)[2] == 1) stop("Experimentals might be tab separated instead of comma.")	sw_input_cloud_use <- sw_input_cloud <- list()	sw_input_prod_use <- sw_input_prod <- list()	sw_input_site_use <- sw_input_site <- list()	sw_input_soils_use <- sw_input_soils <- list()	sw_input_weather_use <- sw_input_weather <- list()	sw_input_climscen_use <- sw_input_climscen <- list()	sw_input_climscen_values_use <- sw_input_climscen_values <- list()	tr_files <- tr_prod <- tr_site <- tr_soil <- tr_weather <- tr_cloud <- list()	tr_input_climPPT <- tr_input_climTemp <- tr_input_shiftedPPT <- tr_input_EvapCoeff <- tr_input_TranspCoeff_Code <- tr_input_TranspCoeff <- tr_input_TranspRegions <- tr_input_SnowD <- tr_VegetationComposition <- list()	sw_input_cloud_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.cloud), nrows=1),error=function(e) { print("datafile.cloud: Bad Path"); print(e)})	sw_input_cloud <- read.csv(temp, skip=1)	colnames(sw_input_cloud) <- colnames(sw_input_cloud_use)	sw_input_prod_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.prod), nrows=1),error=function(e) { print("datafile.prod: Bad Path"); print(e)})	sw_input_prod <- read.csv(temp, skip=1)	colnames(sw_input_prod) <- colnames(sw_input_prod_use)	sw_input_prod_use[-1] <- ifelse(sw_input_prod_use[-1] == 1 | names(sw_input_prod_use[-1]) %in% create_experimentals, 1, 0)	#update specifications based on experimental design	sw_input_site_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.siteparam), nrows=1),error=function(e) { print("datafile.siteparam: Bad Path"); print(e)})	sw_input_site <- read.csv(temp, skip=1)	colnames(sw_input_site) <- colnames(sw_input_site_use)	sw_input_site_use[-1] <- ifelse(sw_input_site_use[-1] == 1 | names(sw_input_site_use[-1]) %in% create_experimentals, 1, 0)	#update specifications based on experimental design	sw_input_soils_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.soils), nrows=1),error=function(e) { print("datafile.soils: Bad Path"); print(e)})	sw_input_soils <- read.csv(temp, skip=1)	colnames(sw_input_soils) <- colnames(sw_input_soils_use)	sw_input_soils_use[-1] <- ifelse(sw_input_soils_use[-1] == 1 | names(sw_input_soils_use[-1]) %in% create_experimentals, 1, 0)	#update specifications based on experimental design	sw_input_weather_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.weathersetup), nrows=1),error=function(e) { print("datafile.weathersetup: Bad Path"); print(e)})	sw_input_weather <- read.csv(temp, skip=1)	colnames(sw_input_weather) <- colnames(sw_input_weather_use)	sw_input_climscen_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.climatescenarios), nrows=1),error=function(e) { print("datafile.climatescenarios: Bad Path"); print(e)})	sw_input_climscen <- read.csv(temp, skip=1)	colnames(sw_input_climscen) <- colnames(sw_input_climscen_use)	sw_input_climscen_values_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.climatescenarios_values), nrows=1),error=function(e) { print("datafile.climatescenarios_values: Bad Path"); print(e)})	sw_input_climscen_values <- read.csv(temp, skip=1)	colnames(sw_input_climscen_values) <- colnames(sw_input_climscen_values_use)	if(dim(sw_input_cloud_use)[2] == 1) stop("Cloud datafile might be tab separated instead of comma.")	if(dim(sw_input_prod_use)[2] == 1) stop("Prod datafile might be tab separated instead of comma.")	if(dim(sw_input_site_use)[2] == 1) stop("Site datafile might be tab separated instead of comma.")	if(dim(sw_input_soils_use)[2] == 1) stop("Soils datafile might be tab separated instead of comma.")	if(dim(sw_input_weather_use)[2] == 1) stop("Weather datafile might be tab separated instead of comma.")	if(dim(sw_input_climscen_use)[2] == 1) stop("Climate Use datafile datafile might be tab separated instead of comma.")	if(dim(sw_input_climscen_values_use)[2] == 1) stop("Climate Values datafile datafile might be tab separated instead of comma.")	#Create a list of possible treatment files with data.	if(any(create_treatments=="sw"))		print("SW treatment is not used because library Rsoilwat only uses one version of soilwat. Sorry")	if(any(create_treatments=="filesin")) {		temp<-list.files(path=file.path(dir.sw.in.tr, "filesin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)		tr_files[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swFiles")),x))))	}	if(any(create_treatments=="prodin")) {		temp<-list.files(path=file.path(dir.sw.in.tr, "prodin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)		tr_prod[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swProd")),x))))	}	if(any(create_treatments=="siteparamin")) {		temp<-list.files(path=file.path(dir.sw.in.tr, "siteparamin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)		tr_site[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swSite")),x))))	}	if(any(create_treatments=="soilsin")) {		temp<-list.files(path=file.path(dir.sw.in.tr, "soilsin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)		tr_soil[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swSoils")),x))))	}	if(any(create_treatments=="weathersetupin")) {		temp<-list.files(path=file.path(dir.sw.in.tr, "weatherin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)		tr_weather[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swWeather")),x))))	}	if(any(create_treatments=="cloudin")) {		temp<-list.files(path=file.path(dir.sw.in.tr, "cloudin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)		tr_cloud[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swCloud")),x))))	}	if(any(create_treatments == "LookupClimatePPTScenarios")) tr_input_climPPT <- read.csv( file.path(dir.sw.in.tr, "LookupClimatePPTScenarios", trfile.LookupClimatePPTScenarios))	if(any(create_treatments == "LookupClimateTempScenarios")) tr_input_climTemp <- read.csv( file.path(dir.sw.in.tr, "LookupClimateTempScenarios", trfile.LookupClimateTempScenarios))	if(any(create_treatments == "LookupShiftedPPTScenarios")) tr_input_shiftedPPT <- read.csv( file.path(dir.sw.in.tr, "LookupShiftedPPTScenarios", trfile.LookupShiftedPPTScenarios), row.names=1)	if(any(create_treatments == "LookupEvapCoeffFromTable")) tr_input_EvapCoeff <- read.csv( file.path(dir.sw.in.tr, "LookupEvapCoeffFromTable", trfile.LookupEvapCoeffFromTable), row.names=1)	if(any(create_treatments == "LookupTranspCoeffFromTable_Grass", create_treatments == "LookupTranspCoeffFromTable_Shrub", create_treatments == "LookupTranspCoeffFromTable_Tree", create_treatments == "LookupTranspCoeffFromTable_Forb", create_treatments == "AdjRootProfile")){		tr_input_TranspCoeff_Code <- tryCatch(read.csv(temp <- file.path(dir.sw.in.tr, "LookupTranspCoeffFromTable", trfile.LookupTranspCoeffFromTable), nrows=2), error=function(e) { print("LookupTranspCoeffFromTable.csv: Bad Path"); print(e)})		tr_input_TranspCoeff_Code <- tr_input_TranspCoeff_Code[-2,]		tr_input_TranspCoeff <- read.csv(temp, skip=2)		colnames(tr_input_TranspCoeff) <- colnames(tr_input_TranspCoeff_Code)	}	if(any(create_treatments == "LookupTranspRegionsFromTable")) tr_input_TranspRegions <- read.csv( file.path(dir.sw.in.tr, "LookupTranspRegionsFromTable", trfile.LookupTranspRegionsFromTable), row.names=1)	if(any(create_treatments == "LookupSnowDensityFromTable")) tr_input_SnowD <- read.csv( file.path(dir.sw.in.tr, "LookupSnowDensityFromTable", trfile.LookupSnowDensityFromTable), row.names=1)	if(any(create_treatments == "AdjMonthlyBioMass_Temperature")) tr_VegetationComposition <- read.csv(file.path(dir.sw.in.tr, "LookupVegetationComposition", trfile.LookupVegetationComposition), skip=1, row.names=1)	#-import regeneration data	param.species_regeneration <- list()	if(any(simulation_timescales=="daily") & aon$dailyRegeneration_GISSM) {		list.species_regeneration <- list.files(dir.sw.in.reg, pattern=".csv")		no.species_regeneration <- length(list.species_regeneration)		if(no.species_regeneration > 0){			f.temp <- read.csv(file.path(dir.sw.in.reg, list.species_regeneration[1]))			param.species_regeneration <- matrix(NA, ncol=no.species_regeneration, nrow=nrow(f.temp))			colnames(param.species_regeneration) <- sub(".csv", "", list.species_regeneration)			rownames(param.species_regeneration) <- f.temp[, 1]			param.species_regeneration[, 1] <- f.temp[, 2]			if(no.species_regeneration > 1) for(f in 2:no.species_regeneration){					f.temp <- read.csv(file.path(dir.sw.in.reg, list.species_regeneration[f]))					param.species_regeneration[, f] <- f.temp[, 2]				}			rm(f.temp)		}	} else {		no.species_regeneration <- 0	}	save(SWRunInformation, include_YN, labels, sw_input_soillayers, sw_input_treatments_use, sw_input_treatments, sw_input_experimentals_use, sw_input_experimentals, create_experimentals, sw_input_treatments_use_combined, create_treatments, sw_input_cloud_use, sw_input_cloud, sw_input_prod_use, sw_input_prod, sw_input_site_use, sw_input_site, sw_input_soils_use, sw_input_soils, sw_input_weather_use, sw_input_weather, sw_input_climscen_use, sw_input_climscen, sw_input_climscen_values_use, sw_input_climscen_values, tr_files, tr_prod, tr_site, tr_soil, tr_weather, tr_cloud, tr_input_climPPT, tr_input_climTemp, tr_input_shiftedPPT, tr_input_EvapCoeff, tr_input_TranspCoeff_Code, tr_input_TranspCoeff, tr_input_TranspRegions, tr_input_SnowD, tr_VegetationComposition, param.species_regeneration, no.species_regeneration, 		file = file.path(dir.in, datafile.SWRWinputs_preprocessed),		compress = FALSE) # No compression for fast access; RDS may be slightly faster, but would require loop over assign(, envir = .GlobalEnv)}if(!be.quiet) print(paste("SWSF reads input data: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))#------create scenario namestemp <- climate.conditions[!grepl(climate.ambient, climate.conditions)] #make sure 'climate.ambient' is first entryif(length(temp) > 0){	temp <- paste0(rownames(future_yrs), ".", rep(temp, each = nrow(future_yrs)))	#add (multiple) future_yrs	temp <- paste0(downscaling.method, ".", rep(temp, each=length(downscaling.method))) #add (multiple) downscaling.method}climate.conditions <- c(climate.ambient, temp)scenario_No <- length(climate.conditions)scenario <- climate.conditions#------create ensemblesif(length(ensemble.levels) > 0) ensemble.levels <- sort(ensemble.levels)do.ensembles <- any(actions=="ensemble") && !is.null(ensemble.families) && length(ensemble.levels) > 0 && is.numeric(ensemble.levels) && scenario_No > 1if(do.ensembles){	ensemble.families <- paste0(rownames(future_yrs), ".", rep(ensemble.families, each = nrow(future_yrs)))	#add (multiple) future_yrs	scenarios.ineach.ensemble <- sapply(ensemble.families, function(x) grepl(pattern=x, climate.conditions, ignore.case=TRUE), simplify=TRUE)	ensemble.families <- ensemble.families[temp <- apply(scenarios.ineach.ensemble, MARGIN=2, FUN=any)]	scenarios.ineach.ensemble <- scenarios.ineach.ensemble[, temp]	families_N <- length(ensemble.families)	if(families_N > 1){		scenariosPERensemble_N <- max(temp <- apply(scenarios.ineach.ensemble, MARGIN=2, FUN=sum))		stopifnot(any(ensemble.levels <= min(temp)))	} else{		scenariosPERensemble_N <- sum(scenarios.ineach.ensemble)		stopifnot(any(ensemble.levels <= scenariosPERensemble_N))	}}#------Determine simulation runs#	- Simulations are run over three nested loops#		- loop1 (1...expN) nested in loop2b (1...runsN_sites) nested in loop3 (1...scenario_No)#			- Note: loop3 (along scenarios) occurs within the function 'do_OneSite'#			- Note: loop2b is a subset of loop2a (1...runsN_master)#		- column 'include_YN' reduces 'site_id' to 'runIDs_sites'#		- 'site_id' and 'P_id' are invariant to 'include_YN'##	- Master input file: column 'include_YN' selects rows which are included in the simulation#		Note: rows of the master input file correspond to rows of the treatment input file#		- column 'site_id'		== consecutive identification numbers of all rows in the master file; this is treated as a unique (and stable) identifier of a site#		- runsN_master			== number of rows in the master file #		- runsN_sites			== number of rows in the master file that are included (runsN_sites <= max(site_id))  [previously, 'runs']#		- runIDs_sites			== identification of rows in the master file that are included  [previously, 'seq.tr']##	- Experimental input file: each row defines a condition which is applied to every runIDs_sites#		- expN	== number of experimental treatments	[previously, 'trow']##	- The function 'do_OneSite' will be called n-times with n = runsN_total#		- runsN_total		== (number of included sites) x (number of experimental treatments)	[previously, 'runsN.total']#		- runIDs_total		== consecutive identification numbers along runsN_total [previously, 'seq.todo']#		- runIDs_done		== values of runIDs_total that have already been processed by 'do_OneSite' [previously, 'seq.done']#		- runIDs_todo		== values of runIDs_total that await simulation by 'do_OneSite' [previously, 'seq.todo']#		- runsN_todo		== number of runIDs_total that await simulation by 'do_OneSite' [previously, 'runsN.todo']##	- The function 'do_OneSite' could be called n-times with n = runsN_incl if all 'include_YN' were on#		- runsN_incl		== (number of sites) x (number of experimental treatments)##	- The variable 'climate.conditions' defines climate conditions that are applied to each 'runIDs_total'#		- scenario_No		== number of climate conditions##	- A grand total of n = runsN_Pid SoilWat runs could be carried out (n == number of rows in the output database)#		- runsN_Pid			== max(P_id) == runsN_incl x scenario_No#		- P_id				== a consecutive identification number for each possible SoilWat simulation; used as the ID for the output database ##	- Iterators:#		- i_sim					== A value out of the set of 'runIDs_todo' (as subset of 'runIDs_total') to be simulated#								== a consecutive index across loops 1+2b#		- i_site <- it_site()	== calculates the current value of 'runIDs_sites' based on 'i_sim'	[previously, 'i_tr']#								== position in loop 2 based on position across loops 1+2b#		- i_exp <- it_exp()		== position in loop 1 based on position across loops 1+2b#		- sc					== the iterator variable across 'scenario_No'#		- P_id <- it_Pid_old()	== a variable consecutive iterator across all loops 1+2b+3#		- P_id <- it_Pid()		== an invariant consecutive iterator across all loops 1+2a+3runsN_master <- nrow(SWRunInformation)runIDs_sites <- which(include_YN > 0)runsN_sites <- length(runIDs_sites)if (!(runsN_sites > 0))	stop(paste("at least 1 SoilWat-run needed for simulation, but", runsN_sites, "found"))# identify how many SoilWat-runs = rows are to be carried outexpN <- NROW(sw_input_experimentals)runsN_total <- runsN_sites * max(expN, 1L)runsN_incl <- runsN_master * max(expN, 1L)runsN_Pid <- runsN_incl * scenario_NorunIDs_total <- seq_len(runsN_total) # consecutive number of all (tr x exp) simulations to be executedcounter.digitsN <- 1 + ceiling(log10(runsN_master * max(expN, 1L)))	#max index digitsrunIDs_todo <- runIDs_total[!(runIDs_total %in% runIDs_done)] # remove already completed runs from todo listrunsN_todo <- length(runIDs_todo)# iterator functions#' @param isim An integer value. A value of \code{runIDs_todo} as subset of \code{runIDs_total}.#' @details NOTE: Do not change the iterators without adjusting the design of the output databases!it_Pid_old <- function(isim, sc) (isim - 1L) * scenario_No + scit_Pid <- function(isim, sc) ((it_exp(isim) - 1L) * runsN_master + it_site(isim) - 1L) * scenario_No + scit_exp <- function(isim) (isim - 1L) %/% runsN_sites + 1Lit_site <- function(isim) runIDs_sites[(isim - 1L) %% runsN_sites + 1L]## Tests#include_YN <- c(0, 0, 1, 0, 0, 1, 1, 0)#include_YN <- rep(1, 8)#t(sapply(runIDs_todo, function(isim) c(isim, it_site(isim), it_exp(isim), it_Pid(isim, 1), it_Pid_old(isim, 1))))#t(sapply(runIDs_total, function(isim) c(isim, it_site(isim), it_exp(isim), it_Pid(isim, 1), it_Pid_old(isim, 1))))#------outputing dataif(makeInputForExperimentalDesign) ExpInput_Seperator <- "X!X"#append treatment information to the aggregated output in addition to selected Index_RunInformationIndex_RunInformation_Treatments <- NULLif(length(create_treatments) > 0) {	Index_RunInformation_Treatments <- match(create_treatments, names(sw_input_treatments))}daily_no <- length(output_aggregate_daily)if(any(simulation_timescales=="daily")){	if(any(output_aggregate_daily == "SWAbulk") & length(SWPcrit_MPa) > 0){		output_aggregate_daily <- output_aggregate_daily[-which(output_aggregate_daily == "SWAbulk")]		for(icrit in seq(along=SWPcrit_MPa)){			output_aggregate_daily <- c(output_aggregate_daily, paste("SWAbulkatSWPcrit", abs(round(-1000*SWPcrit_MPa[icrit], 0)), "kPa", sep=""))		}		daily_no <- length(output_aggregate_daily)	}#	if(AggLayer.daily){#		aggLs_no <- 2 + ifelse(is.null(Depth_ThirdAggLayer.daily), 1, ifelse(!is.na(Depth_ThirdAggLayer.daily), 1, 0)) + ifelse(is.null(Depth_FourthAggLayer.daily), 1, ifelse(!is.na(Depth_FourthAggLayer.daily), 1, 0))#	} else {#at this stage we don't know how many soil layers we will have among the SoilWat runs; so just prepare for the maximum#		if(!any(create_treatments == "soilsin") & !is.null(sw_input_soillayers)){#			aggLs_no <- max(apply(sw_input_soillayers[, -1], MARGIN=1, FUN=function(x) ifelse(is.na(x[1]), NA, findInterval(x[1] - sqrt(.Machine$double.neg.eps), c(0, na.exclude(unlist(x[-1]))))) ), na.rm=TRUE)#		} else {#			aggLs_no <- SoilLayer_MaxNo#		}#	}}#------------------------FLAGS FOR EXTERNAL DATAtemp <- matrix(data=do.ExtractExternalDatasets, ncol=2, nrow=length(do.ExtractExternalDatasets)/2, byrow=TRUE)exinfo <- data.frame(t(as.numeric(temp[,-1])))names(exinfo) <- temp[,1]exinfo$use_sim_spatial <- 	exinfo$ExtractSoilDataFromCONUSSOILFromSTATSGO_USA	||	exinfo$ExtractSoilDataFromISRICWISEv12_Global		||	exinfo$ExtractElevation_NED_USA						||	exinfo$ExtractElevation_HWSD_Global					||	exinfo$ExtractSkyDataFromNOAAClimateAtlas_USA		||	exinfo$ExtractSkyDataFromNCEPCFSR_Global#------------------------SPATIAL SETUP OF SIMULATIONSif (exinfo$use_sim_spatial || any(actions == "map_input")) {	if (any(!requireNamespace("rgdal"), !requireNamespace("sp"), !requireNamespace("raster"))) {		stop("The packages 'rgdal', 'sp', and 'raster' are required, but one or multiple of them are not installed.")	}		# make sure that flag 'sim_cells_or_points' has a valid option	sim_cells_or_points <- match.arg(sim_cells_or_points, c("point", "cell"))	# make sure sim_raster agrees with sim_res and sim_crs; sim_raster takes priority	if (sim_cells_or_points == "cell") {		if (file.exists(fname_sim_raster)) {			sim_raster <- raster::raster(fname_sim_raster)			sim_res <- raster::res(sim_raster)			sim_crs <- raster::crs(sim_raster)		}		# make sure that sim_res is valid		stopifnot(is.finite(sim_res), length(sim_res) == 2L, sim_res > 0)	}	# make sure that sim_crs is valid	stopifnot((temp <- rgdal::checkCRSArgs(as.character(sim_crs)))[[1]])	sim_crs <- sp::CRS(temp[[2]])	# SpatialPoints of simulation cell centers/sites in WGS84	crs_sites <- sp::CRS("+init=epsg:4326")	# sp::CRS("+proj=longlat +datum=WGS84 +no_defs")	run_sites <- sp::SpatialPoints(coords = with(SWRunInformation[runIDs_sites,], data.frame(X_WGS84, Y_WGS84)), proj4string = crs_sites)	}#--------------------------------------------------------------------------------------------------##------------------------SET UP PARALLELIZATION#used in: GriddedDailyWeatherFromNCEPCFSR_Global, external dataset extractions, loop calling do_OneSite, and ensemblesworkersN <- 1parallel_init <- FALSEif(any(actions == "external") || (actionWithSoilWat && runsN_todo > 0) || do.ensembles){	if(parallel_runs){		if(!be.quiet) print(paste("SWSF prepares parallelization: started at", t1 <- Sys.time()))		if(identical(parallel_backend, "mpi")) {			mpi.spawn.Rslaves(nslaves=num_cores)			exportObjects <- function(allObjects) {				print("exporting objects from master node to slave nodes")				t.bcast <- Sys.time()				for(obj in 1:length(allObjects)) {					bcast.tempString <- allObjects[obj]					bcast.tempValue <- try(eval(as.name(allObjects[obj])))					if(!inherits(bcast.tempValue, "try-error")){						mpi.bcast.Robj2slave(bcast.tempString)						mpi.bcast.Robj2slave(bcast.tempValue)						mpi.bcast.cmd(cmd=try(assign(bcast.tempString, bcast.tempValue)))					} else {						print(paste(obj, bcast.tempString, "not successful"))					}				}				print(paste("object export took", round(difftime(Sys.time(), t.bcast, units="secs"), 2), "secs"))			}		}		if(identical(parallel_backend, "snow")){			if(!be.quiet) setDefaultClusterOptions(outfile="")			#cl <-  makeCluster(num_cores, type="MPI", outfile="")			cl <- snow::makeSOCKcluster(num_cores)			clusterApply(cl, seq_len(num_cores), function(x) .nodeNumber <<- x) # need a .x object that does not get deleted with rm(list = ls())			#snow::clusterSetupRNG(cl) #random numbers setup			doSNOW::registerDoSNOW(cl) 	# register foreach backend		}		if(identical(parallel_backend, "multicore")) {			#stop("Only use snow on JANUS, because multicore cannot access cores outside master node")			registerDoMC(num_cores)		}		if(identical(parallel_backend, "mpi")){			workersN <- (mpi.comm.size() - 1)		} else {			workersN <- foreach::getDoParWorkers()		}		parallel_init <- TRUE		if(!be.quiet) print(paste("SWSF prepares parallelization: initialization of", workersN, "workers ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))	}}#--------------------------------------------------------------------------------------------------##------------------------FUNCTIONS FOR NCEP/CFSR DATAif(exinfo$GriddedDailyWeatherFromNCEPCFSR_Global || exinfo$ExtractSkyDataFromNCEPCFSR_Global){	writeLines(c("'NCEPCFSR' extractions: make sure the following conditions are met:", 		" 	1) C code for 'cfsr_convert' is located in directory 'dir.cfsr.code'",		"	2) Compiled 'wgrib2' executable is located in directory 'dir.cfsr.code' or '/opt/local/bin/' & have it located in the same directory as cfsr_convert.  Instructions for how to compile 'wgrib2' can be found in the 'cfsr_convert.c'. The code of wgrib2 is available from http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/",		"	3) Appropriate grib files (the data) are located in directory 'dir.cfsr.data'.  Info about the gribfiles is in 'cfsr_convert.c'"))	#daily data (http://rda.ucar.edu/datasets/ds093.1/): ds093.1 NCEP Climate Forecast System Reanalysis (CFSR) Selected Hourly Time-Series Products, January 1979 to December 2010, 0.313-deg: 6-hourly	#- maximum temperature: 2m above ground (Kelvin): 6-hour period	#	-> tmax.gdas.yyyymm.grb2 --> max of 4 values per day	#- minimum temperature: 2m above ground (Kelvin): 6-hour period	#	-> tmin.gdas.yyyymm.grb2 --> max of 4 values per day	#- precipitation rate: ground or water surface (kg m-2 s-1): 6-hour average	#	-> prate.gdas.yyyymm.grb2 --> sum of 4 values per day which are converted to cm/6-hour	#monthly data (http://rda.ucar.edu/datasets/ds093.2/): ds093.2 - NCEP Climate Forecast System Reanalysis (CFSR) Monthly Products, January 1979 to December 2010, 0.313-deg: monthly mean (4 per day) of forecasts of 6-hour average	#- relative humidity (%): entire atmosphere --> 2m above ground	#	-> [0.5-deg] pgbh06.gdas.R_H.2m.grb2 --> means for Jan-Dec	#- wind (m s-1): u- and v-component at 10m above ground	#	-> flxf06.gdas.WND.10m.grb2 (u- and v-component) --> means for Jan-Dec	#- total cloud cover (%): entire atmosphere as a single layer	#	-> flxf06.gdas.T_CDC.EATM.grb2 --> means for Jan-Dec	load_NCEPCFSR_shlib <- function(cfsr_so){		if(!is.loaded("writeMonthlyClimate_R")) dyn.load(cfsr_so) # load because .so is available		invisible(0)	}	prepare_NCEPCFSR_extraction <- function(dir.cfsr.data, dir.cfsr.code = dir.cfsr.data) {		dir.create(dir.in.cfsr <- file.path(dir.big, "ncepcfsr"), showWarnings=FALSE)		fname_cfsr <- file.path(dir.in.cfsr, "cfsr_convert.so")		.local <- function(){			#Check for the shared object 'cfsr_convert.so' that contains the C functions accessible to R			if(!file.exists(fname_cfsr)){ # compile				dtemp <- getwd()				setwd(dir.cfsr.code)				stopifnot(file.exists("cfsr_convert.c", "generic2.c", "generic2.h", "filefuncs2.c", "filefuncs2.h", "mymemory2.c", "mymemory2.h"))				unlink(c("cfsr_convert.o", "generic2.o", "filefuncs2.o", "mymemory2.o"))				stopifnot(system2(command=file.path(Sys.getenv()[["R_HOME"]], "R"), args=paste("CMD SHLIB -o", fname_cfsr, "cfsr_convert.c generic2.c filefuncs2.c mymemory2.c"), wait=TRUE) == 0)				setwd(dtemp)			}			load_NCEPCFSR_shlib(fname_cfsr)			#Check for wgrib2 (http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/)			if(!file.exists(wgrib2 <- file.path(dir.in.cfsr, "wgrib2"))){				temp2 <- if(nchar(temp <- Sys.which("wgrib2")) > 0) temp else if(file.exists(temp <- "/opt/local/bin/wgrib2")) temp else ""				stopifnot(nchar(temp2) > 0)				file.copy(from=temp2, to=wgrib2)			}			#Soft link to gribbed data			fname_gribDir <- "griblargeC2"			if(!file.exists(dir.grib <- file.path(dir.in.cfsr, fname_gribDir))){ # value of gribDir defined in cfsr_convert.c				stopifnot(system2(command="ln", args=paste("-s", file.path(dir.cfsr.data, fname_gribDir), dir.grib)) == 0)			}			#Set up temporary directory for C code to store objects			if(file.exists(ftemp <- file.path(dir.in.cfsr, "temporary_dy"))) unlink(ftemp, recursive=TRUE)			temp <- lapply(lapply(c("tmax", "tmin", "ppt"), FUN=function(x) file.path(ftemp, x)), FUN=function(x) dir.create(x, recursive=TRUE, showWarnings=FALSE))			return(0)		}		temp <- .local()		res <- if(!inherits(temp, "try-error")) list(dir.in.cfsr=dir.in.cfsr, cfsr_so=fname_cfsr)  else temp		return(res)	}		dir.ex.CFSR <- file.path(dir.ex.weather, "NCEPCFSR_Global", "CFSR_weather_prog08032012")	stopifnot(file.exists(dir.ex.CFSR))	prepd_CFSR <- prepare_NCEPCFSR_extraction(dir.cfsr.data=dir.ex.CFSR)	stopifnot(!inherits(prepd_CFSR, "try-error"))	# Wrapper functions for C code to access NCEP/CFSR data and write out to temporary files	gribDailyWeatherData <- function(id, do_daily, nSites, latitudes, longitudes) {		if(id %% 36 == 1) print(paste(Sys.time(), ": NCEP/CFSR extraction: year=", do_daily[id, "years"]))		gribData <- .C("dailyWeather2_R",							nSites = as.integer(nSites),							latitudes = as.double(latitudes),							longitudes = as.double(longitudes),							year = as.integer(do_daily[id, "years"]),							month = as.integer(do_daily[id, "months"]),							type = as.integer(do_daily[id, "types"]))		return(1)	}	writeDailyWeatherData <- function(year, nSites, siteNames, siteDirsC) {		dataWrite <- .C("dailyWeather2Write_R",							nSites = as.integer(nSites),							siteNames = as.character(siteNames),							siteDirs = as.character(siteDirsC),							year = as.integer(year))		return(1)	}	gribMonthlyClimate <- function(type, nSites, latitudes, longitudes, siteDirsC, yearLow, yearHigh) {		gribData <- .C("monthlyClimate2_R",							nSites = as.integer(nSites),							latitudes = as.double(latitudes),							longitudes = as.double(longitudes),							siteDirs = as.character(siteDirsC),							yearLow = as.integer(yearLow),							yearHigh = as.integer(yearHigh),							type = as.integer(type))		return(1)	}	writeMonthlyClimate <- function(id, siteDirsC) {		dataWrite <- .C("writeMonthlyClimate2_R", siteDir = as.character(siteDirsC[id]))		return(1)	}	get_NCEPCFSR_data <- function(dat_sites, daily=FALSE, monthly=FALSE, yearLow, yearHigh, n_site_per_core=100, cfsr_so, dir.in.cfsr, dir.temp, rm_mc_files=FALSE, continueAfterAbort. = continueAfterAbort){	#str(dat_sites): 'data.frame':	n_sites obs. of  3 variables:	# $ WeatherFolder: chr  ...	# $ X_WGS84      : num  -117 -117 -117 -117 -120 ...	# $ Y_WGS84      : num  32.8 32.8 32.8 32.8 38.9 ...				years <- yearLow:yearHigh		# directory paths		dir.temp.cfsr <- file.path(dir.temp, "temp_NCEFCFSR")		dir.temp.sites <- file.path(dir.temp.cfsr, dat_sites[, "WeatherFolder"])				# determine previous efforts				if (continueAfterAbort.) {			i_done <- file.exists(dir.temp.sites)			if (sum(i_done) > 0) {				for (i in which(i_done)) {					i_done[i] <- 						if (monthly) {							file.exists(file.path(dir.temp.sites[i], "mc.csv")) ||							{file.exists(file.path(dir.temp.sites[i], "cc.txt")) &&							file.exists(file.path(dir.temp.sites[i], "rh.txt")) &&							file.exists(file.path(dir.temp.sites[i], "ws.txt"))}						} else {							TRUE						} && if (daily) {							d_files <- list.files(dir.temp.sites[i], pattern = "weath.")							d_years <- as.integer(sapply(strsplit(d_files, ".", fixed = TRUE), function(x) x[2]))							all(d_years %in% years)						} else {							TRUE						}					if (!i_done[i]) unlink(dir.temp.sites[i], recursive = TRUE)				}			}			i_todo <- !i_done					} else {			i_todo <- rep(TRUE, nrow(dat_sites))		}		# prepare tasks		# do the extractions, loop over chunks of sites		n_sites <- sum(i_todo)		n_sites_all <- nrow(dat_sites)				if (n_sites > 0) {			dat_sites_todo <- dat_sites[i_todo, ]						dir.create(dir.temp.cfsr, showWarnings = FALSE)			temp <- lapply(dir.temp.sites, dir.create, showWarnings = FALSE)			dir.temp.sitesC <- gsub("/", "//", normalizePath(dir.temp.sites)) # C-style paths; they cannot be relative to ~					n_years <- length(years)			n_climvars <- n_dailyvars <- 3			do_sites <- parallel::splitIndices(n_sites, ceiling(n_sites / n_site_per_core))			do_daily <- expand.grid(types = seq_len(n_dailyvars) - 1, months = st_mo, years = years)			dtemp <- getwd()			setwd(dir.in.cfsr)			# set up parallel			if (parallel_runs && parallel_init) {				list.export <- c("load_NCEPCFSR_shlib", "cfsr_so", "dir.in.cfsr") #objects that need exporting to slaves				if (identical(parallel_backend, "mpi")) {					exportObjects(list.export)					mpi.bcast.cmd(load_NCEPCFSR_shlib(cfsr_so))					mpi.bcast.cmd(setwd(dir.in.cfsr))				}				if (identical(parallel_backend, "snow")) {					export_obj_local <- list.export[list.export %in% ls(name=environment())]					export_obj_in_parent <- list.export[list.export %in% ls(name=parent.frame())]					export_obj_in_parent <- export_obj_in_parent[!(export_obj_in_parent %in% export_obj_local)]					export_obj_in_globenv <- list.export[list.export %in% ls(name=.GlobalEnv)]					export_obj_in_globenv <- export_obj_in_globenv[!(export_obj_in_globenv %in% c(export_obj_local, export_obj_in_parent))]					stopifnot(c(export_obj_local, export_obj_in_parent, export_obj_in_globenv) %in% list.export)					if (length(export_obj_local) > 0) snow::clusterExport(cl, export_obj_local, envir=environment())					if (length(export_obj_in_parent) > 0) snow::clusterExport(cl, export_obj_in_parent, envir=parent.frame())					if (length(export_obj_in_globenv) > 0) snow::clusterExport(cl, export_obj_in_globenv, envir=.GlobalEnv)					snow::clusterEvalQ(cl, load_NCEPCFSR_shlib(cfsr_so))					snow::clusterEvalQ(cl, setwd(dir.in.cfsr))				}			}			for (k in seq_along(do_sites)) {				if(!be.quiet) print(paste(Sys.time(), ": NCEP/CFSR extraction of", if(daily) "daily", if(daily && monthly) "and", if(monthly) "monthly", "data: chunk", k, "of", length(do_sites)))				nDailyReads <- nDailyWrites <- nMonthlyReads <- nMonthlyWrites <- 0				ntemp <- length(do_sites[[k]])				irows <- do_sites[[k]]				longs <- dat_sites_todo[irows, "X_WGS84"]				lats <- dat_sites_todo[irows, "Y_WGS84"]				dtemp <- dir.temp.sitesC[irows]				if (print.debug) print(paste(Sys.time(), "cfsr chunk", k, ": # open R files", system2(command="lsof", args="-c R | wc -l", stdout=TRUE)))				if (parallel_runs && parallel_init) {					if (identical(parallel_backend, "mpi")) {						if (daily) {							nDailyReads <- mpi.applyLB(x=1:nrow(do_daily), fun=gribDailyWeatherData, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)							nDailyReads <- do.call(sum, nDailyReads)							nDailyWrites <- mpi.applyLB(x=years, fun=writeDailyWeatherData, nSites=ntemp, siteNames=dat_sites_todo[irows, "WeatherFolder"], siteDirsC=dtemp)							nDailyWrites <- do.call(sum, nDailyWrites)						}						if (monthly) {							nMonthlyReads <- mpi.applyLB(x=0:(n_climvars-1), fun=gribMonthlyClimate, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)							nMonthlyReads <- do.call(sum, nMonthlyReads)						}						if (monthly && k == length(do_sites)) { # only do at the end							nMonthlyWrites <- mpi.applyLB(x=seq_len(n_sites_all), fun=writeMonthlyClimate, siteDirsC=dir.temp.sitesC)							nMonthlyWrites <- do.call(sum, nMonthlyWrites)						}					} else if (identical(parallel_backend, "snow")) {						if (daily) {							nDailyReads <- snow::clusterApplyLB(cl, x=1:nrow(do_daily), fun=gribDailyWeatherData, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)							nDailyReads <- do.call(sum, nDailyReads)							nDailyWrites <- snow::clusterApplyLB(cl, x=years, fun=writeDailyWeatherData, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)							nDailyWrites <- do.call(sum, nDailyWrites)						}						if (monthly) {							nMonthlyReads <- snow::clusterApplyLB(cl, x=0:(n_climvars-1), fun=gribMonthlyClimate, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)							nMonthlyReads <- do.call(sum, nMonthlyReads)						}						if (monthly && k == length(do_sites)) { # only do at the end							nMonthlyWrites <- snow::clusterApplyLB(cl, x=seq_len(n_sites_all), fun=writeMonthlyClimate, siteDirsC=dir.temp.sitesC)							nMonthlyWrites <- do.call(sum, nMonthlyWrites)						}					} else if (identical(parallel_backend, "multicore")) {						if (daily) {							nDailyReads <- foreach(id = 1:nrow(do_daily), .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								gribDailyWeatherData(id, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)							nDailyWrites <- foreach(y = years, .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								writeDailyWeatherData(y, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)						}						if (monthly) {							nMonthlyReads <- foreach(iv = 0:(n_climvars-1), .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								gribMonthlyClimate(iv, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)						}						if (monthly && k == length(do_sites)) { # only do at the end							nMonthlyWrites <- foreach(ic = seq_len(n_sites_all), .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								writeMonthlyClimate(ic, siteDirsC=dir.temp.sitesC)						}					}				} else {					if (daily) {						nDailyReads <- foreach(id = 1:nrow(do_daily), .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							gribDailyWeatherData(id, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)						nDailyWrites <- foreach(y = years, .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							writeDailyWeatherData(y, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)					}					if (monthly) {						nMonthlyReads <- foreach(iv = 0:(n_climvars-1), .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							gribMonthlyClimate(iv, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)					}					if (monthly && k == length(do_sites)) { # only do at the end						nMonthlyWrites <- foreach(ic = seq_len(n_sites_all), .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							writeMonthlyClimate(ic, siteDirsC=dir.temp.sitesC)					}				}				# check that all was done				if (daily) stopifnot(nDailyReads == nrow(do_daily), nDailyWrites == n_years)				if (monthly) stopifnot(nMonthlyReads == n_climvars)			}			# check that all was done			if (monthly) stopifnot(nMonthlyWrites == n_sites)			# clean up parallel			if (parallel_runs && parallel_init){				if (identical(parallel_backend, "mpi")) {					mpi.bcast.cmd(rm(list=ls()))					mpi.bcast.cmd(gc())				}				if (identical(parallel_backend, "snow")) {					snow::clusterEvalQ(cl, rm(list=ls()))					snow::clusterEvalQ(cl, gc())				}			}			setwd(dtemp)		}		# concatenating the monthlyClimate csv files		if (monthly) {			res_clim <- data.frame(matrix(NA, nrow = n_sites_all, ncol = 1 + n_climvars * 12))			colnames(res_clim) <- c("WeatherFolder", paste0("Cloud_m", st_mo), paste0("Wind_m", st_mo), paste0("RH_m", st_mo))			res_clim[, "WeatherFolder"] <- dat_sites[, "WeatherFolder"]			for (i in seq_len(n_sites_all)) {				ftemp <- file.path(dir.temp.sites[i], "mc.csv")				if (file.exists(ftemp)) {					table.mc <- read.csv(file=ftemp, comment="", stringsAsFactors=FALSE)					res_clim[i, 1 + st_mo] <- table.mc[, "Cloud_Cover"]					res_clim[i, 1 + 12 + st_mo] <- table.mc[, "Surface_Wind"]					res_clim[i, 1 + 24 + st_mo] <- table.mc[, "Rel_Humidity"]					if (rm_mc_files == TRUE) unlink(ftemp)				}			}		} else {			res_clim <- NULL		}		list(dir.temp.cfsr = dir.temp.cfsr, res_clim = res_clim)	}}#------------------------DAILY WEATHERif (extract_determine_database == "SWRunInformation" && "dailyweather_source" %in% colnames(SWRunInformation)) {	sites_dailyweather_source <- factor(SWRunInformation$dailyweather_source[runIDs_sites], levels=dailyweather_options)	do_weather_source <- anyNA(sites_dailyweather_source)} else {	sites_dailyweather_source <- factor(rep(NA, runsN_sites), levels=dailyweather_options)	do_weather_source <- TRUE}weather.digits <- 2lwf_cond1 <- sw_input_treatments_use$LookupWeatherFolder && sum(is.na(sw_input_treatments$LookupWeatherFolder[runIDs_sites])) == 0lwf_cond2 <- (sum(is.na(SWRunInformation$WeatherFolder[runIDs_sites])) == 0) && !any(as.logical(c(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica, exinfo$GriddedDailyWeatherFromDayMet_USA, exinfo$GriddedDailyWeatherFromNRCan_10km_Canada, exinfo$GriddedDailyWeatherFromNCEPCFSR_Global)))lwf_cond3 <- sw_input_experimentals_use$LookupWeatherFolder && sum(is.na(sw_input_experimentals$LookupWeatherFolder)) == 0lwf_cond4 <- any(create_treatments == "LookupWeatherFolder")if(any(lwf_cond1, lwf_cond2, lwf_cond3, lwf_cond4)){	#function to be executed for each SoilWat-run	#TODO replace with Rsoilwat31::getWeatherData_folders	ExtractLookupWeatherFolder <- function(dir.weather, weatherfoldername){		WeatherFolder <- file.path(dir.weather, weatherfoldername)		weath <- list.files(WeatherFolder, pattern="weath.")		stopifnot(!anyNA(years <- as.numeric(sub(pattern="weath.", replacement="", weath))))		weatherData <- list()		for(j in seq_along(weath)) {			data_sw <- as.matrix(read.table(file.path(WeatherFolder, weath[j]), header=FALSE, comment.char = "#", blank.lines.skip=TRUE, sep="\t"))			data_sw[, -1] <- round(data_sw[, -1], 2) #weather.digits			colnames(data_sw) <- c("DOY", "Tmax_C", "Tmin_C", "PPT_cm")			weatherData[[j]] <- new("swWeatherData", year=years[j], data = data.matrix(data_sw, rownames.force = FALSE))		}		names(weatherData) <- years		return(weatherData)	}}if(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica){	#extract daily weather information for the grid cell coded by latitude/longitude for each simulation run	#Citation: Maurer, E. P., A. W. Wood, J. C. Adam, D. P. Lettenmaier, and B. Nijssen. 2002. A long-term hydrologically based dataset of land surface fluxes and states for the conterminous United States. Journal of Climate 15:3237-3251.	dir.ex.maurer2002 <- file.path(dir.ex.weather,"Maurer+_2002updated","DAILY_FORCINGS")	stopifnot(file.exists(dir.ex.maurer2002))	create_filename_for_Maurer2002_NorthAmerica <- function(X_WGS84, Y_WGS84){		gsub("[[:space:]]", "", paste("data", formatC(28.8125+round((Y_WGS84-28.8125)/0.125,0)*0.125, digits=4, format="f"), formatC(28.8125+round((X_WGS84-28.8125)/0.125,0)*0.125, digits=4, format="f"), sep="_"))	}	#function to be executed for each SoilWat-run	#' @return A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}.	#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.	ExtractGriddedDailyWeatherFromMaurer2002_NorthAmerica <- function(cellname, startYear=simstartyr, endYear=endyr){		#read data from Maurer et al. 2002		weath.data <- try(read.table(file=file.path(dir.ex.maurer2002, cellname), comment.char=""), silent=TRUE)				if(!inherits(weath.data, "try-error")){			colnames(weath.data) <- c("year", "month", "day", "prcp_mm", "Tmax_C", "Tmin_C", "Wind_mPERs")			#times			date <- seq(from=as.Date(with(weath.data[1, ], paste(year, month, day, sep="-")), format="%Y-%m-%d"),					to=as.Date(with(weath.data[nrow(weath.data), ], paste(year, month, day, sep="-")), format="%Y-%m-%d"),					by="1 day")						# conversion precipitation: mm/day -> cm/day			data_all <- with(weath.data, data.frame(doy=1 + as.POSIXlt(date)$yday, Tmax_C, Tmin_C, prcp_mm/10))			colnames(data_all) <- c("DOY", "Tmax_C", "Tmin_C", "PPT_cm")			years <- startYear:endYear			n_years <- length(years)			if(!all(years %in% unique(weath.data$year)))				stop("simstartyr or endyr out of weather data range")			weathDataList <- list()			for(y in seq_along(years)) {				data_sw <- data_all[weath.data$year == years[y], ]				data_sw[, -1] <- round(data_sw[, -1], 2) #weather.digits				weathDataList[[y]]<-new("swWeatherData", data = data.matrix(data_sw, rownames.force = FALSE), year = years[y]) #strip row.names, otherwise they consume about 60% of file size			}			names(weathDataList) <- as.character(years)			weath.data <- weathDataList		}				weathDataList	}}if(exinfo$GriddedDailyWeatherFromDayMet_NorthAmerica){	# https://daymet.ornl.gov/	#extract daily weather information for the grid cell coded by latitude/longitude for each simulation run	#Citation	#	- article: Thornton, P.E., Running, S.W., White, M.A. 1997. Generating surfaces of daily meteorological variables over large regions of complex terrain. Journal of Hydrology 190: 214 - 251. http://dx.doi.org/10.1016/S0022-1694(96)03128-9	#	- dataset: Thornton, P.E., M.M. Thornton, B.W. Mayer, N. Wilhelmi, Y. Wei, R. Devarakonda, and R.B. Cook. 2014. Daymet: Daily Surface Weather Data on a 1-km Grid for North America, Version 2. ORNL DAAC, Oak Ridge, Tennessee, USA. Accessed Month DD, YYYY. Time period: YYYY-MM-DD to YYYY-MM-DD. Spatial range: N=DD.DD, S=DD.DD, E=DDD.DD, W=DDD.DD. http://dx.doi.org/10.3334/ORNLDAAC/1219	stopifnot(file.exists(dir.ex.daymet <- file.path(dir.ex.weather, "DayMet_NorthAmerica", "DownloadedSingleCells_FromDayMet_NorthAmerica")))	stopifnot(require(DaymetR)) #https://bitbucket.org/khufkens/daymetr	stopifnot(require(raster))	stopifnot(require(rgdal))	get_DayMet_cellID <- function(coords_WGS84) {		# Determine 1-km cell that contains requested location		res_DayMet <- 1000L		proj_LCC <- CRS("+proj=lcc +lat_1=25 +lat_2=60 +lat_0=42.5 +lon_0=-100 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")		proj_WGS84 <- CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0")		xy_LCC <- coordinates(spTransform(SpatialPoints(coords = coords_WGS84, proj4string = proj_WGS84), proj_LCC))		dm_LCC <- floor(xy_LCC / res_DayMet) # Origin at lower-lef corner (-2015000, -3037000)			## ==> (0, 0)- cell includes xlim = [0, 1000[ and ylim = [0, 1000[			## ==> at 100-m and 1-m scale: ok; but some deviations at 0.5-m scale		cellID <- apply(dm_LCC, 1, FUN = function(chr) paste0("daymet_pixel_",													if(chr[1] < 0) "-" else "+", formatC(abs(chr[1]), width=6, flag="0", format="d"), "_",													if(chr[2] < 0) "-" else "+", formatC(abs(chr[2]), width=6, flag="0", format="d")))		dm_LCC <- res_DayMet * dm_LCC + 500 # center of 1-km cells to avoid projection errors at cell margins		dm_WGS84 <- coordinates(spTransform(SpatialPoints(coords = dm_LCC, proj4string = proj_LCC), proj_WGS84))		return(list(cellID = cellID, dm_LCC = dm_LCC, dm_WGS84 = dm_WGS84))	}	#' @return A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}.	#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.	get_DayMet_NorthAmerica <- function(cellID, Xdm_WGS84, Ydm_WGS84, start_year=simstartyr, end_year=endyr){		# Filename for data of this 1-km cell		ftemp <- file.path(dir.ex.daymet, paste0(cellID, "_", start_year, "_", end_year, ".csv"))		# Get data		pwd <- getwd()		get_from_ornl <- TRUE		if(file.exists(ftemp)){			dm_temp <- try(read.table(ftemp, sep = ",", skip = 6, header = TRUE), silent=TRUE)			if(!inherits(dm_temp, "try-error")) get_from_ornl <- FALSE		}		if(get_from_ornl){			setwd(dir.ex.daymet)			dm_temp <- try(DaymetR::download.daymet(site=cellID, lat=Ydm_WGS84, lon=Xdm_WGS84, start_yr=start_year, end_yr=end_year, internal=TRUE, quiet=TRUE), silent=TRUE)		}		# Convert to Rsoilwat format		if(!inherits(dm_temp, "try-error")){			if(exists(cellID, envir=.GlobalEnv)){				temp <- get(cellID, envir=.GlobalEnv)$data			} else if(!get_from_ornl && inherits(dm_temp, "data.frame")){				temp <- dm_temp			} else stop(paste("Daymet data not successful", cellID))			data_all <- with(temp, data.frame(year, yday, tmax..deg.c., tmin..deg.c., prcp..mm.day./10))			stopifnot(!anyNA(data_all), sum(data_all == -9999L) == 0)			template_sw <- data.frame(matrix(NA, nrow=366, ncol=4, dimnames=list(NULL, c("DOY", "Tmax_C", "Tmin_C", "PPT_cm"))))			years <- start_year:end_year			weathDataList <- list()			for(y in seq_along(years)){				data_sw <- template_sw				# All Daymet years, including leap years, have 1 - 365 days. For leap years, the Daymet database includes leap day. Values for December 31 are discarded from leap years to maintain a 365-day year.				data_sw[1:365, ] <- data_all[data_all$year == years[y], -1]				if(isLeapYear(years[y])){					data_sw[366, ] <- c(366, data_sw[365, -1])				}				data_sw[, -1] <- round(data_sw[, -1], 2) #weather.digits				weathDataList[[y]] <- new("swWeatherData", data=data.matrix(data_sw[if(isLeapYear(years[y])) 1:366 else 1:365, ], rownames.force=FALSE), year=years[y]) #strip row.names, otherwise they consume about 60% of file size			}			names(weathDataList) <- as.character(years)		} else {			weathDataList <- dm_temp		}		# Clean up		if(exists(cellID, envir=.GlobalEnv)) rm(list=cellID, envir=.GlobalEnv)		setwd(pwd)		weathDataList	}	if(getCurrentWeatherDataFromDatabase && createAndPopulateWeatherDatabase){		# Function to be executed for all SoilWat-sites together		#' @return An invisible zero. A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}. The list is copied to the weather database.		#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.		ExtractGriddedDailyWeatherFromDayMet_NorthAmerica <- function(site_ids, coords_WGS84, start_year, end_year) {			if (!be.quiet) print(paste("Started 'ExtractGriddedDailyWeatherFromDayMet_NorthAmerica' at", Sys.time()))			# Check if weather data was previously partially extracted			wtemp_file <- file.path(dir.out.temp, "DayMet_weather_temp.rds")			site_ids_done <- if (file.exists(wtemp_file)) readRDS(wtemp_file) else NULL			iuse <- !(site_ids %in% site_ids_done)			if (sum(iuse) > 0) {				site_ids_todo <- site_ids[iuse]				xy_WGS84 <- coords_WGS84[iuse, , drop=FALSE]				dm <- get_DayMet_cellID(xy_WGS84)				#TODO: re-write for parallel processing (does it make sense to download in parallel?)				# Extract weather data sequentially for requested locations				for (idm in seq_along(site_ids_todo)) {					if (!be.quiet) print(paste(Sys.time(), "DayMet data extraction of site", site_ids_todo[idm], "at", paste(round(coords_WGS84[idm, ], 4), collapse="/")))					weatherData <- get_DayMet_NorthAmerica(cellID=dm$cellID[idm], Xdm_WGS84=dm$dm_WGS84[idm, 1], Ydm_WGS84=dm$dm_WGS84[idm, 2], start_year, end_year)										if (!inherits(weatherData, "try-error")) {						# Store site weather data in weather database						data_blob <- dbW_weatherData_to_blob(weatherData, type = dbW_compression_type)						Rsoilwat31:::dbW_addWeatherDataNoCheck(Site_id = site_ids_todo[idm],							Scenario_id = 1,							StartYear = start_year,							EndYear = end_year,							weather_blob = data_blob)						site_ids_done <- c(site_ids_done, site_ids_todo[idm])						saveRDS(site_ids_done, file = wtemp_file)					} else {						warning(paste(Sys.time(), "DayMet data extraction NOT successful for site", site_ids_todo[idm]))					}				}			}			if (!be.quiet) print(paste("Finished 'ExtractGriddedDailyWeatherFromDayMet_NorthAmerica' at", Sys.time()))			invisible(0)		}			} else {		# Function to be executed for each SoilWat-run		ExtractGriddedDailyWeatherFromDayMet_NorthAmerica <- function(site_ids, coords_WGS84, start_year, end_year) {			xy_WGS84 <- matrix(unlist(coords_WGS84), ncol = 2)[1, , drop = FALSE]			dm <- get_DayMet_cellID(xy_WGS84)			get_DayMet_NorthAmerica(cellID=dm$cellID[1], Xdm_WGS84=dm$dm_WGS84[1, 1], Ydm_WGS84=dm$dm_WGS84[1, 2], start_year, end_year)		}	}}if(exinfo$GriddedDailyWeatherFromNRCan_10km_Canada && createAndPopulateWeatherDatabase){	#Citations:	#	- Hopkinson, R. F., D. W. McKenney, E. J. Milewska, M. F. Hutchinson, P. Papadopol, and L. A. Vincent. 2011. Impact of Aligning Climatological Day on Gridding Daily Maximum–Minimum Temperature and Precipitation over Canada. Journal of Applied Meteorology and Climatology 50:1654-1665.	#	- Hutchinson, M. F., D. W. McKenney, K. Lawrence, J. H. Pedlar, R. F. Hopkinson, E. Milewska, and P. Papadopol. 2009. Development and Testing of Canada-Wide Interpolated Spatial Models of Daily Minimum–Maximum Temperature and Precipitation for 1961–2003. Journal of Applied Meteorology and Climatology 48:725-741.	#	- McKenney, D. W., M. F. Hutchinson, P. Papadopol, K. Lawrence, J. Pedlar, K. Campbell, E. Milewska, R. F. Hopkinson, D. Price, and T. Owen. 2011. Customized Spatial Climate Models for North America. Bulletin of the American Meteorological Society 92:1611-1622.	dir.ex.NRCan <- file.path(dir.ex.weather, "NRCan_10km_Canada", "DAILY_GRIDS")	stopifnot(file.exists(dir.ex.NRCan), require(raster), require(sp), require(rgdal))	# Function to be executed for all SoilWat-sites together	#' @return An invisible zero. A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}. The list is copied to the weather database.	#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.	ExtractGriddedDailyWeatherFromNRCan_10km_Canada <- function(site_ids, coords_WGS84, start_year, end_year) {		if(!be.quiet) print(paste("Started 'ExtractGriddedDailyWeatherFromNRCan_10km_Canada' at", Sys.time()))		NRC_years <- as.integer(list.dirs(path=dir.ex.NRCan, recursive=FALSE, full.names=FALSE))		NRC_target_years <- NRC_years[NRC_years %in% start_year:end_year]		stopifnot(start_year:end_year %in% NRC_target_years)		vars <- c("max", "min", "pcp") # units = C, C, mm/day		prj_geographicWGS84 <- CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0")		prj_geographicNAD83 <- CRS("+init=epsg:4269 +proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs +towgs84=0,0,0")		sp_locs <- SpatialPoints(coords=coords_WGS84, proj4string=prj_geographicWGS84)		sp_locs <- spTransform(sp_locs, CRSobj=prj_geographicNAD83)		#TODO: re-write for parallel processing with other backends		if(parallel_runs && identical(parallel_backend, "snow")) beginCluster(n=num_cores, type="SOCK")		#TODO: re-write for a more memory friendly approach		# Check if weather data was partially extracted already		wtemp_file <- file.path(dir.out.temp, "NRCan_weather_temp.RData")		if(file.exists(wtemp_file)){			load(wtemp_file) # NRC_weather, iy			yr_offset <- iy			NRC_use_years <- NRC_target_years[-(1:iy)]		} else {			NRC_weather <- array(NA, dim=c(length(sp_locs), 366, length(NRC_target_years), 3), dimnames=list(NULL, NULL, NRC_target_years, c("Tmax(C)", "Tmin(C)", "PPT(mm)")))			NRC_use_years <- NRC_target_years			yr_offset <- 0		}		# Extract weather data for all locations together for each day of each year		pwd <- getwd()		for(iy in seq_along(NRC_use_years)){ # Loop through years			if(!be.quiet) print(paste(Sys.time(), "NRC data extraction of year", NRC_use_years[iy]))			setwd(file.path(dir.ex.NRCan, NRC_use_years[iy]))			NRC_days <- list.files() #find all days for this year			ndays <- length(NRC_days) / length(vars)			stopifnot(ndays == if(isLeapYear(NRC_use_years[iy])) 366 else 365)			# Stack rasters for each day and extract data			NRC_stack <- stack(NRC_days, RAT=FALSE, quick=TRUE)			projection(NRC_stack) <- prj_geographicNAD83			temp <- round(extract(NRC_stack, sp_locs), 2) #weather.digits; [sp_locs, NRC_days x vars]			# Convert extraction information to array			ivars <- substr(NRC_days, 1, 3) # sapply(vars, nchar) == 3			for(iv in seq_along(vars)){				idays <- as.integer(sapply(strsplit(NRC_days[vars[iv] == ivars], split="[_.]"), FUN=function(x) x[2]))				NRC_weather[, 1:ndays, yr_offset + iy, iv] <- temp[, which(vars[iv] == ivars)[order(idays)][1:ndays]]			}			save(NRC_weather, iy, file=wtemp_file)		}		setwd(pwd)		if(parallel_runs && identical(parallel_backend, "snow")) endCluster()		# Convert weather array to SoilWat weather objects for each sites		NRC_weather[, , , "PPT(mm)"] <- NRC_weather[, , , "PPT(mm)"] / 10	# convert from mm/day to cm/day				for (i in seq_along(site_ids)) {			if (!be.quiet && i %% 100 == 1)				print(paste(Sys.time(), "storing NRC weather data of site_id", site_ids[i], i, "of", length(site_ids), "sites in database"))						weatherData <- list()			for (iy in seq_along(NRC_target_years)) {				doys <- if (isLeapYear(NRC_use_years[iy])) 1:366 else 1:365				data_sw <- cbind(doys, NRC_weather[i, doys, iy, ]) #DOY Tmax(C) Tmin(C) PPT(cm) [ppt was converted from mm to cm]				colnames(data_sw) <- c("DOY", "Tmax_C", "Tmin_C", "PPT_cm")				weatherData[[iy]] <- new("swWeatherData", data = data.matrix(data_sw, rownames.force = FALSE), year = NRC_target_years[iy])			}			names(weatherData) <- as.character(NRC_target_years)			# Store site weather data in weather database			data_blob <- dbW_weatherData_to_blob(weatherData, type = dbW_compression_type)			Rsoilwat31:::dbW_addWeatherDataNoCheck(Site_id = site_ids[i],				Scenario_id = 1,				StartYear = start_year,				EndYear = end_year,				weather_blob = data_blob)		}		#unlink(file=wtemp_file)		if (!be.quiet) print(paste("Finished 'ExtractGriddedDailyWeatherFromNRCan_10km_Canada' at", Sys.time()))		rm(NRC_weather, weatherData, data_blob)		gc()		invisible(0)	}}if(exinfo$GriddedDailyWeatherFromNCEPCFSR_Global && createAndPopulateWeatherDatabase){	#Citations: Saha, S., et al. 2010. NCEP Climate Forecast System Reanalysis (CFSR) Selected Hourly Time-Series Products, January 1979 to December 2010. Research Data Archive at the National Center for Atmospheric Research, Computational and Information Systems Laboratory. http://dx.doi.org/10.5065/D6513W89.	# http://rda.ucar.edu/datasets/ds093.1/. Accessed 8 March 2012.	# Function to be executed for all SoilWat-sites together	GriddedDailyWeatherFromNCEPCFSR_Global <- function(site_ids, dat_sites, start_year, end_year, n_site_per_core = 100, rm_temp = TRUE) {		# do the extractions		etemp <- get_NCEPCFSR_data(dat_sites = dat_sites, daily=TRUE, monthly=FALSE, yearLow=start_year, yearHigh=end_year, n_site_per_core=n_site_per_core, cfsr_so=prepd_CFSR$cfsr_so, dir.in.cfsr=prepd_CFSR$dir.in.cfsr, dir.temp=dir.out.temp, rm_mc_files=TRUE)		# move the weather data into the database		for (i in seq_along(site_ids)) {			weatherData <- getWeatherData_folders(LookupWeatherFolder = etemp$dir.temp.cfsr,				weatherDirName = dat_sites[i, "WeatherFolder"],				filebasename = "weath",				startYear = start_year,				endYear = end_year)			# Store site weather data in weather database			data_blob <- dbW_weatherData_to_blob(weatherData, type = dbW_compression_type)			Rsoilwat31:::dbW_addWeatherDataNoCheck(Site_id = site_ids[i],				Scenario_id = 1,				StartYear = start_year,				EndYear = end_year,				weather_blob = data_blob)		}		if (rm_temp) {			dir.remove(etemp$dir.temp.cfsr)			temp <- lapply(c("ppt", "tmax", "tmin"), FUN=function(x) dir.remove(file.path(prepd_CFSR$dir.in.cfsr, "temporary_dy", x)))		}		if (!be.quiet) print(paste("Finished 'ExtractGriddedDailyWeatherFromNCEPCFSR_Global' at", Sys.time()))		invisible(0)	}}if(do_weather_source){	#Functions to determine sources of daily weather; they write to global 'sites_dailyweather_source' and 'sites_dailyweather_names', i.e., the last entry is the one that will be used	dw_LookupWeatherFolder <- function(){		if(any(lwf_cond1, lwf_cond2, lwf_cond3, lwf_cond4)){			# Check which requested lookup weather folders are available			pwd <- getwd()			setwd(file.path(dir.sw.in.tr, "LookupWeatherFolder"))			there <- rep(FALSE, times = runsN_sites)			if(lwf_cond1)				there <- there | sapply(runIDs_sites, FUN=function(ix) if(!is.na(sw_input_treatments$LookupWeatherFolder[ix])) file.exists(sw_input_treatments$LookupWeatherFolder[ix]) else FALSE)			if(lwf_cond2)				there <- there | sapply(runIDs_sites, FUN=function(ix) if(!is.na(SWRunInformation$WeatherFolder[ix])) file.exists(SWRunInformation$WeatherFolder[ix]) else FALSE)			if(lwf_cond3)				there <- there | rep(any(sapply(sw_input_experimentals$LookupWeatherFolder, FUN=function(ix) file.exists(sw_input_experimentals$LookupWeatherFolder))), times = runsN_sites)			setwd(pwd)			if(sum(there) > 0)				sites_dailyweather_source[there] <<- "LookupWeatherFolder"			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'LookupWeatherFolder'"))		}		invisible(0)	}	dw_Maurer2002_NorthAmerica <- function(){		if(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica && (simstartyr >= 1949 && endyr <= 2010)){			# Check which requested Maurer weather data are available			Maurer <- with(SWRunInformation[runIDs_sites, ], create_filename_for_Maurer2002_NorthAmerica(X_WGS84, Y_WGS84))			there <- sapply(Maurer, FUN=function(im) file.exists(file.path(dir.ex.maurer2002, im)))			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "Maurer2002_NorthAmerica"				sites_dailyweather_names[there] <<- paste0(SWRunInformation$Label[runIDs_sites][there], "_", Maurer[there])			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'Maurer2002_NorthAmerica'"))		}		invisible(0)	}	dw_DayMet_NorthAmerica <- function(){		if(exinfo$GriddedDailyWeatherFromDayMet_NorthAmerica && (simstartyr >= 1980 && endyr <= as.POSIXlt(Sys.time())$year+1900 - 1)){			# Check which of the DayMet weather data are available			#	- Temperature: 2-meter air temperature in Celsius degrees			#	- Precipitation: mm/day; Daily total precipitation in millimeters per day, sum of all forms converted to water-equivalent. Precipitation occurrence on any given day may be ascertained.			#	- Grids domain: -131.104 	-52.95 	52.000 	14.53			#	- Grids: Geographic Coordinate Reference: WGS_1984; Projection: Lambert Conformal Conic			#	- Cells size: 1000 x 1000 m			#	- All Daymet years, including leap years, have 1 - 365 days. For leap years, the Daymet database includes leap day. Values for December 31 are discarded from leap years to maintain a 365-day year.			there <- (SWRunInformation[runIDs_sites, "X_WGS84"] >= -131.104 & SWRunInformation[runIDs_sites, "X_WGS84"] <= -52.95) & (SWRunInformation[runIDs_sites, "Y_WGS84"] >= 14.53 & SWRunInformation[runIDs_sites, "Y_WGS84"] <= 52)			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "DayMet_NorthAmerica"				sites_dailyweather_names[there] <<- with(SWRunInformation[runIDs_sites[there], ], paste0(Label, "_DayMet", formatC(X_WGS84, digits=4, format="f"), "_", formatC(Y_WGS84, digits=4, format="f")))			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'DayMet_NorthAmerica'"))		}		invisible(0)	}	dw_NRCan_10km_Canada <- function(){		if(exinfo$GriddedDailyWeatherFromNRCan_10km_Canada && (simstartyr >= 1950 && endyr <= 2013)){			# Check which of the NRCan weather data are available			#	- Temperature: Celsius degrees			#	- Precipitation: mm			#	- Grids domain: 141.00 to 52.00 W, 41.00 to 83.00 N			#	- Grids datum: geographic NAD83			#	- Columns: 1068, Rows: 510, Cells size: 0.083333333			nrc_test <- raster(file.path(dir.ex.NRCan, "1950", "max1950_1.asc"))			projection(nrc_test) <- CRS("+init=epsg:4269 +proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs +towgs84=0,0,0") #	see http://spatialreference.org/ref/epsg/4269/			sp_locs <- SpatialPoints(coords=SWRunInformation[runIDs_sites, c("X_WGS84", "Y_WGS84")], proj4string=CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"))			there <- !is.na(extract(nrc_test, y=spTransform(sp_locs, CRSobj=CRS(projection(nrc_test)))))			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "NRCan_10km_Canada"				sites_dailyweather_names[there] <<- with(SWRunInformation[runIDs_sites[there], ], paste0(Label, "_NRCan", formatC(X_WGS84, digits=4, format="f"), "_", formatC(Y_WGS84, digits=4, format="f")))			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'NRCan_10km_Canada'"))		}		invisible(0)	}	dw_NCEPCFSR_Global <- function(){		if(exinfo$GriddedDailyWeatherFromNCEPCFSR_Global && (simstartyr >= 1979 && endyr <= 2010)){			# Check which of the NCEPCFSR_Global weather data are available			#	- Grids domain: 0E to 359.688E and 89.761N to 89.761S			there <- (SWRunInformation[runIDs_sites, "X_WGS84"] >= 0 - 180 & SWRunInformation[runIDs_sites, "X_WGS84"] <= 360 - 180) & (SWRunInformation[runIDs_sites, "Y_WGS84"] >= -89.761 & SWRunInformation[runIDs_sites, "Y_WGS84"] <= 89.761)			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "NCEPCFSR_Global"				sites_dailyweather_names[there] <<- with(SWRunInformation[runIDs_sites[there], ], paste0(Label, "_CFSR", formatC(X_WGS84, digits=4, format="f"), "_", formatC(Y_WGS84, digits=4, format="f")))			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'NCEPCFSR_Global'"))		}		invisible(0)	}	#Determine order of priorities (highest priority comes last)	sites_dailyweather_names <- rep(NA, times=length(sites_dailyweather_source))	dailyweather_priorities <- rev(paste("dw", dailyweather_options, sep="_"))	for(idw in dailyweather_priorities) get(idw)()	if(anyNA(sites_dailyweather_source)){		if(FALSE){# remove sites with no weather; code to run by hand			xy <- SpatialPoints(coords=t(sapply(strsplit(list.files(dir.ex.maurer2002), "_"), FUN=function(x) as.numeric(x[3:2]))), proj4string=CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"))			sp_locs2 <- spTransform(sp_locs, CRSobj=CRS(projection(nrc_test)))			plot(sp_locs2, pch=19, cex=0.5, col=c("blue", "red", "green", "purple", "black")[ifelse(is.na(sites_dailyweather_source),5,sites_dailyweather_source)])			plot(nrc_test, col=adjustcolor("orange", alpha.f=0.5), add=TRUE)			if(require(maps)) map("state", add=TRUE)			plot(xy, col=adjustcolor("darkgray", alpha.f=0.5), lwd=1, add=TRUE)			id_remove <- which(is.na(sites_dailyweather_source))			if(!be.quiet) print(paste("There are no daily weather data for", length(id_remove), "sites"))			SWRunInformation$Include_YN[runIDs_sites][id_remove] <- 0			write.csv(SWRunInformation, file=file.path(dir.in, datafile.SWRunInformation), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))						stop(paste("Restart code because master file", datafile.SWRunInformation, "has changed"))		}	}	# Save information about weather source to disk file	sites_dailyweather_names <- gsub("[[:space:]]", "", sites_dailyweather_names)	SWRunInformation$WeatherFolder[runIDs_sites][!is.na(sites_dailyweather_names)] <- na.exclude(sites_dailyweather_names)	SWRunInformation$dailyweather_source[runIDs_sites] <- as.character(sites_dailyweather_source)	write.csv(SWRunInformation, file=file.path(dir.in, datafile.SWRunInformation), row.names=FALSE)	unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))}#------------------------CHECK THAT DAILY WEATHER DATA IS AVAILABLEif(anyNA(sites_dailyweather_source)){	stop("There are sites without daily weather. Provide data for all runs")}if(exinfo$ExtractClimateChangeScenarios_CMIP3_BCSD_GDODCPUCLLNL_USA || exinfo$ExtractClimateChangeScenarios_CMIP3_BCSD_GDODCPUCLLNL_Global || exinfo$ExtractClimateChangeScenarios_CMIP5_BCSD_GDODCPUCLLNL_USA || exinfo$ExtractClimateChangeScenarios_CMIP5_BCSD_GDODCPUCLLNL_Global || exinfo$ExtractClimateChangeScenarios_CMIP5_BCSD_NEX_USA) {	getScenarioWeatherDataFromDatabase <- TRUE	getCurrentWeatherDataFromDatabase <- TRUE}if(getScenarioWeatherDataFromDatabase)	getCurrentWeatherDataFromDatabase <- TRUEif(getCurrentWeatherDataFromDatabase){	if(!(createAndPopulateWeatherDatabase || file.exists(dbWeatherDataFile)))		stop("Create or use existing Weather database with Scenario data inside.")} else {	if(!any(create_treatments == "LookupWeatherFolder", as.logical(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica), as.logical(exinfo$GriddedDailyWeatherFromDayMet_NorthAmerica)))		stop("Daily weather data must be provided through 'LookupWeatherFolder', 'Maurer2002_NorthAmerica', or 'DayMet_NorthAmerica' since no weather database is used")}#------ Create the Database and Tables withinif(!be.quiet) print(paste("SWSF sets up the database: started at", t1 <- Sys.time()))name.OutputDB <- file.path(dir.out, "dbTables.sqlite3")if(copyCurrentConditionsFromDatabase | copyCurrentConditionsFromTempSQL) name.OutputDBCurrent <- file.path(dir.out, "dbTables_current.sqlite3")setwd(dir.prj)source(file.path(dir.code, "2_SWSF_p2of4_CreateDB_Tables_v51.R"), verbose = FALSE, chdir = FALSE)con <- DBI::dbConnect(RSQLite::SQLite(), dbname=name.OutputDB)if (getCurrentWeatherDataFromDatabase || getScenarioWeatherDataFromDatabase) {	# Check that version of dbWeather suffices	dbW_setConnection(dbWeatherDataFile)	v_dbW <- dbW_version()		if (v_dbW < minVersion_dbWeather) {		print(paste0("The version (", v_dbW, ") of the daily weather database is outdated; min. version required: ", minVersion_dbWeather))		if (v_dbW >= "1") print("Use function 'Rsoilwat31:::dbW_upgrade_v1to2' to upgrade your version 1.y.z weather database to version 2.0.0")		stop("Outdated weather database")	}	}if(!be.quiet) print(paste("SWSF sets up the database: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))#------simulation timingoutput_timescales_shortest <- ifelse(any(simulation_timescales=="daily"), 1, ifelse(any(simulation_timescales=="weekly"), 2, ifelse(any(simulation_timescales=="monthly"), 3, 4)))simTiming <- function(startyr, simstartyr, endyr){	#simyrs <- simstartyr:endyr	#no.simyr <- endyr - simstartyr + 1	useyrs <- startyr:endyr	no.useyr <- endyr - startyr + 1	no.usemo <- no.useyr * 12	no.usedy <- as.numeric(as.POSIXlt(paste(endyr, "-12-31", sep="")) - as.POSIXlt(paste(startyr, "-01-01", sep=""))) + 1	discardyr <- startyr - simstartyr	discardmo <- discardyr * 12	discarddy <- as.numeric(as.POSIXlt(paste(startyr, "-01-01", sep="")) - as.POSIXlt(paste(simstartyr, "-01-01", sep="")))	index.useyr <- (discardyr+1):(discardyr+no.useyr)	index.usemo <- (discardmo+1):(discardmo+no.usemo)	index.usedy <- (discarddy+1):(discarddy+no.usedy)	return(list(useyrs=useyrs, no.useyr=no.useyr, index.useyr=index.useyr, index.usemo=index.usemo, index.usedy=index.usedy))}simTiming_ForEachUsedTimeUnit <- function(simTime, latitude=90){	#positive latitudes -> northern hemisphere; negative latitudes -> southern hemisphere	res <- NULL	if(any(simulation_timescales=="daily")){		temp <- as.POSIXlt(seq(from=as.POSIXlt(paste(min(simTime$useyrs), "-01-01", sep="")), to=as.POSIXlt(paste(max(simTime$useyrs), "-12-31", sep="")), by="1 day"))		res$doy_ForEachUsedDay <- res$doy_ForEachUsedDay_NSadj <- temp$yday + 1		res$month_ForEachUsedDay <- res$month_ForEachUsedDay_NSadj <- temp$mon + 1		res$year_ForEachUsedDay <- res$year_ForEachUsedDay_NSadj <- temp$year + 1900		if(latitude < 0 && accountNSHemispheres_agg){			dshift <- as.POSIXlt(paste(simTime$useyrs, 6, 30, sep="-"))$yday+1	#new month either at end of year or in the middle because the two halfs (6+6 months) of a year are of unequal length (182 (183 if leap year) and 183 days): I chose to have a new month at end of year (i.e., 1 July -> 1 Jan & 30 June -> 31 Dec; but, 1 Jan -> July 3/4): and instead of a day with doy=366, there are two with doy=182			res$doy_ForEachUsedDay_NSadj <- unlist(lapply(seq(along=simTime$useyrs), FUN=function(x) c((temp <- res$doy_ForEachUsedDay[simTime$useyrs[x] == res$year_ForEachUsedDay])[-(1:dshift[x])], temp[1:dshift[x]])))			res$month_ForEachUsedDay_NSadj <- strptime(paste(res$year_ForEachUsedDay, res$doy_ForEachUsedDay_NSadj, sep="-"), format="%Y-%j")$mon + 1			res$year_ForEachUsedDay_NSadj <- c(rep(simTime$useyrs[1]-1, times=dshift[1] + ifelse(dshift[1] == 182, 2, 3)), res$year_ForEachUsedDay[-(((temp <- length(res$year_ForEachUsedDay)) - dshift[1] - ifelse(dshift[1] == 182, 1, 2)):temp)])		}	}	if(any(simulation_timescales=="weekly")){	}	if(any(simulation_timescales=="monthly")){		res$yearno_ForEachUsedMonth <- res$yearno_ForEachUsedMonth_NSadj <- rep(1:simTime$no.useyr, each=12)		res$month_ForEachUsedMonth <- res$month_ForEachUsedMonth_NSadj <- rep(st_mo, times=simTime$no.useyr)		if(latitude < 0 && accountNSHemispheres_agg){			res$month_ForEachUsedMonth_NSadj <- (res$month_ForEachUsedMonth + 5) %% 12 + 1		}	}	if(any(simulation_timescales=="yearly")){	}	return(res)}simTime <- simTiming(startyr, simstartyr, endyr)simTime_ForEachUsedTimeUnit_North <- simTiming_ForEachUsedTimeUnit(simTime, latitude=90)if(accountNSHemispheres_agg){	simTime_ForEachUsedTimeUnit_South <- simTiming_ForEachUsedTimeUnit(simTime, latitude=-90)} else {	simTime_ForEachUsedTimeUnit_South <- simTime_ForEachUsedTimeUnit_North}#------auxiliary functionsadjustLayersDepth <- function(layers_depth, d) return(round(layers_depth[1:d])) #The wrapper only handles 1-cm resolution of soil depths (maily because of the trco)getLayersWidth <- function(layers_depth) return(diff(c(0, layers_depth)))setLayerSequence <- function(d) return(1:d)sw_dailyC4_TempVar <- function(dailyTempMin, dailyTempMean, simTime2){	#Variables to estimate percent C4 species in North America: Teeri JA, Stowe LG (1976) Climatic patterns and the distribution of C4 grasses in North America. Oecologia, 23, 1-12.	Month7th_MinTemp_C <- aggregate(dailyTempMin[simTime2$month_ForEachUsedDay_NSadj == 7], by=list(simTime2$year_ForEachUsedDay_NSadj[simTime2$month_ForEachUsedDay_NSadj == 7]), FUN=min)[, 2]	LengthFreezeFreeGrowingPeriod_Days <- aggregate(dailyTempMin, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=function(x) {temp <- rle(x > 0); if(any(temp$values)) max(temp$lengths[temp$values], na.rm=TRUE) else 0})[, 2]	DegreeDaysAbove65F_DaysC <- aggregate(dailyTempMean, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=function(x) sum(ifelse((temp <- x - ((65-32) * 5/9)) > 0, temp, 0)))[, 2]	nyrs <- seq_along(Month7th_MinTemp_C) #if southern Hemisphere, then 7th month of last year is not included	res <- c(apply(temp <- cbind(Month7th_MinTemp_C[nyrs], LengthFreezeFreeGrowingPeriod_Days[nyrs], DegreeDaysAbove65F_DaysC[nyrs]), MARGIN=2, FUN=mean), apply(temp, MARGIN=2, FUN=sd))	names(res) <- c(temp <- c("Month7th_NSadj_MinTemp_C", "LengthFreezeFreeGrowingPeriod_NSadj_Days", "DegreeDaysAbove65F_NSadj_DaysC"), paste(temp, ".sd", sep=""))	return(res)}sw_SiteClimate_Ambient <- function(weatherList, year.start, year.end, do.C4vars=FALSE, simTime2=NULL) {	sw.weather.suffices <- as.numeric(names(weatherList))	itemp <- year.start <= sw.weather.suffices & year.end >= sw.weather.suffices	years <- sw.weather.suffices[itemp]	tempMean <- tempMin <- tempMax <- ppt <- rep(0, times=12)	mat <- NULL	if(do.C4vars){		dailyTempMin <- NULL		dailyTempMean <- NULL	}	if((no.yrs <- length(years)) > 0) for(y in 1:no.yrs){			temp.dailyTempMean <- apply(get_swWeatherData(weatherList, years[y])@data[, 2:3], 1, mean)			temp.dailyTempMin <- get_swWeatherData(weatherList, years[y])@data[, 3]			temp.dailyTempMax <- get_swWeatherData(weatherList, years[y])@data[, 2]			mat <- c(mat, mean(temp.dailyTempMean))			if(do.C4vars){				dailyTempMin <- c(dailyTempMin, get_swWeatherData(weatherList, years[y])@data[, 3])				dailyTempMean <- c(dailyTempMean, temp.dailyTempMean)			}			month_forEachDoy <- as.POSIXlt(seq(from=as.POSIXlt(paste(years[y], "-01-01", sep="")), to=as.POSIXlt(paste(years[y], "-12-31", sep="")), by="1 day"))$mon + 1			if (years[y] == 1942 ){			  month_forEachDoy<-c(month_forEachDoy,12)			}			tempMean <- tempMean + aggregate(temp.dailyTempMean, by=list(month_forEachDoy), FUN=mean)[, 2]			tempMin <- tempMin + aggregate(temp.dailyTempMin, by=list(month_forEachDoy), FUN=mean)[, 2]			tempMax <- tempMax + aggregate(temp.dailyTempMax, by=list(month_forEachDoy), FUN=mean)[, 2]			ppt <- ppt + aggregate(get_swWeatherData(weatherList, years[y])@data[, 4], by=list(month_forEachDoy), FUN=sum)[, 2]		}	tempMean <- tempMean / no.yrs	tempMin <- tempMin / no.yrs	tempMax <- tempMax / no.yrs	ppt <- ppt / no.yrs	res <- list(meanMonthlyTempC=tempMean, minMonthlyTempC=tempMin, maxMonthlyTempC=tempMax,				meanMonthlyPPTcm=ppt, MAP_cm=sum(ppt), MAT_C=mean(mat))	if(do.C4vars){		res$dailyTempMin <- dailyTempMin		res$dailyTempMean <- dailyTempMean		res$dailyC4vars <- sw_dailyC4_TempVar(dailyTempMin, dailyTempMean, simTime2)	}	return(res)}PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996 <- function(MAP_mm,MAT_C,monthly.ppt,monthly.temp,dailyC4vars,isNorth,shrub.fraction.limit,		use_Annuals_Fraction,Annuals_Fraction,		use_C4_Fraction,C4_Fraction,		use_C3_Fraction,C3_Fraction,		use_Shrubs_Fraction,Shrubs_Fraction,		use_Forbs_Fraction, Forbs_Fraction,		use_BareGround_Fraction, BareGround_Fraction) {	cut0Inf <- function(x) {x[x < 0] <- NA; return(x)}	NAto0 <- function(x) {x[is.na(x)] <- 0; return(x)}	finite01 <- function(x) {x[x < 0 | is.na(x)] <- 0; x[x > 1] <- 1; return(x)}	f.digits <- 3	tolerance <- 1.1*10^-f.digits	#Get the user specified fractions, if column is false set to NA	tree.fraction <- 0 #option 'PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996' doesn't estimate tree cover, i.e., assumed to be == 0	forb.fraction <- 0	bareGround.fraction <- 0	AnnC4C3ShrubForbBareGroundFraction <- rep(NA, 6)	if(use_Annuals_Fraction){		AnnC4C3ShrubForbBareGroundFraction[1] <- finite01(Annuals_Fraction)	} else {		AnnC4C3ShrubForbBareGroundFraction[1] <- 0 #Annuals can not be NA	}	if(use_C4_Fraction)		AnnC4C3ShrubForbBareGroundFraction[2] <- C4_Fraction	if(use_C3_Fraction)		AnnC4C3ShrubForbBareGroundFraction[3] <- C3_Fraction	if(use_Shrubs_Fraction)		AnnC4C3ShrubForbBareGroundFraction[4] <- Shrubs_Fraction	if(use_Forbs_Fraction) {		AnnC4C3ShrubForbBareGroundFraction[5] <- finite01(Forbs_Fraction)	} else {		AnnC4C3ShrubForbBareGroundFraction[5] <- forb.fraction	}	if(use_BareGround_Fraction) {		AnnC4C3ShrubForbBareGroundFraction[6] <- finite01(BareGround_Fraction)	} else {		AnnC4C3ShrubForbBareGroundFraction[6] <- bareGround.fraction	}	AnnC4C3ShrubForbBareGroundFraction <- cut0Inf(AnnC4C3ShrubForbBareGroundFraction) #treat negatives as if NA	TotalFraction <- sum(AnnC4C3ShrubForbBareGroundFraction, na.rm=TRUE)	#Decide if all fractions are sufficiently defined or if they need to be calculated based on climate variables	if(!isTRUE(all.equal(TotalFraction, 1, tolerance=tolerance)) && TotalFraction < 1 && sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) == 0) {		stop(print(paste(i, " run: User defined fractions of Shrub, C3, C4, Annuals are all set, but less than 1", sep=""))) #throw an error	}	if(isTRUE(all.equal(TotalFraction, 1, tolerance=tolerance)) || TotalFraction > 1 || sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) == 1){		if(sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) == 1){ #if only one is NA, then this can be calculated			AnnC4C3ShrubForbBareGroundFraction[which(is.na(AnnC4C3ShrubForbBareGroundFraction))] <- cut0Inf(1 - TotalFraction)		} else {			AnnC4C3ShrubForbBareGroundFraction <- finite01(AnnC4C3ShrubForbBareGroundFraction) #the composition is >= 1, so set eventually remaining NA to 0		}		TotalFraction <- sum(AnnC4C3ShrubForbBareGroundFraction, na.rm=TRUE)		AnnC4C3ShrubForbBareGroundFraction <- AnnC4C3ShrubForbBareGroundFraction / TotalFraction #Rescale, in case it is needed	} else { #i.e., (TotalFraction < 1 && sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) > 1) is TRUE; thus, calculate some fractions based on climate variables		if(isNorth){ #Northern hemisphere			Months_WinterTF <- c(12, 1:2)			Months_SummerTF <- c(6:8)		} else {			Months_WinterTF <- c(6:8)			Months_SummerTF <- c(12, 1:2)		}		ppt.SummerToMAP <- sum(monthly.ppt[Months_SummerTF]) / MAP_mm		ppt.WinterToMAP <- sum(monthly.ppt[Months_WinterTF]) / MAP_mm		#---Potential natural vegetation		#1. step: Paruelo JM, Lauenroth WK (1996) Relative abundance of plant functional types in grasslands and shrublands of North America. Ecological Applications, 6, 1212-1224.		if(MAP_mm < 1){			shrubs.fractionNA <- NA		} else {			shrubs.fractionNA <- cut0Inf(1.7105 - 0.2918 * log(MAP_mm) + 1.5451 * ppt.WinterToMAP) 								#if NA, then not enough winter precipitation above a given MAP		}		if(MAT_C <= 0){			grass.c4.fractionNA <- 0		} else {			grass.c4.fractionNA <- cut0Inf(-0.9837 + 0.000594 * MAP_mm + 1.3528 * ppt.SummerToMAP + 0.2710 * log(MAT_C))			#if NA, then either MAT < 0 or not enough summer precipitation or too cold below a given MAP		}		if(ppt.WinterToMAP <= 0){			grass.c3ingrasslands.fractionNA <- grass.c3inshrublands.fractionNA <- NA		} else {			grass.c3ingrasslands.fractionNA <- cut0Inf(1.1905 - 0.02909 * MAT_C + 0.1781 * log(ppt.WinterToMAP) - 0.2383 * 1)		#if NA, then not enough winter precipitation or too warm below a given MAP			grass.c3inshrublands.fractionNA <- cut0Inf(1.1905 - 0.02909 * MAT_C + 0.1781 * log(ppt.WinterToMAP) - 0.2383 * 2)		}		grass.c3.fractionNA <- ifelse(shrubs.fractionNA >= shrub.fraction.limit && !is.na(shrubs.fractionNA), grass.c3inshrublands.fractionNA, grass.c3ingrasslands.fractionNA)		grass.Annual.fraction <- AnnC4C3ShrubForbBareGroundFraction[1] #Ann will be 0 or something <= 1		#2. step: Teeri JA, Stowe LG (1976) Climatic patterns and the distribution of C4 grasses in North America. Oecologia, 23, 1-12.		#This equations give percent species/vegetation -> use to limit Paruelo's C4 equation, i.e., where no C4 species => there are no C4 abundance > 0		if(dailyC4vars["LengthFreezeFreeGrowingPeriod_NSadj_Days"] <= 0){			grass.c4.species <- 0		} else {			x10 <- dailyC4vars["Month7th_NSadj_MinTemp_C"] * 9/5 + 32			x13 <- dailyC4vars["DegreeDaysAbove65F_NSadj_DaysC"] * 9/5			x18 <- log(dailyC4vars["LengthFreezeFreeGrowingPeriod_NSadj_Days"])			grass.c4.species <- as.numeric((1.60 * x10 + 0.0086 * x13 - 8.98 * x18 - 22.44) / 100)		}		grass.c4.fractionNA <- ifelse(grass.c4.species >= 0, grass.c4.fractionNA, NA)		#3. step: Replacing missing values: If no or only one successful equation, then add 100% C3 if MAT < 10 C, 100% shrubs if MAP < 600 mm, and 100% C4 if MAT >= 10C & MAP >= 600 mm	[these rules are made up arbitrarily by drs, Nov 2012]		if(sum(!is.na(shrubs.fractionNA), !is.na(grass.c4.fractionNA), !is.na(grass.c3.fractionNA)) <= 1){			if(MAP_mm < 600) shrubs.fractionNA <- 1 + ifelse(is.na(shrubs.fractionNA), 0, shrubs.fractionNA)			if(MAT_C < 10)  grass.c3.fractionNA <- 1 + ifelse(is.na(grass.c3.fractionNA), 0, grass.c3.fractionNA)			if(MAT_C >= 10  & MAP_mm >= 600)  grass.c4.fractionNA <- 1 + ifelse(is.na(grass.c4.fractionNA), 0, grass.c4.fractionNA)		}		#4. step: Scale fractions to 0-1 with a sum of 1 including grass.Annual.fraction, but don't scale grass.Annual.fraction		#if na then use calc fraction else use the user defined fraction		shrubs.fraction <- NAto0(shrubs.fractionNA)		grass.c4.fraction <- NAto0(grass.c4.fractionNA)		grass.c3.fraction <- NAto0(grass.c3.fractionNA)		sumVegWithoutAnnuals <- shrubs.fraction + grass.c4.fraction + grass.c3.fraction		shrubs.fraction <- (shrubs.fraction / sumVegWithoutAnnuals) * (1 - grass.Annual.fraction) #scale these down to 1-annual fraction		grass.c4.fraction <- (grass.c4.fraction / sumVegWithoutAnnuals) * (1 - grass.Annual.fraction)		grass.c3.fraction <- (grass.c3.fraction / sumVegWithoutAnnuals) * (1 - grass.Annual.fraction)		calcAnnC4C3ShrubForbBareGroundFraction <- c(grass.Annual.fraction, grass.c4.fraction, grass.c3.fraction, shrubs.fraction)		naIndex <- which(is.na(AnnC4C3ShrubForbBareGroundFraction))		#replace missing values		if(isTRUE(all.equal(sum(calcAnnC4C3ShrubForbBareGroundFraction[naIndex]), 0)) && isTRUE(all.equal(temp <- sum(AnnC4C3ShrubForbBareGroundFraction[!naIndex]), 0))){ #there would be no vegetation, so force vegetation > 0			AnnC4C3ShrubForbBareGroundFraction[naIndex] <- (1 - temp) / length(naIndex)		} else {			AnnC4C3ShrubForbBareGroundFraction[naIndex] <- calcAnnC4C3ShrubForbBareGroundFraction[naIndex]		}		#now we need to get the sum and scale the naIndex values accordingly		AnnC4C3ShrubForbBareGroundFraction[naIndex] <- sapply(AnnC4C3ShrubForbBareGroundFraction[naIndex], function(x) (x/sum(AnnC4C3ShrubForbBareGroundFraction[naIndex])) * (1-sum(AnnC4C3ShrubForbBareGroundFraction[-naIndex])))	}	#Scale Grass components to one (or set to 0)	if(!isTRUE(all.equal(sum(AnnC4C3ShrubForbBareGroundFraction[4:6]), 1))){		grass.c4.fractionG <- AnnC4C3ShrubForbBareGroundFraction[2] / (1-sum(AnnC4C3ShrubForbBareGroundFraction[4:6]))		grass.c3.fractionG <- AnnC4C3ShrubForbBareGroundFraction[3] / (1-sum(AnnC4C3ShrubForbBareGroundFraction[4:6]))		grass.Annual.fractionG <- AnnC4C3ShrubForbBareGroundFraction[1] / (1-sum(AnnC4C3ShrubForbBareGroundFraction[4:6]))	} else {		grass.c4.fractionG <- grass.c3.fractionG <- grass.Annual.fractionG <- 0	}	grass.fraction <- sum(AnnC4C3ShrubForbBareGroundFraction[c(1:3)])	return(list("Composition"=c("Grasses"=grass.fraction, "Shrubs"=AnnC4C3ShrubForbBareGroundFraction[4], "Trees"=tree.fraction, "Forbs"=AnnC4C3ShrubForbBareGroundFraction[5], "BareGround"=AnnC4C3ShrubForbBareGroundFraction[6]),"grasses.c3c4ann.fractions"=c(grass.c3.fractionG,grass.c4.fractionG,grass.Annual.fractionG)))}AdjMonthlyBioMass <- function(tr_VegetationComposition,AdjMonthlyBioMass_Temperature,AdjMonthlyBioMass_Precipitation,grasses.c3c4ann.fractions,growing.season.threshold.tempC,isNorth,MAP_mm,monthly.temp) {	tr_VegComp_Adj <- tr_VegetationComposition	#Default shrub biomass input is at MAP = 450 mm/yr, and default grass biomass input is at MAP = 340 mm/yr	#Describe conditions for which the default vegetation biomass values are valid	std.winter <- c(11:12, 1:2) #Assumes that the "growing season" (valid for growing.season.threshold.tempC == 4) in 'tr_VegetationComposition' starts in March and ends after October, for all functional groups.	std.growing <- st_mo[-std.winter] #Assumes that the "growing season" in 'tr_VegetationComposition' starts in March and ends after October, for all functional groups.	#Default site for the grass description is SGS LTER	StandardGrasses_MAP_mm <- 340	StandardGrasses_VegComposition <- c(0.12, 0.22, 0.66) #Fraction of shrubs, C3, and C4	#Default site for the shrub description is Reynolds Creek, ID	StandardShrub_MAP_mm <- 250	StandardShrub_VegComposition <- c(0.7, 0.3, 0) #Fraction of shrubs, C3, and C4	#Calculate 'live biomass amount'	tr_VegComp_Adj$Sh.Amount.Live <- tr_VegComp_Adj$Sh.Biomass * tr_VegComp_Adj$Sh.Perc.Live	tr_VegComp_Adj$C3.Amount.Live <- tr_VegComp_Adj$C3.Biomass * tr_VegComp_Adj$C3.Perc.Live	tr_VegComp_Adj$C4.Amount.Live <- tr_VegComp_Adj$C4.Biomass * tr_VegComp_Adj$C4.Perc.Live	tr_VegComp_Adj$Annual.Amount.Live <- tr_VegComp_Adj$Annual.Biomass * tr_VegComp_Adj$Annual.Perc.Live	#Scale monthly values of litter and live biomass amount by column-max; total biomass will be back calculated from 'live biomass amount' / 'percent live'	colmax <- apply(tr_VegComp_Adj[, itemp <- grepl("Litter", names(tr_VegComp_Adj)) | grepl("Amount.Live", names(tr_VegComp_Adj))], MARGIN=2, FUN=max)	colmin <- apply(tr_VegComp_Adj[, itemp], MARGIN=2, FUN=min)	tr_VegComp_Adj[, itemp] <- sweep(tr_VegComp_Adj[, itemp], MARGIN=2, STATS=colmax, FUN="/")	#Pull different composition types	shrubs_Composition <- shrubs_Standard <- tr_VegComp_Adj[, grepl("Sh", names(tr_VegComp_Adj))]	C3_Composition <- C3_Standard <- tr_VegComp_Adj[, grepl("C3", names(tr_VegComp_Adj))]	C4_Composition <- C4_Standard <- tr_VegComp_Adj[, grepl("C4", names(tr_VegComp_Adj))]	AnnGrass_Composition <- AnnGrass_Standard <- tr_VegComp_Adj[, grepl("Annual", names(tr_VegComp_Adj))]	adjCompPPT <- function(shrubs_Composition, C3_Composition, C4_Composition, AnnGrass_Composition, ShrubsMAP_mm, GrassMAP_mm) {		#Equations: Milchunas & Lauenroth 1993 (Fig. 2): Y [g/m2/yr] = c1 * MAP [mm/yr] + c2		Shrub_ANPP <- function(MAP_mm) 0.393 * MAP_mm - 10.2		Grass_ANPP <- function(MAP_mm) 0.646 * MAP_mm - 102.5		#Intercepts to match outcomes of M & L 1993 equations under 'default' MAP with our previous default inputs for shrubs and sgs-grasslands		#Whereas these intercepts were introduced artificially, they could also be interpreted as perennial storage, e.g., Lauenroth & Whitman (1977) found "Accumulation in the standing dead was 63% of inputs, in the litter 8%, and belowground 37%.". Lauenroth, W.K. & Whitman, W.C. (1977) Dynamics of dry matter production in a mixed-grass prairie in western North Dakota. Oecologia, 27, 339-351.		Shrub_ANPPintercept <- (StandardShrub_VegComposition[1]*colmax["Sh.Amount.Live"] + StandardShrub_VegComposition[2]*colmax["C3.Amount.Live"] + StandardShrub_VegComposition[3]*colmax["C4.Amount.Live"]) - Shrub_ANPP(StandardShrub_MAP_mm)	#Default input for shrubs (IM_USC00107648_Reynolds; 70% shrubs, 30% C3): biomass was estimated at MAP = 450 mm/yr		Grasses_ANPPintercept <- (StandardGrasses_VegComposition[1]*colmax["Sh.Amount.Live"] + StandardGrasses_VegComposition[2]*colmax["C3.Amount.Live"] + StandardGrasses_VegComposition[3]*colmax["C4.Amount.Live"]) - Grass_ANPP(StandardGrasses_MAP_mm)		#Default input for sgs-grassland (GP_SGSLTER; 12% shrubs, 22% C3, and 66% C4): biomass was estimated at MAP = 340 mm/yr		#Get scaling values for scaled biomass; guarantee that > minimum.totalBiomass		minimum.totalBiomass <- 0 #This is a SoilWat parameter		Shrub_BiomassScaler <- max(minimum.totalBiomass, Shrub_ANPP(ShrubsMAP_mm) + Shrub_ANPPintercept)		Grass_BiomassScaler <- max(minimum.totalBiomass, Grass_ANPP(GrassMAP_mm) + Grasses_ANPPintercept)		#Scale live biomass amount by productivity; assumption: ANPP = peak standing live biomass		shrubs_Composition$Sh.Amount.Live <- shrubs_Composition$Sh.Amount.Live * Shrub_BiomassScaler		C3_Composition$C3.Amount.Live <- C3_Composition$C3.Amount.Live * Grass_BiomassScaler		C4_Composition$C4.Amount.Live <- C4_Composition$C4.Amount.Live * Grass_BiomassScaler		AnnGrass_Composition$Annual.Amount.Live <- AnnGrass_Composition$Annual.Amount.Live * Grass_BiomassScaler		#Scale litter amount by productivity and adjust for ratio of litter/live		shrubs_Composition$Sh.Litter <- shrubs_Composition$Sh.Litter * Shrub_BiomassScaler * colmax["Sh.Litter"] / colmax["Sh.Amount.Live"]		C3_Composition$C3.Litter <- C3_Composition$C3.Litter * Grass_BiomassScaler * colmax["C3.Litter"] / colmax["C3.Amount.Live"]		C4_Composition$C4.Litter <- C4_Composition$C4.Litter * Grass_BiomassScaler * colmax["C4.Litter"] / colmax["C4.Amount.Live"]		AnnGrass_Composition$Annual.Litter <- AnnGrass_Composition$Annual.Litter * Grass_BiomassScaler * colmax["Annual.Litter"] / colmax["Annual.Amount.Live"]		#Guarantee that live fraction = ]0, 1]		shrubs_Composition$Sh.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), shrubs_Composition$Sh.Perc.Live))		C3_Composition$C3.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), C3_Composition$C3.Perc.Live))		C4_Composition$C4.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), C4_Composition$C4.Perc.Live))		AnnGrass_Composition$Annual.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), AnnGrass_Composition$Annual.Perc.Live))		#Calculate total biomass based on scaled live biomass amount		shrubs_Composition$Sh.Biomass <- shrubs_Composition$Sh.Amount.Live / shrubs_Composition$Sh.Perc.Live		C3_Composition$C3.Biomass <- C3_Composition$C3.Amount.Live / C3_Composition$C3.Perc.Live		C4_Composition$C4.Biomass <- C4_Composition$C4.Amount.Live / C4_Composition$C4.Perc.Live		AnnGrass_Composition$Annual.Biomass <- AnnGrass_Composition$Annual.Amount.Live / AnnGrass_Composition$Annual.Perc.Live		return(list("shrubs_Composition"=shrubs_Composition,"C3_Composition"=C3_Composition,"C4_Composition"=C4_Composition,"AnnGrass_Composition"=AnnGrass_Composition))	}	#adjust phenology for mean monthly temperatures	if(AdjMonthlyBioMass_Temperature) {		growing.season <- monthly.temp >= growing.season.threshold.tempC		if(!isNorth) growing.season <- c(growing.season[7:12], growing.season[1:6]) #Standard growing season needs to be adjusted for southern Hemi		predict.season <- function(biomass_Standard, std.season.padded, std.season.seq, site.season.seq){			#length(std.season.seq) >= 3 because of padding and test that season duration > 0			calc.loess_coeff <- function(N, span){				#prevent call to loessc.c:ehg182(104): "span too small.   fewer data values than degrees of freedom"				lcoef <- list(span=min(1, span), degree=2)				if(span > 1) return(lcoef)				nf <- floor(lcoef$span * N) - 1 #see R/trunk/src/library/stats/src/loessf.f:ehg136()				if(nf > 2){					lcoef$degree <- 2				} else if(nf > 1){					lcoef$degree <- 1				} else {					lcoef <- calc.loess_coeff(N, lcoef$span+0.1)				}				return(lcoef)			}			lcoef <- calc.loess_coeff(N=length(std.season.seq), span=0.4)			op <- options(c("warn", "error"))			options(warn=-1, error=traceback) #loess throws many warnings: 'pseudoinverse used', see calc.loess_coeff(), etc.			res <- sapply(apply(biomass_Standard, MARGIN=2, function(x) {lf<-loess(x[std.season.padded] ~ std.season.seq, span=lcoef$span, degree=lcoef$degree); predict(lf, newdata=data.frame(std.season.seq=site.season.seq) ) }), FUN=function(x) max(0, x)) # guarantee that > 0			options(op)			return(res)		}		#Adjust for timing and duration of non-growing season		if(sum(!growing.season) > 0) {			if(sum(!growing.season) < 12) {				std.winter.padded <- (c(std.winter[1] - 1, std.winter, std.winter[length(std.winter)] + 1) - 1) %% 12 + 1				std.winter.seq <- 0:(length(std.winter.padded) - 1)				site.winter.seq <- seq(from=1, to=length(std.winter), length=sum(!growing.season))				site.winter.start <- (temp3 <- (temp2 <- cumsum(c(0, (rtemp <- rle(!growing.season))$lengths))+1)[-length(temp2)][rtemp$values])[length(temp3)] #Calculate first month of winter				site.winter.months <- (site.winter.start + 1:sum(!growing.season) - 2) %% 12 + 1				shrubs_Composition[site.winter.months,] <- predict.season(shrubs_Standard, std.winter.padded, std.winter.seq, site.winter.seq)				C3_Composition[site.winter.months,] <- predict.season(C3_Standard, std.winter.padded, std.winter.seq, site.winter.seq)				C4_Composition[site.winter.months,] <- predict.season(C4_Standard, std.winter.padded, std.winter.seq, site.winter.seq)				AnnGrass_Composition[site.winter.months,] <- predict.season(AnnGrass_Standard, std.winter.padded, std.winter.seq, site.winter.seq)			} else { #if winter lasts 12 months				#Take the mean of the winter months				shrubs_Composition[] <- matrix(apply(shrubs_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(shrubs_Composition), byrow=TRUE)				C3_Composition[] <- matrix(apply(C3_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(C3_Composition), byrow=TRUE)				C4_Composition[] <- matrix(apply(C4_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(C4_Composition), byrow=TRUE)				AnnGrass_Composition[] <- matrix(apply(AnnGrass_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(AnnGrass_Composition), byrow=TRUE)			}		}		#Adjust for timing and duration of growing season		if(sum(growing.season)>0) {			if(sum(growing.season) < 12) {				std.growing.padded <- (c(std.growing[1] - 1, std.growing, std.growing[length(std.growing)] + 1) - 1) %% 12 + 1				std.growing.seq <- 0:(length(std.growing.padded) - 1)				site.growing.seq <- seq(from=1, to=length(std.growing), length=sum(growing.season))				site.growing.start <- (temp3 <- (temp2 <- cumsum(c(0, (rtemp <- rle(growing.season))$lengths))+1)[-length(temp2)][rtemp$values])[1] #Calculate first month of growing season				site.growing.months <- (site.growing.start + 1:sum(growing.season) - 2) %% 12 + 1				shrubs_Composition[site.growing.months,] <- predict.season(shrubs_Standard, std.growing.padded, std.growing.seq, site.growing.seq)				C3_Composition[site.growing.months,] <- predict.season(C3_Standard, std.growing.padded, std.growing.seq, site.growing.seq)				C4_Composition[site.growing.months,] <- predict.season(C4_Standard, std.growing.padded, std.growing.seq, site.growing.seq)				AnnGrass_Composition[site.growing.months,] <- predict.season(AnnGrass_Standard, std.growing.padded, std.growing.seq, site.growing.seq)			} else { #if growing season lasts 12 months				shrubs_Composition[] <- matrix(apply(shrubs_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(shrubs_Composition), byrow=TRUE)				C3_Composition[] <- matrix(apply(C3_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(C3_Composition), byrow=TRUE)				C4_Composition[] <- matrix(apply(C4_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(C4_Composition), byrow=TRUE)				AnnGrass_Composition[] <- matrix(apply(AnnGrass_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(AnnGrass_Composition), byrow=TRUE)			}		}		if(!isNorth) { #Adjustements were done as if on nothern hemisphere			shrubs_Composition <- rbind(shrubs_Composition[7:12,], shrubs_Composition[1:6,])			C3_Composition <- rbind(C3_Composition[7:12,], C3_Composition[1:6,])			C4_Composition <- rbind(C4_Composition[7:12,], C4_Composition[1:6,])			AnnGrass_Composition <- rbind(AnnGrass_Composition[7:12,], AnnGrass_Composition[1:6,])		}		if(!AdjMonthlyBioMass_Precipitation){			temp<-adjCompPPT(shrubs_Composition,C3_Composition,C4_Composition,AnnGrass_Composition,ShrubsMAP_mm=StandardShrub_MAP_mm, GrassMAP_mm=StandardGrasses_MAP_mm)			shrubs_Composition <- temp$shrubs_Composition			C3_Composition <- temp$C3_Composition			C4_Composition <- temp$C4_Composition			AnnGrass_Composition <- temp$AnnGrass_Composition		}	}	#Adjust biomass amounts by productivity relationship with MAP	if(AdjMonthlyBioMass_Precipitation) {		temp<-adjCompPPT(shrubs_Composition,C3_Composition,C4_Composition,AnnGrass_Composition,ShrubsMAP_mm=MAP_mm, GrassMAP_mm=MAP_mm)		shrubs_Composition <- temp$shrubs_Composition		C3_Composition <- temp$C3_Composition		C4_Composition <- temp$C4_Composition		AnnGrass_Composition <- temp$AnnGrass_Composition	}	Grass_Composition <- C3_Composition*grasses.c3c4ann.fractions[1] + C4_Composition*grasses.c3c4ann.fractions[2] + AnnGrass_Composition*grasses.c3c4ann.fractions[3]	return(list("grass"=as.matrix(Grass_Composition),"shrub"=as.matrix(shrubs_Composition)))}#Circular functions: int=number of units in circle, e.g., for days: int=365; for months: int=12circ.mean <- function(x, int, na.rm=FALSE){	if(length(x) == sum(is.na(x))){		return(NA)	} else {		require(circular)		circ <- 2 * pi / int		x.circ <- circular(x * circ, type="angles", units="radians", rotation="clock", modulo="2pi")		x.int <- mean.circular(x.circ, na.rm=na.rm) / circ		rm(circ, x.circ)		return(round(as.numeric(x.int) - 1, 13) %% int + 1)	# map 0 -> int; rounding to 13 digits: 13 was empirically derived for int={12, 365} and x=c((-1):2, seq(x-5, x+5, by=1), seq(2*x-5, 2*x+5, by=1)) assuming that this function will never need to calculate for x > t*int with t>2	}}circ.range <- function(x, int, na.rm=FALSE) {	if(length(x) == sum(is.na(x))){		return(NA)	} else {		require(circular)		circ <- 2 * pi / int		x.circ <- circular(x * circ, type="angles", units="radians", rotation="clock", modulo="2pi")		x.int <- range(x.circ, na.rm=na.rm) / circ		rm(circ, x.circ)		return(as.numeric(x.int))	}}circ.sd <- function(x, int, na.rm=FALSE){	if(length(x) == sum(is.na(x)) || sum(!is.na(x)) == 1){		return(NA)	} else if(sd(x, na.rm=TRUE) == 0){		return(0)	} else {		require(circular)		circ <- 2 * pi / int		x.circ <- circular(x * circ, type="angles", units="radians", rotation="clock", modulo="2pi")		x.int <- sd.circular(x.circ, na.rm=na.rm) / circ		rm(circ, x.circ)		return(as.numeric(x.int))	}}#functions wet and dry periodsmax.duration <- function(x) {	r <- rle(x)	if(length(temp <- which(r$values==1)) > 0){		rmax <- max(r$lengths[temp])	} else {		rmax <- 0	}	return(rmax)}startDoyOfDuration <- function(x, duration=10) {	r <- rle(x)	if(length(r$lengths)==1 | sum(r$values==1 & r$lengths>=duration)==0 ){		return (ifelse((length(r$lengths)==1 & (r$values==0 | r$lengths<duration)) | sum(r$values==1 & r$lengths>=10)==0, NA, 1)[1])	} else {		first10dry <- r$lengths[which(r$values==1 & r$lengths>=duration)][1] #pick first period		if( !is.na(first10dry) ){			ind <- which(r$lengths==first10dry & r$values==1)[1] #always pick start of first suitable period		} else {			ind <- -1		}		if(ind==1) {#start of period at beginning of year			return(1)		} else if(ind==-1) {#no period this year			return(NA)		} else {			return(cumsum(r$lengths)[ind-1]+1)		}	}}endDoyAfterDuration <- function(x, duration=10) {	r <- rle(x)	if(length(r$lengths)==1 | sum(r$values==1 & r$lengths>=duration)==0 ){		return (ifelse((length(r$lengths)==1 & (r$values==0 | r$lengths<duration)) | sum(r$values==1 & r$lengths>=duration)==0, 365, NA)[1])	} else {		last10dry <- (rl <- r$lengths[which(r$values==1 & r$lengths>=duration)])[length(rl)] #pick last period		if( length(last10dry) > 0 ){			ind <- (temp <- which(r$lengths==last10dry & r$values==1))[length(temp)]	#always pick end of last suitable period		} else {			ind <- -1		}		if(ind==-1) {#no period this year			return(NA)		} else {			return(cumsum(r$lengths)[ind])		}	}}#convert SWP(matric) to VWC(matric), e.g., to calculate field capacity and wilting pointSWPtoVWC <- function(swp, sand, clay) {#Cosby, B. J., G. M. Hornberger, R. B. Clapp, and T. R. Ginn. 1984. A statistical exploration of the relationships of soil moisture characteristics to the physical properties of soils. Water Resources Research 20:682-690.	#1. SWP in MPa [single value] + sand and clay in fraction [single values] --> VWC in fraction [single value]	#2. SWP in MPa [single value] + sand and clay in fraction [vectors of length d] --> VWC in fraction [vector of length d]	#3. SWP in MPa [vector of length l] + sand and clay in fraction [single values] --> VWC in fraction [vector of length l]	#4. SWP in MPa [vector of length l] + sand and clay in fraction [vectors of length d] --> VWC in fraction [matrix with nrow=l and ncol=d, SWP vector repeated for each column]: probably not used	#5. SWP in MPa [matrix with nrow=l and ncol=d] + sand and clay in fraction [single values] --> VWC in fraction [matrix with nrow=l and ncol=d]	#6. SWP in MPa [matrix with nrow=l and ncol=d] + sand and clay in fraction [vectors of length d] --> VWC in fraction [matrix with nrow=l and ncol=d, sand/clay vector repeated for each row]#input: sand and clay as fraction of matric volume, i.e, they don't need to be scaled with gravel	stopifnot(length(sand) && length(sand) == length(clay))	na.act <- na.action(na.exclude(apply(data.frame(sand, clay), MARGIN=1, FUN=sum)))	if(length(sand) > length(na.act)){		na.index <- as.vector(na.act)		if(length(na.index) > 0){			sand <- sand[-na.index]			clay <- clay[-na.index]		}		thetas <- -14.2 * sand - 3.7 * clay + 50.5		psis <- 10 ^ (-1.58 * sand - 0.63 * clay + 2.17)		b <- -0.3 * sand + 15.7 * clay + 3.10		if(any(b <= 0)) stop("b <= 0")		bar_conversion <- 1024		MPa_toBar <- -10		get_vector <- function(swp, sand, clay, thetas=thetas, psis=psis, b=b, do.na=TRUE){#either swp or sand/clay needs be a single value			vwc <- ifelse(!is.na(swp) & swp <= 0 & sand <= 1 & sand >= 0 & clay <= 1 & clay >= 0, thetas * (psis / (swp * MPa_toBar * bar_conversion))^(1/b) / 100, NA)			if(do.na & length(na.index) > 0){				vwc <- napredict(na.act, vwc)			}			return(vwc)		}		if(is.null(dim(swp))){			if(length(swp) == 1 & length(sand) >= 1 | length(swp) >= 1 & length(sand) == 1){ #cases 1-3				vwc <- get_vector(swp, sand, clay, thetas=thetas, psis=psis, b=b)			} else if(length(swp) > 1 & length(sand) > 1){ #case 4				vwc <- t(sapply(1:length(swp), FUN=function(d) get_vector(swp[d], sand, clay, thetas=thetas, psis=psis, b=b)))			}		} else {			if(length(sand) == 1){ #case 5				vwc <- sapply(1:ncol(swp), FUN=function(d) get_vector(swp[, d], sand, clay, thetas=thetas, psis=psis, b=b))			} else { #case 6				sand <- napredict(na.act, sand)				clay <- napredict(na.act, clay)				stopifnot(ncol(swp) == length(sand))				psis <- napredict(na.act, psis)				thetas <- napredict(na.act, thetas)				b <- napredict(na.act, b)				vwc <- sapply(1:ncol(swp), FUN=function(d) get_vector(swp[, d], sand[d], clay[d], thetas=thetas[d], psis=psis[d], b=b[d], do.na=FALSE))			}		}	} else {		vwc <- swp		vwc[!is.na(vwc)] <- NA	}	return(vwc) #fraction m3/m3 [0, 1]}#convert VWC(matric) to SWP(matric)VWCtoSWP <- function(vwc, sand, clay) {#Cosby, B. J., G. M. Hornberger, R. B. Clapp, and T. R. Ginn. 1984. A statistical exploration of the relationships of soil moisture characteristics to the physical properties of soils. Water Resources Research 20:682-690.	#1. VWC in fraction [single value] + sand and clay in fraction [single values] --> SWP in MPa [single value]	#2. VWC in fraction [single value] + sand and clay in fraction [vectors of length d] --> SWP in MPa [vector of length d]	#3. VWC in fraction [vector of length l] + sand and clay in fraction [single values] --> SWP in MPa [vector of length l]	#4. VWC in fraction [vector of length l] + sand and clay in fraction [vectors of length d] --> SWP in MPa [matrix with nrow=l and ncol=d, VWC vector repeated for each column]: probably not used	#5. VWC in fraction [matrix with nrow=l and ncol=d] + sand and clay in fraction [single values] --> SWP in MPa [matrix with nrow=l and ncol=d]	#6. VWC in fraction [matrix with nrow=l and ncol=d] + sand and clay in fraction [vectors of length d] --> SWP in MPa [matrix with nrow=l and ncol=d, sand/clay vector repeated for each row]#input: sand and clay as fraction of matric volume, i.e, they don't need to be scaled with gravel	stopifnot(length(sand) && length(sand) == length(clay))	na.act <- na.action(na.exclude(apply(data.frame(sand, clay), MARGIN=1, FUN=sum)))	if(length(sand) > length(na.act)){		na.index <- as.vector(na.act)		if(length(na.index) > 0){			sand <- sand[-na.index]			clay <- clay[-na.index]		}		thetas <- -14.2 * sand - 3.7 * clay + 50.5		psis <- 10 ^ (-1.58 * sand - 0.63 * clay + 2.17)		b <- -0.3 * sand + 15.7 * clay + 3.10		if(any(b <= 0)) stop("b <= 0")		bar_conversion <- 1024		bar_toMPa <- -1/10		get_vector <- function(vwc, sand, clay, thetas=thetas, psis=psis, b=b, do.na=TRUE){#either vwc or sand/clay needs be a single value			swp <- ifelse(!is.na(vwc) & vwc <= 1 & vwc >= 0 & sand <= 1 & sand >= 0 & clay <= 1 & clay >= 0, psis / ((vwc*100/thetas) ^ b * bar_conversion) * bar_toMPa, NA)			if(do.na & length(na.index) > 0){				swp <- napredict(na.act, swp)			}			return(swp)		}		if(is.null(dim(vwc))){			if(length(vwc) == 1 & length(sand) >= 1 | length(vwc) >= 1 & length(sand) == 1){ #cases 1-3				swp <- get_vector(vwc, sand, clay, thetas=thetas, psis=psis, b=b)			} else if(length(vwc) > 1 & length(sand) > 1){ #case 4				swp <- t(sapply(1:length(vwc), FUN=function(d) get_vector(vwc[d], sand, clay, thetas=thetas, psis=psis, b=b)))			}		} else {			if(length(sand) == 1){ #case 5				swp <- sapply(1:ncol(vwc), FUN=function(d) get_vector(vwc[, d], sand, clay, thetas=thetas, psis=psis, b=b))			} else { #case 6				sand <- napredict(na.act, sand)				clay <- napredict(na.act, clay)				stopifnot(ncol(vwc) == length(sand))				psis <- napredict(na.act, psis)				thetas <- napredict(na.act, thetas)				b <- napredict(na.act, b)				swp <- sapply(1:ncol(vwc), FUN=function(d) get_vector(vwc[, d], sand[d], clay[d], thetas=thetas[d], psis=psis[d], b=b[d], do.na=FALSE))			}		}	} else {		swp <- vwc		swp[!is.na(swp)] <- NA	}	return(swp) #MPa [-Inf, 0]}#two, three, or four layer aggregation for average daily aggregation outputsetAggSoilLayerForAggDailyResponses <- function(layers_depth){	d <- length(layers_depth)	vals <- list()	#first layer	DeepestFirstDailyAggLayer <- findInterval(Depth_FirstAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)	vals[[1]] <- 1:DeepestFirstDailyAggLayer	#second layer	if(!is.null(Depth_SecondAggLayer.daily)){		DeepestSecondDailyAggLayer <- findInterval(Depth_SecondAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)	} else {		DeepestSecondDailyAggLayer <- d	}	if(is.numeric(DeepestSecondDailyAggLayer) && is.numeric(DeepestFirstDailyAggLayer) && d > DeepestFirstDailyAggLayer){		vals[[2]] <- (DeepestFirstDailyAggLayer+1):DeepestSecondDailyAggLayer	}	#third layer	if(!is.null(Depth_ThirdAggLayer.daily)){		if(!is.na(Depth_ThirdAggLayer.daily)){			DeepestThirdDailyAggLayer <- findInterval(Depth_ThirdAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)		} else {			DeepestThirdDailyAggLayer <- NULL		}	} else {		DeepestThirdDailyAggLayer <- d	}	if(is.numeric(DeepestThirdDailyAggLayer) && is.numeric(DeepestSecondDailyAggLayer) && d > DeepestSecondDailyAggLayer){		vals[[3]] <- (DeepestSecondDailyAggLayer+1):DeepestThirdDailyAggLayer	}	#fourth layer	if(!is.null(Depth_FourthAggLayer.daily)){		if(!is.na(Depth_FourthAggLayer.daily)){			DeepestFourthDailyAggLayer <- findInterval(Depth_FourthAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)		} else {			DeepestFourthDailyAggLayer <- NULL		}	} else {		DeepestFourthDailyAggLayer <- d	}	if(is.numeric(DeepestFourthDailyAggLayer) && is.numeric(DeepestThirdDailyAggLayer) && d > DeepestThirdDailyAggLayer){		vals[[4]] <- ((DeepestThirdDailyAggLayer+1):DeepestFourthDailyAggLayer)	}	return(vals)}#function to extrapolate windspeeds measured at heights different than SoilWat required 2-m above groundadjust.WindspeedHeight <- function(uz, height){	# Allen RG, Walter IA, Elliott R, Howell T, Itenfisu D, Jensen M (2005) In The ASCE standardized reference evapotranspiration equation, pp. 59. ASCE-EWRI Task Committee Report.	# input: windspeed [m/s] at height x	# output: windspeed [m/s] at height 2 m	stopifnot(all(uz >= 0) && height >= 2 )	return( uz * 4.87 / log(67.8 * height - 5.42) )	# eqn. 33 in Allen et al. (2005)}#--------------------------------------------------------------------------------------------------##------------------------OBTAIN INFORMATION FROM EXTERNAL DATASETS PRIOR TO SIMULATION RUNS TO CREATE THEMif(any(actions == "external") && any(exinfo[!grepl("GriddedDailyWeather", names(exinfo))] > 0)){	setwd(dir.prj)	if(!be.quiet) print(paste("SWSF extracts information from external datasets prior to simulation runs: started at", t1 <- Sys.time()))	stopifnot(file.exists(dir.external))	source(file.path(dir.code, "2_SWSF_p3of4_ExternalDataExtractions_v51.R"), verbose = FALSE, chdir = FALSE)	# Check that include_YN* are inclusive	includes_all_sources <- grep("Include_YN", colnames(SWRunInformation), ignore.case = TRUE, value = TRUE)	includes_sources <- includes_all_sources[-which(includes_all_sources == "Include_YN")]	if (length(includes_sources) > 0L) {		include_YN_sources <- apply(SWRunInformation[, includes_sources, drop = FALSE], 1, function(x) all(x > 0L))			if (all(include_YN_sources[include_YN > 0L])) {			if(!be.quiet) print(paste("External sources available for all requested SWSF simulation runs"))			} else {			include_YN_available <- rep(0, runsN_master)			include_YN_available[include_YN_sources] <- 1			SWRunInformation$include_YN_available <- include_YN_available			write.csv(SWRunInformation, file = file.path(dir.in, datafile.SWRunInformation), row.names = FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))			rm(include_YN_available)			stop("External sources not available for every requested SWSF simulation run. ",				"New column 'include_YN_available' with updated information stored to MasterInput file 'SWRunInformation' on disk. ",				"SWSF is stopped so that you can bring 'include_YN' and 'include_YN_available' in agreement before running the simulations.")		}			rm(include_YN_sources)	}	rm(includes_all_sources, includes_sources)	if(!be.quiet) print(paste("SWSF extracts information from external datasets prior to simulation runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))}#--------------------------------------------------------------------------------------------------##------------------------OBTAIN INFORMATION FROM TABLES PRIOR TO SIMULATION RUNS TO CREATE THEM#------obtain information prior to simulation runsif(any(actions == "create")){	if(!be.quiet) print(paste("SWSF obtains information prior to simulation runs: started at", t1 <- Sys.time()))	if(any(create_treatments == "LookupEvapCoeffFromTable")){		#lookup bare soil evaporation coefficients per soil layer per distribution type for each simulation run and copy values to 'datafile.soils'		get.LookupEvapCoeffFromTable <- function(evco_type, sw_input_soils_use, sw_input_soils){			#extract data from table by category			table.EvapCoeff <- matrix(data=unlist(sapply(evco_type, FUN=function(i) {tr_input_EvapCoeff[which(rownames(tr_input_EvapCoeff) == as.character(i)), 1:SoilLayer_MaxNo]})), ncol=SoilLayer_MaxNo, byrow=TRUE)			#add data to sw_input_soils and set the use flags			i.temp <- grepl(pattern="EvapCoeff", x=names(sw_input_soils_use))			tr.col.max <- max(rowSums(!is.na(table.EvapCoeff)))			sw_input_soils[, i.temp][1:tr.col.max] <- ifelse(!is.na(table.EvapCoeff[, 1:tr.col.max]), table.EvapCoeff[, 1:tr.col.max], 0)			sw_input_soils[, i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- NA			sw_input_soils_use[i.temp][1:tr.col.max] <- 1			sw_input_soils_use[i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- 0			return(list(sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils))		}		if( !(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupEvapCoeffFromTable")) ){#Use only if option is off in sw_input_experimentals and on in treatments			if(any(is.na(sw_input_treatments$LookupEvapCoeffFromTable))) stop("ERROR: LookupEvapCoeffFromTable column in treatments cannot have any NAs.")			if(!all(unique(sw_input_treatments$LookupEvapCoeffFromTable) %in% rownames(tr_input_EvapCoeff))) stop("ERROR: LookupEvapCoeffFromTable column values in treatments do not match up with trfile.LookupEvapCoeffFromTable row names.")			tempdat <- get.LookupEvapCoeffFromTable(evco_type=sw_input_treatments$LookupEvapCoeffFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils)			sw_input_soils_use <- tempdat$sw_input_soils_use			sw_input_soils <- tempdat$sw_input_soils			#write data to datafile.soils			write.csv(rbind(sw_input_soils_use, sw_input_soils), file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		}	}	if(any(create_treatments == "LookupTranspRegionsFromTable")){		#lookup transpiration region per soil layer per distribution type for each simulation run and copy values to 'datafile.soils'		get.LookupTranspRegionsFromTable <- function(trtype, sw_input_soils_use, sw_input_soils){			#extract data from table by type			table.TranspReg <- matrix(data=unlist(sapply(trtype, FUN=function(i) {tr_input_TranspRegions[which(rownames(tr_input_TranspRegions) == as.character(i)), 1:SoilLayer_MaxNo]})), ncol=SoilLayer_MaxNo, byrow=TRUE)			#add data to sw_input_soils and set the use flags			i.temp <- grepl(pattern="TranspRegion", x=names(sw_input_soils_use))			tr.col.max <- max(rowSums(!is.na(table.TranspReg)))			sw_input_soils[, i.temp][1:tr.col.max] <- table.TranspReg[, 1:tr.col.max]			sw_input_soils[, i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- NA			sw_input_soils_use[i.temp][1:tr.col.max] <- 1			sw_input_soils_use[i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- 0			return(list(sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils))		}		if( !(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupTranspRegionsFromTable")) ){#Use only if option is off in sw_input_experimentals			if(any(is.na(sw_input_treatments$LookupTranspRegionsFromTable))) stop("ERROR: LookupTranspRegionsFromTable column in treatments cannot have any NAs.")			if(!all(unique(sw_input_treatments$LookupTranspRegionsFromTable) %in% rownames(tr_input_TranspRegions))) stop("ERROR: LookupTranspRegionsFromTable column values in treatments do not match up with trfile.LookupTranspRegionsFromTable row names.")			tempdat <- get.LookupTranspRegionsFromTable(trtype=sw_input_treatments$LookupTranspRegionsFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils)			sw_input_soils_use <- tempdat$sw_input_soils_use			sw_input_soils <- tempdat$sw_input_soils			#write data to datafile.soils			write.csv(rbind(sw_input_soils_use, sw_input_soils), file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		}	}	if(any(create_treatments == "LookupSnowDensityFromTable")){		#lookup monthly snow density values per category for each simulation run and copy values to 'datafile.cloud'		get.LookupSnowDensityFromTable <- function(sdcategories, sw_input_cloud_use, sw_input_cloud){			#extract data from table by category			snowd <- matrix(data=unlist(sapply(sdcategories, FUN=function(i) {tr_input_SnowD[which(rownames(tr_input_SnowD) == as.character(i)), st_mo]})), ncol=12, byrow=TRUE)			notes <- data.frame(matrix(data=unlist(sapply(sdcategories, FUN=function(i) {tr_input_SnowD[which(rownames(tr_input_SnowD) == as.character(i)), 13:14]})), ncol=2, byrow=TRUE), stringsAsFactors=FALSE)			#add fresh snow density during month of no or zero data			if(sum(itemp <- (is.na(snowd) | snowd == 0)) > 0) snowd[itemp] <- 76 #76 kg/m3 = median of medians over 6 sites in Colorado and Wyoming: Judson, A. & Doesken, N. (2000) Density of Freshly Fallen Snow in the Central Rocky Mountains. Bulletin of the American Meteorological Society, 81, 1577-1587.			#add data to sw_input_cloud and set the use flags			sw_input_cloud_use[i.temp <- grepl(pattern="snowd", x=names(sw_input_cloud_use))] <- 1			sw_input_cloud[, i.temp][st_mo] <- snowd			sw_input_cloud[, grepl(pattern="(SnowD_Hemisphere)|(SnowD_Source)", x=names(sw_input_cloud))] <- cbind(notes[1], apply(notes[2], MARGIN=2, FUN=function(x) paste("Type", sdcategories, "from", x)))			return(list(sw_input_cloud_use=sw_input_cloud_use, sw_input_cloud=sw_input_cloud))		}		if( !(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupSnowDensityFromTable")) ){#Use only if option is off in sw_input_experimentals			if(any(is.na(sw_input_treatments$LookupSnowDensityFromTable))) stop("ERROR: LookupSnowDensityFromTable column in treatments cannot have any NAs.")			if(!all(unique(sw_input_treatments$LookupSnowDensityFromTable) %in% rownames(tr_input_SnowD))) stop("ERROR: LookupSnowDensityFromTable column values in treatments do not match up with trfile.LookupSnowDensityFromTable row names.")			tempdat <- get.LookupSnowDensityFromTable(sdcategories=sw_input_treatments$LookupSnowDensityFromTable, sw_input_cloud_use=sw_input_cloud_use, sw_input_cloud=sw_input_cloud)			sw_input_cloud_use <- tempdat$sw_input_cloud_use			sw_input_cloud <- tempdat$sw_input_cloud			#write data to datafile.cloud			write.csv(rbind(sw_input_cloud_use, sw_input_cloud), file=file.path(dir.sw.dat, datafile.cloud), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		}	}	if(any(create_treatments == "LookupTranspCoeffFromTable_Grass", create_treatments == "LookupTranspCoeffFromTable_Shrub", create_treatments == "LookupTranspCoeffFromTable_Tree", create_treatments == "LookupTranspCoeffFromTable_Forb", create_treatments == "AdjRootProfile"))	{		#lookup transpiration coefficients for grasses, shrubs, and trees per soil layer or per soil depth increment of 1 cm per distribution type for each simulation run and copy values to 'datafile.soils'		#first row of datafile is label for per soil layer 'Layer' or per soil depth increment of 1 cm 'DepthCM'		#second row of datafile is source of data		#the other rows contain the data for each distribution type = columns		TranspCoeffByVegType <- function(soillayer_no, trco_type, layers_depth, adjustType=c("positive", "inverse", "allToLast"))		{			#extract data from table by category			trco.code <- as.character(tr_input_TranspCoeff_Code[, which(colnames(tr_input_TranspCoeff_Code) == trco_type)])			trco <- rep(0, times=soillayer_no)			trco.raw <- na.omit(tr_input_TranspCoeff[, which(colnames(tr_input_TranspCoeff) == trco_type)])			if(trco.code == "DepthCM"){				trco_sum <- ifelse((temp <- sum(trco.raw, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)				lup <- 1				for(l in 1:soillayer_no){					llow <- as.numeric(layers_depth[l])					if(is.na(llow) | lup > length(trco.raw))					{						l <- l - 1						break					}					trco[l] <- sum(trco.raw[lup:llow], na.rm=TRUE) / trco_sum					lup <- llow + 1				}				usel <- l			} else if(trco.code == "Layer"){				usel <- ifelse(length(trco.raw) < soillayer_no, length(trco.raw), soillayer_no)				trco[1:usel] <- trco.raw[1:usel] / ifelse((temp <- sum(trco.raw[1:usel], na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			}			if(identical(adjustType, "positive")){				trco <- trco / sum(trco)	#equivalent to: trco + (1 - sum(trco)) * trco / sum(trco)			} else if(identical(adjustType, "inverse")){				irows <- 1:max(which(trco > 0))				trco[irows] <- trco[irows] + rev(trco[irows]) * (1 / sum(trco[irows]) - 1)	#equivalent to: trco + (1 - sum(trco)) * rev(trco) / sum(trco)			} else if(identical(adjustType, "allToLast")){				irow <- max(which(trco > 0))				if(irow > 1){					trco[irow] <- 1 - sum(trco[1:(irow - 1)]) 	#adding all the missing roots because soil is too shallow to the deepest available layer				} else {					trco[1] <- 1				}			}			return(trco)		}		#cannot write data from sw_input_soils to datafile.soils	}	if(!be.quiet) print(paste("SWSF obtains information prior to simulation runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))}#--------------------------------------------------------------------------------------------------##------------------------CALCULATIONS PRIOR TO SIMULATION RUNS TO CREATE THEM#------flagstemp <- matrix(data=do.PriorCalculations, ncol=2, nrow=length(do.PriorCalculations)/2, byrow=TRUE)pcalcs <- data.frame(t(as.numeric(temp[,-1])))names(pcalcs) <- temp[,1]if(actionWithSoilWat) {	do.GetClimateMeans <- 	(sum(sw_input_climscen_values_use[-1]) > 0) |			pcalcs$EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature |			sw_input_site_use$SoilTempC_atLowerBoundary |			sw_input_site_use$SoilTempC_atUpperBoundary |			pcalcs$EstimateInitialSoilTemperatureForEachSoilLayer |			any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") |			any(create_treatments == "AdjMonthlyBioMass_Temperature") |			any(create_treatments == "AdjMonthlyBioMass_Precipitation") |			any(create_treatments == "Vegetation_Biomass_ScalingSeason_AllGrowingORNongrowing")}if(any(actions == "create") && any(pcalcs > 0)){	if(!be.quiet) print(paste("SWSF makes calculations prior to simulation runs: started at", t1 <- Sys.time()))	if(pcalcs$CalculateBareSoilEvaporationCoefficientsFromSoilTexture){		#calculate bare soil evaporation coefficients per soil layer for each simulation run and copy values to 'datafile.soils'		bsEvap.depth.max <- 15	# max = 15 cm: Torres EA, Calera A (2010) Bare soil evaporation under high evaporation demand: a proposed modification to the FAO-56 model. Hydrological Sciences Journal-Journal Des Sciences Hydrologiques, 55, 303-315.		ld <- 1:SoilLayer_MaxNo		use.layers <- which(sw_input_soils_use[match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))] == 1)		stopifnot(length(use.layers) > 0)		layers.depth <- as.matrix(sw_input_soillayers[runIDs_sites, match(paste("depth_L", use.layers, sep=""), colnames(sw_input_soillayers)), drop = FALSE])		if(length(dim(layers.depth)) > 0){			layers.width <- t(apply(layers.depth, MARGIN=1, FUN=function(x) diff(c(0, x))))		} else {			layers.width <- diff(c(0, layers.depth))		}		bsEvap.ld <- t(lapply(1:nrow(layers.depth), FUN=function(l) 1:(1+findInterval(bsEvap.depth.max - sqrt(.Machine$double.neg.eps), na.exclude(as.numeric(layers.depth[l, ]))))))#TODO: add influence of gravel		sand <- sw_input_soils[runIDs_sites, match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use)), drop = FALSE]		clay <- sw_input_soils[runIDs_sites, match(paste("Clay_L", ld, sep=""), colnames(sw_input_soils_use)), drop = FALSE]		sand.mean <- sapply(1:nrow(layers.depth), FUN=function(l) weighted.mean(as.numeric(sand[l, bsEvap.ld[[l]]]), w=layers.width[bsEvap.ld[[l]]], na.rm=TRUE))		clay.mean <- sapply(1:nrow(layers.depth), FUN=function(l) weighted.mean(as.numeric(clay[l, bsEvap.ld[[l]]]), w=layers.width[bsEvap.ld[[l]]], na.rm=TRUE))		temp <- 4.1984+0.6695*sand.mean^2+168.7603*clay.mean^2	# soil texture influence: Wythers KR, Lauenroth WK, Paruelo JM (1999) Bare-Soil Evaporation Under Semiarid Field Conditions. Soil Science Society of America Journal, 63, 1341-1349.		bsEvap.depth.min <- ifelse(length(dim(layers.depth)) > 0, min(layers.width[, 1]), min(layers.width[1]))		stopifnot(bsEvap.depth.min < bsEvap.depth.max)		temp <- matrix(data=c(temp, rep(bsEvap.depth.min, times=nrow(layers.depth)), rep(bsEvap.depth.max, times=nrow(layers.depth))), ncol=3, byrow=FALSE)		bsEvap.depth <- apply(temp, MARGIN=1, FUN=function(x) min(c(x[3], max(x[1:2], na.rm=TRUE)), na.rm=TRUE))		bsEvap.ld <- t(lapply(1:nrow(layers.depth), FUN=function(l) 1:(1+findInterval(bsEvap.depth[l] - sqrt(.Machine$double.neg.eps), na.exclude(as.numeric(layers.depth[l, ]))))))		bsEvap.coeff <-  t(sapply(1:nrow(layers.depth), FUN=function(i) {							temp <- rep(NA, times=SoilLayer_MaxNo);							temp[bsEvap.ld[[i]]] <- 1 - exp(1 - layers.depth[i, bsEvap.ld[[i]]] * 5 / bsEvap.depth[i]) / exp(1);	#function made up to match previous cummulative distributions							return( (temp <- (c(temp <- as.numeric(temp), 1)-c(0, temp))[ld])/sum(temp, na.rm=TRUE) )	#garuantee that sum is 1						} ))		i.bsE <- grepl(pattern="EvapCoeff", x=names(sw_input_soils_use))		#add data to sw_input_soils and set the use flags		sw_input_soils_use[i.bsE] <- 0		sw_input_soils_use[i.bsE][1:max(unlist(bsEvap.ld))] <- 1		sw_input_soils[runIDs_sites, i.bsE] <- 0		sw_input_soils[runIDs_sites, i.bsE] <- bsEvap.coeff		#write data to datafile.soils		tempdat <- rbind(sw_input_soils_use, sw_input_soils)		write.csv(tempdat, file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)		unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		rm(tempdat, i.bsE, bsEvap.coeff, bsEvap.depth, clay.mean, sand.mean, sand, clay, use.layers, layers.depth, layers.width)	}# SoilWat >=v31 calculates field capacity and wilting point internally; they are no longer required as inputs and this option has become obsolete#	if(pcalcs$CalculateFieldCapacityANDWiltingPointFromSoilTexture){#		#lookup soil texture data from 'datafile.soils' for those that the use flag of sand and clay is set, and calculate field capacity and wilting point#		ld <- 1:SoilLayer_MaxNo#		use.layers <- which(sw_input_soils_use[match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))] == 1)#		sand <- sw_input_soils[, match(paste("Sand_L", use.layers, sep=""), colnames(sw_input_soils_use))]#		clay <- sw_input_soils[, match(paste("Clay_L", use.layers, sep=""), colnames(sw_input_soils_use))]##		fieldc <- sapply(1:ncol(sand), FUN=function(i) SWPtoVWC(-0.033, sand[, i], clay[, i]))#		wiltp <- sapply(1:ncol(sand), FUN=function(i) SWPtoVWC(-1.5, sand[, i], clay[, i]))##		#add data to sw_input_cloud and set the use flags#		sw_input_soils_use[i.fieldc <- match(paste("FieldC_L", use.layers, sep=""), colnames(sw_input_soils_use))] <- 1#		sw_input_soils_use[i.wiltp <- match(paste("WiltP_L", use.layers, sep=""), colnames(sw_input_soils_use))] <- 1#		sw_input_soils[, i.fieldc] <- fieldc#		sw_input_soils[, i.wiltp] <- wiltp##		#write data to datafile.soils#		tempdat <- rbind(sw_input_soils_use, sw_input_soils)#		write.csv(tempdat, file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)#		unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))##		rm(use.layers, sand, clay, fieldc, wiltp, tempdat, i.fieldc, i.wiltp)#	}	#------used during each simulation run: define functions here	if(pcalcs$EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature){		sw_input_site_use$SoilTempC_atLowerBoundary <- 1 #set use flag		sw_input_site_use$SoilTempC_atUpperBoundary <- 1		#call function 'SiteClimate' in each SoilWat-run	}	if(pcalcs$EstimateInitialSoilTemperatureForEachSoilLayer){		#set use flags		ld <- 1:SoilLayer_MaxNo		use.layers <- which(sw_input_soils_use[match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))] == 1)		index.soilTemp <- match(paste("SoilTemp_L", ld, sep=""), colnames(sw_input_soils_use))[use.layers]		soilTemp <- sw_input_soils[runIDs_sites, index.soilTemp, drop = FALSE]		sw_input_soils_use[index.soilTemp] <- 1		#function to be executed for each SoilWat-run		EstimateInitialSoilTemperatureForEachSoilLayer <- function(layers_depth, lower.Tdepth, soilTupper, soilTlower){			sl <- c(0, lower.Tdepth)			st <- c(soilTupper, soilTlower)			return( predict(lm(st ~ sl), data.frame(sl=layers_depth)) )		}	}	if(!be.quiet) print(paste("SWSF makes calculations prior to simulation runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))}#--------------------------------------------------------------------------------------------------##------------------------MAP INPUT VARIABLES (FOR QUALITY CONTROL)if (any(actions == "map_input") && length(map_vars) > 0) {	if (!be.quiet) print(paste("SWSF generates maps of input variables for quality control: started at", t1 <- Sys.time()))	dir.create(dir.inmap <- file.path(dir.out, "Input_maps"), showWarnings = FALSE)	input_avail <- list(SWRunInformation = list(cols = colnames(SWRunInformation), use = rep(TRUE, ncol(SWRunInformation))),						sw_input_soillayers = list(cols = colnames(sw_input_soillayers), use = rep(TRUE, ncol(sw_input_soillayers))),						sw_input_cloud = list(cols = colnames(sw_input_cloud), use = as.logical(sw_input_cloud_use)),						sw_input_prod = list(cols = colnames(sw_input_prod), use = as.logical(sw_input_prod_use)),						sw_input_site = list(cols = colnames(sw_input_site), use = as.logical(sw_input_site_use)),						sw_input_soils = list(cols = colnames(sw_input_soils), use = as.logical(sw_input_soils_use)),						sw_input_weather = list(cols = colnames(sw_input_weather), use = as.logical(sw_input_weather_use)),						sw_input_climscen = list(cols = colnames(sw_input_climscen), use = as.logical(sw_input_climscen_use)),						sw_input_climscen_values = list(cols = colnames(sw_input_climscen_values), use = as.logical(sw_input_climscen_use))					)							for (iv in seq_along(map_vars)) {		iv_locs <- lapply(input_avail, function(ina) grep(map_vars[iv], ina$cols[ina$use], ignore.case = TRUE, value = TRUE))		iv_locs <- iv_locs[lengths(iv_locs) > 0]				if (length(iv_locs) > 0) {			dir.create(dir.inmapvar <- file.path(dir.inmap, map_vars[iv]), showWarnings = FALSE)			for (it1 in seq_along(iv_locs)) for (it2 in seq_along(iv_locs[[it1]])) {				dat <- as.numeric(get(names(iv_locs)[it1])[runIDs_sites, iv_locs[[it1]][it2]])								if (any(is.finite(dat))) {					names(dat) <- iv_locs[[it1]][it2]								map_flag <- paste(names(iv_locs)[it1], iv_locs[[it1]][it2], sim_cells_or_points, sep = "_")								# Convert data to spatial object					if (sim_cells_or_points == "point") {						sp_dat <- as(run_sites, "SpatialPointsDataFrame")						temp <- as.data.frame(dat)						colnames(temp) <-  iv_locs[[it1]][it2]						slot(sp_dat, "data") <- temp										if (!raster::compareCRS(crs_sites, sim_crs)) {							sp_dat <- sp::spTransform(sp_dat, CRS = sim_crs)						}									} else if (sim_cells_or_points == "cell") {						sp_dat <- sim_raster						stopifnot(raster::canProcessInMemory(sp_dat)) # if failing, then need a more sophisticated assignment of values than implemented below						temp <- run_sites						if (!raster::compareCRS(crs_sites, sim_crs)) {							temp <- sp::spTransform(temp, CRS = sim_crs)						}										sp_dat[raster::cellFromXY(sp_dat, sp::coordinates(temp))] <- dat					}								# Save to disk					saveRDS(sp_dat, file = file.path(dir.inmapvar, paste0(map_flag, ".rds")))								# Figure					png(height = 10, width = 6, units = "in", res = 200, file = file.path(dir.inmapvar, paste0(map_flag, ".png")))					par_old <- par(mfrow = c(2, 1), mar = c(2.5, 2.5, 0.5, 0.5), mgp = c(1.25, 0.25, 0), tcl = 0.5, cex = 1)								# panel a: map					n_cols <- 255					cols <- rev(terrain.colors(7))					cols[1] <- "gray"					cols <- colorRampPalette(c(cols, "dodgerblue3"))(n_cols)					if (sim_cells_or_points == "point") {						par1 <- par(mar = c(2.5, 2.5, 0.5, 8.5))						cdat <- cut(dat, n_cols)						p_size <- function(x) max(0.25, min(2, 100 / x))						sp::plot(sp_dat, col = cols[as.integer(cdat)], pch = 15, cex = p_size(length(dat)), axes = TRUE, asp = 1)						# legend						ids <- round(seq(1, n_cols, length.out = 12))						lusr <- par("usr")						lxy <- cbind(rep(lusr[2] + (lusr[2] - lusr[1]) / 15, 12),									 lusr[3] + (lusr[4] - lusr[3]) / 4 + seq(0, 1, length.out = 12) * (lusr[4] - lusr[3]) / 2)						points(lxy, col = cols[ids], pch = 15, cex = 2, xpd = NA)						text(lxy, pos = 4, labels = levels(cdat)[ids], xpd = NA)						par(par1)					} else if (sim_cells_or_points == "cell") {						raster::plot(sp_dat, col = cols, asp = 1)					}					mtext(side = 3, line = -1, adj = 0.03, text = paste0("(", letters[1], ")"), font = 2)					# panel b: histogram					hist(dat, xlab = paste(names(iv_locs)[it1], iv_locs[[it1]][it2]), main = "")					mtext(side = 3, line = -1, adj = 0.03, text = paste0("(", letters[2], ")"), font = 2)								par(par_old)					dev.off()				}			}		}	}		if (!be.quiet) print(paste("SWSF input maps: ended after",  round(difftime(Sys.time(), t1, units = "secs"), 2), "s"))}#--------------------------------------------------------------------------------------------------##------------------------FUNCTION FOR A SOILWAT SIMULATIONif(actionWithSoilWat){do_OneSite <- function(i_sim, i_labels, i_SWRunInformation, i_sw_input_soillayers, i_sw_input_treatments, i_sw_input_cloud, i_sw_input_prod, i_sw_input_site, i_sw_input_soils, i_sw_input_weather, i_sw_input_climscen, i_sw_input_climscen_values) {#i_sim: a value of runIDs_total, i.e., counting the simulation runs#i_xxx = the i_site-row of xxx for the i-th simulation run; if expN > 0 then these will eventually be repeated, and below replaced with experimental values#i_exp = the row of sw_input_experimentals for the i_sim-th simulation run#P_id is a unique id number for each scenario in each run	time.sys <- Sys.time()	flag.icounter <- formatC(i_sim, width=counter.digitsN, format = "d", flag="0")#-----------------------Check for experimentals	if(expN > 0 && length(create_experimentals) > 0) {		i_exp <- it_exp(i_sim)		i_labels <- paste(flag.icounter, sw_input_experimentals[i_exp,1], i_labels, sep="_")		#--put information from experimental design into appropriate input variables; create_treatments and the _use files were already adjusted for the experimental design when files were read in/created		transferExpDesignToInput <- function(i_sw_input){			ctemp <- (temp <- match(names(sw_input_experimentals)[sw_input_experimentals_use == 1], names(i_sw_input), nomatch=0))[!temp == 0]			if(length(ctemp) > 0){				cexp <- match(names(i_sw_input)[ctemp], names(sw_input_experimentals), nomatch=0)				i_sw_input[ctemp] <- sw_input_experimentals[i_exp, cexp]			}			return(i_sw_input)		}		i_sw_input_treatments <- transferExpDesignToInput(i_sw_input_treatments)		i_sw_input_soils <- transferExpDesignToInput(i_sw_input_soils)		i_sw_input_site <- transferExpDesignToInput(i_sw_input_site)		i_sw_input_prod <- transferExpDesignToInput(i_sw_input_prod)	}#------------------------Preparations for simulation run	if(!be.quiet) print(paste(i_sim, ":", i_labels, "started at ", time.sys))	#Check what needs to be done	#TODO this currently doesn't work in the database setup	isdone.overallAggs <- rep(FALSE, scenario_No)	if(any(simulation_timescales=="daily") && daily_no > 0){		isdone.dailyAggs <- matrix(data=FALSE, nrow=daily_no, ncol=scenario_No)	} else {		isdone.dailyAggs <- TRUE	}	#set up task list: code: -1, don't do; 0, failed; 1, to do; 2, success	tasks <- list(aggregate = 1L, #for now: ignoring to check time-series aggregations, i.e., assuming that if overallAggs is done, then time-series output was also completed					create = 1L,					execute = 1L)	#Prepare directory structure in case SoilWat input/output is requested to be stored on disk	if (saveRsoilwatInput || saveRsoilwatOutput) {		temp <- file.path(dir.sw.runs, i_labels)		dir.create2(temp, showWarnings = FALSE)		f_sw_input <- file.path(temp, "sw_input.RData")		f_sw_output <- file.path(temp, "sw_output.RData")	}	#----Get preparations done	if (all(unlist(tasks) %in% c(-1L, 1L))) {		#get treatment sw.input.filenames for this run		filesin <- swFilesIn		if(!is.null(create_treatments) & tasks$create == 1L){			if(any(create_treatments == "sw")){				sw <- i_sw_input_treatments$sw			}			if(any(create_treatments == "filesin")){				filesin <- i_sw_input_treatments$filesin			}			if(any(create_treatments == "prodin")){				prodin <- i_sw_input_treatments$prodin			}			if(any(create_treatments == "siteparamin")){				siteparamin <- i_sw_input_treatments$siteparamin			}			if(any(create_treatments == "soilsin")){				soilsin <- i_sw_input_treatments$soilsin			}			if(any(create_treatments == "weathersetupin")){				weatherin <- i_sw_input_treatments$weathersetupin			}			if(any(create_treatments == "cloudin")){				cloudin <- i_sw_input_treatments$cloudin			}		}		#if action is not create then get sw.input.filenames from filesin for this run		if(tasks$create == -1L){			stop("This currently doesn't work") #TODO make it work low PR			soilsin <- basename(unlist(strsplit(infiletext[10], split="[[:space:]]"))[1])		}		#------Learn about soil layer structure		#determine number of soil layers = d and soildepth		if(!any(create_treatments=="soilsin") & tasks$create == 1L) {			soildepth <- i_sw_input_soillayers$SoilDepth_cm			layers_depth <- na.omit(as.numeric(i_sw_input_soillayers[2 + lmax]))			if(!(length(d <- which(soildepth == layers_depth)) > 0)){	#soildepth is one of the lower layer boundaries				d <- min(length(layers_depth), findInterval(soildepth, layers_depth)+1)	#soildepth is not one of the lower layer boundaries, the next deeper layer boundary is used			}		} else {# needs to be read from soilsin file			if(tasks$create == -1L) stop("This currently doesn't work") #TODO make it work low PR			layers_depth <- swSoils_Layers(tr_soil[[soilsin]])[,1]			d <- length(layers_depth)			soildepth <- max(layers_depth)		}		#functions to obtain soil layer structures		#layer sequence		ld <- setLayerSequence(d)		layers_depth <- adjustLayersDepth(layers_depth, d)		layers_width <- getLayersWidth(layers_depth)		#top and bottom layer aggregation		setDeepestTopLayer <- function(d){			return(max(1, findInterval(Depth_TopLayers, layers_depth) ))		}		setTopLayer <- function(d){			return(1:(ifelse(d<DeepestTopLayer, d, DeepestTopLayer)))		}		setBottomLayer <- function(d){			if(d <= DeepestTopLayer){				val  <- NULL			} else {				val  <- ((DeepestTopLayer+1):d)			}			return(val)		}		DeepestTopLayer <- setDeepestTopLayer(d)		topL <- setTopLayer(d)		bottomL <- setBottomLayer(d)		#------Learn about simulation time		if(any(create_treatments == "YearStart") | any(create_treatments == "YearEnd")){			#------time frame of simulation			if(any(create_treatments == "YearStart")){				#year when SoilWat starts the simulation				simstartyr  <- i_sw_input_treatments$YearStart				#first year that is used for output aggregation, e.g., simstartyr + 1				startyr <- getStartYear(simstartyr)			}			if(any(create_treatments == "YearEnd")){				#year when SoilWat ends the simulation				endyr <- i_sw_input_treatments$YearEnd			}			#------simulation timing needs to be adjusted			simTime <- simTiming(startyr, simstartyr, endyr)			simTime2 <- simTiming_ForEachUsedTimeUnit(simTime, latitude=i_SWRunInformation$Y_WGS84)		} else {			if(i_SWRunInformation$Y_WGS84 >= 0){				simTime2 <- simTime_ForEachUsedTimeUnit_North			} else {				simTime2 <- simTime_ForEachUsedTimeUnit_South			}		}	}#------------------------CREATE RUNS	if (tasks$create == 1L && continueAfterAbort && saveRsoilwatInput && file.exists(f_sw_input)) {		load(f_sw_input)	# load objects: swRunScenariosData, i_sw_weatherList, grasses.c3c4ann.fractions, ClimatePerturbationsVals		tasks$create <- 2L	}	if (tasks$create == 1L) {		if(print.debug) print("Start of section 'create'")		EVCO_done <- TRCO_done <- FALSE	#to check whether we get information for evaporation and transpiration coefficients		TRRG_done <- FALSE #to check whether we get information for transpiration regions				# Data objects used also during aggregation		grasses.c3c4ann.fractions <- rep(list(rep(NA, 3)), scenario_No) #Init fractions of C3, C4, and annual grasses of grass-vegetation type fraction; used in create and aggregate		ClimatePerturbationsVals <- matrix(data=c(rep(1,12),rep(0,24)),nrow=scenario_No, ncol=12*3, byrow=TRUE) #, dimnames=list(NULL,paste(rep(paste("ClimatePerturbations.", c("PrcpMultiplier.m", "TmaxAddand.m", "TminAddand.m"), sep=""), each=12), st_mo, rep(c("_none", "_C", "_C"), each=12), "_const", sep=""))		#------1. Step: Information for this SoilWat-run from prepared SoilWat-run stored in dir.sw.in		#Make a local copy of the swInput object do not want to destroy orignal		swRunScenariosData<-list(scenario_No)		swRunScenariosData[[1]]<-swDataFromFiles		#get folder and file names		outsetupin <- swOutSetupIn		dir.sw.runs.weather <- i_sw_input_treatments$LookupWeatherFolder		if(print.debug) print("Start of LookupWeatherFolder")		#write input file names and paths to first file, unless filesin is a treatment		if(!any(create_treatments=="filesin")){			swFiles_Years(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, yearsin, sep="")			swFiles_LogFile(swRunScenariosData[[1]]) <- paste(ifelse(sw.outputs == "", "", paste(sw.outputs, .Platform$file.sep, sep="")), sep="")			swFiles_SiteParams(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, siteparamin, sep="")			swFiles_Soils(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, soilsin, sep="")			swFiles_WeatherSetup(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, weatherin, sep="")			swFiles_WeatherPrefix(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, filebasename.WeatherDataYear, sep="")			swFiles_MarkovProbs(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, sep="")			swFiles_MarkovCov(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, sep="")			swFiles_Cloud(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, cloudin, sep="")			swFiles_Prod(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, prodin, sep="")			swFiles_Estab(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, estabin, sep="")			swFiles_SWCsetup(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, swcsetupin, sep="")			swFiles_OutputPrefix(swRunScenariosData[[1]]) <- paste(ifelse(sw.outputs == "", "", paste(sw.outputs, .Platform$file.sep, sep="")), sep="")			swFiles_Output(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, outsetupin, sep="")		}		#adjust simulation years		swYears_StartYear(swRunScenariosData[[1]]) <- as.integer(simstartyr)		swYears_EndYear(swRunScenariosData[[1]]) <- as.integer(endyr)		##adjust soil temp equation parameters		if(any(create_treatments=="MaxTempDepth"))		  swRunScenariosData[[1]]@site@SoilTemperatureConstants[[10]] <- i_sw_input_treatments$MaxTempDepth		#------2. Step: a) Information for this SoilWat-run from treatment SoilWat input files stored in dir.sw.in.tr		if(any(create_treatments=="sw"))			print("SW treatment is not used because library Rsoilwat only uses one version of soilwat. Sorry")		if(any(create_treatments=="filesin"))			set_swFiles(swRunScenariosData[[1]]) <- tr_files[[filesin]]		if(any(create_treatments=="prodin"))			set_swProd(swRunScenariosData[[1]]) <- tr_prod[[prodin]]		if(any(create_treatments=="siteparamin")){			set_swSite(swRunScenariosData[[1]]) <- tr_site[[siteparamin]]			TRRG_done <- TRUE		}		if(any(create_treatments=="soilsin")){			set_swSoils(swRunScenariosData[[1]]) <- tr_soil[[soilsin]]			EVCO_done <- TRCO_done <- TRUE		}		if(any(create_treatments=="weathersetupin"))			set_swWeather(swRunScenariosData[[1]]) <- tr_weather[[weatherin]]		if(any(create_treatments=="cloudin"))			set_swCloud(swRunScenariosData[[1]]) <- tr_cloud[[cloudin]]		#------2. Step: b) Information for this SoilWat-run from treatment chunks stored in dir.sw.in.tr		#Do the lookup stuff for experimental design that was done for the treatment design before the call to call_OneSite, but couldn't for the experimental design because at that time information was unkown		if(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupEvapCoeffFromTable")) {			if(any(is.na(i_sw_input_treatments$LookupEvapCoeffFromTable)) || !all(unique(i_sw_input_treatments$LookupEvapCoeffFromTable) %in% rownames(tr_input_EvapCoeff))) {				print("ERROR: LookupEvapCoeffFromTable column in expirementals cannot have any NAs or name is not in tr_input_EvapCoeff table.")				tasks$create <- 0L			} else {				tempdat <- get.LookupEvapCoeffFromTable(evco_type=i_sw_input_treatments$LookupEvapCoeffFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=i_sw_input_soils)				if(all(colSums(tempdat$sw_input_soils,na.rm=T)>0) && !any(is.na(colSums(tempdat$sw_input_soils))) ) {					sw_input_soils_use <- tempdat$sw_input_soils_use					i_sw_input_soils <- tempdat$sw_input_soils				} else {					print("ERROR: get.LookupEvapCoeffFromTable returned a Layer that didn't have a sum greater then 0 or had a NA.")					tasks$create <- 0L				}			}		}		if(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupTranspRegionsFromTable")) {			if(any(is.na(i_sw_input_treatments$LookupTranspRegionsFromTable)) || !all(unique(i_sw_input_treatments$LookupTranspRegionsFromTable) %in% rownames(tr_input_TranspRegions))) {				print("ERROR: LookupTranspRegionsFromTable column in expirementals cannot have any NAs or name is not in LookupTranspRegionsFromTable data table.")				tasks$create <- 0L			} else {				tempdat <- get.LookupTranspRegionsFromTable(trtype=i_sw_input_treatments$LookupTranspRegionsFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=i_sw_input_soils)				sw_input_soils_use <- tempdat$sw_input_soils_use				i_sw_input_soils <- tempdat$sw_input_soils			}		}		if(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupSnowDensityFromTable")) {			if(any(is.na(i_sw_input_treatments$LookupSnowDensityFromTable)) || !all(unique(i_sw_input_treatments$LookupSnowDensityFromTable) %in% rownames(tr_input_SnowD))) {				print("ERROR: LookupSnowDensityFromTable column in expirementals cannot have any NAs or name is not in tr_input_SnowD data table.")				tasks$create <- 0L			} else {				tempdat <- get.LookupSnowDensityFromTable(sdcategories=i_sw_input_treatments$LookupSnowDensityFromTable, sw_input_cloud_use=sw_input_cloud_use, sw_input_cloud=i_sw_input_cloud)				sw_input_cloud_use <- tempdat$sw_input_cloud_use				i_sw_input_cloud <- tempdat$sw_input_cloud			}		}		#Treatment chunks		if(print.debug) print("Start of LookupTranspCoeff")		if(print.debug) print(".........grass")		if(any(create_treatments == "LookupTranspCoeffFromTable_Grass")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Grass)) print("LookupTranspCoeffFromTable_Grass for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Grass %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Grass name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0L			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Grass"], layers_depth=layers_depth, adjustType="positive")				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){#trco does not have NA and sum is greater than 0.					#set the use flags					i.temp <- grepl(pattern=paste("Grass", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				} else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type grass.")					tasks$create <- 0L				}			}		}		if(print.debug) print(".........shrub")		if(any(create_treatments == "LookupTranspCoeffFromTable_Shrub")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Shrub)) print("LookupTranspCoeffFromTable_Shrub for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Shrub %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Shrub name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0L			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Shrub"], layers_depth=layers_depth, adjustType="inverse")				#set the use flags				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){					i.temp <- grepl(pattern=paste("Shrub", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				}  else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type shrub.")					tasks$create <- 0L				}			}		}		if(print.debug) print(".........tree")		if(any(create_treatments == "LookupTranspCoeffFromTable_Tree")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Tree)) print("LookupTranspCoeffFromTable_Tree for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Tree %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Tree name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0L			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Tree"], layers_depth=layers_depth, adjustType="inverse")				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){					i.temp <- grepl(pattern=paste("Tree", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				} else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type Tree.")					tasks$create <- 0L				}			}		}		if(print.debug) print(".........forb")		if(any(create_treatments == "LookupTranspCoeffFromTable_Forb")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Forb)) print("LookupTranspCoeffFromTable_Forb for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Forb %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Forb name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0L			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Forb"], layers_depth=layers_depth, adjustType="inverse")				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){					i.temp <- grepl(pattern=paste("Forb", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				} else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type Forb.")					tasks$create <- 0L				}			}		}		#the monthly ppt-shifts are extracted, but written to the weathersetup input file only at the end of the create section 'copy and make climate scenarios from datafiles', because they are multiplied with any climate change factors		ppt_scShift <- rep(1, times=12)		if(any(create_treatments=="LookupShiftedPPTScenarios")){			ppt_scShift <- tr_input_shiftedPPT[which(rownames(tr_input_shiftedPPT) == i_sw_input_treatments[1,"LookupShiftedPPTCategory"]),(ts <- which(colnames(tr_input_shiftedPPT) == paste(i_sw_input_treatments$LookupShiftedPPTScenarios, "_m1", sep=""))):(ts+11)][st_mo]		}		if(any(create_treatments=="LookupClimatePPTScenarios") | any(create_treatments=="LookupClimateTempScenarios")){			clim_scale <- swWeather_MonScalingParams(swRunScenariosData[[1]])[, 1:3]			#Treatment chunk = climate precipitation scenarios			if(any(create_treatments=="LookupClimatePPTScenarios") ) {				clim_scale[, 1] <- tr_input_climPPT[st_mo, which(colnames(tr_input_climPPT) == i_sw_input_treatments$LookupClimatePPTScenarios)]			}			#Treatment chunk = climate temperature scenarios			if(any(create_treatments=="LookupClimateTempScenarios") ) {				clim_scale[, 2] <- clim_scale[, 3] <- tr_input_climTemp[st_mo, which(colnames(tr_input_climTemp) == i_sw_input_treatments$LookupClimateTempScenarios)]			}			swWeather_MonScalingParams(swRunScenariosData[[1]])[, 1:3] <- clim_scale			rm(clim_scale)		}		#------4. Step: Information from datafiles are added if flagged 'use' to SoilWat input files		#add information from datafile to cloudin		if(print.debug) print("Start of cloudin")		wind <- with(i_sw_input_cloud, data.frame(wind_ms_1, wind_ms_2, wind_ms_3, wind_ms_4, wind_ms_5, wind_ms_6, wind_ms_7, wind_ms_8, wind_ms_9, wind_ms_10, wind_ms_11, wind_ms_12))		if(do.wind <- datafile.windspeedAtHeightAboveGround != SoilWat.windspeedAtHeightAboveGround)			wind <- adjust.WindspeedHeight(uz=wind, height=datafile.windspeedAtHeightAboveGround)		if(sum(sw_input_cloud_use[-1]) > 0 | do.wind){			#sky cover			if(sum(sw_input_cloud_use[grepl(pattern="SkyC", x=names(sw_input_cloud_use))]) > 0) {				sky <- with(i_sw_input_cloud, data.frame(SkyC_1, SkyC_2, SkyC_3, SkyC_4, SkyC_5, SkyC_6, SkyC_7, SkyC_8, SkyC_9, SkyC_10, SkyC_11, SkyC_12))				swCloud_SkyCover(swRunScenariosData[[1]]) <- round(as.double(sky), 0)			}			#wind speed			if(sum(sw_input_cloud_use[grepl(pattern="wind", x=names(sw_input_cloud_use))]) > 0 | do.wind) {				swCloud_WindSpeed(swRunScenariosData[[1]]) <- round(as.double(wind), 2)			}			#relative humidity			if(sum(sw_input_cloud_use[grepl(pattern="RH", x=names(sw_input_cloud_use))]) > 0) {				rh <- with(i_sw_input_cloud, data.frame(RH_1, RH_2, RH_3, RH_4, RH_5, RH_6, RH_7, RH_8, RH_9, RH_10, RH_11, RH_12))				swCloud_Humidity(swRunScenariosData[[1]]) <- round(as.double(rh), 0)			}			#snow density			if(sum(sw_input_cloud_use[grepl(pattern="snowd", x=names(sw_input_cloud_use))]) > 0) {				snowd <- with(i_sw_input_cloud, data.frame(snowd_1, snowd_2, snowd_3, snowd_4, snowd_5, snowd_6, snowd_7, snowd_8, snowd_9, snowd_10, snowd_11, snowd_12))				if(i_SWRunInformation$Y_WGS84 < 0 && i_sw_input_cloud$SnowD_Hemisphere == "N" || i_SWRunInformation$Y_WGS84 > 0 && i_sw_input_cloud$SnowD_Hemisphere == "S"){	#adjust for hemisphere only if location and data are opposite					snowd <- c(snowd[7:12], snowd[1:6])				}				swCloud_SnowDensity(swRunScenariosData[[1]]) <- round(as.double(snowd), 1)			}		}		#add vegetation information	from datafile to prodin		if(print.debug) print("Start of prodin")		if(sum(sw_input_prod_use[-1]) > 0){			#composition			if(sum(use_comp <- unlist(sw_input_prod_use[grepl(pattern="Composition", x=names(sw_input_prod_use))])) > 0) {				comp.datfile <- with(i_sw_input_prod, data.frame(Composition_GrassFraction, Composition_ShrubFraction, Composition_TreeFraction, Composition_ForbFraction, Composition_BareGround))				comp.datfile[is.na(comp.datfile)]<-0				swRunScenariosData[[1]]@prod@Composition[1:5]<- as.numeric(comp.datfile[1:length(use_comp)])			}			#albedo			if(sum(use_albedo <- unlist(sw_input_prod_use[grepl(pattern="Albedo", x=names(sw_input_prod_use))])) > 0) {				albedo.datfile <- with(i_sw_input_prod, data.frame(Grass_Albedo, Shrub_Albedo, Tree_Albedo, Forb_Albedo, BareGround_Albedo))				swProd_Albedo(swRunScenariosData[[1]])[use_albedo] <- albedo.datfile[use_albedo]			}			#constant canopy height			if(sum(use_height <- unlist(sw_input_prod_use[grepl(pattern="CanopyHeight_Constant", x=names(sw_input_prod_use))])) > 0) {				height.datfile <- with(i_sw_input_prod, data.frame(Grass_CanopyHeight_Constant_cm, Shrub_CanopyHeight_Constant_cm, Tree_CanopyHeight_Constant_cm,Forb_CanopyHeight_Constant_cm))				height.datfile[is.na(height.datfile)]<-0				swRunScenariosData[[1]]@prod@CanopyHeight[5,] <- as.numeric(height.datfile[1:length(use_height)])			}			#flag for hydraulic redistribution			if(sum(use_HD <- unlist(sw_input_prod_use[grepl(pattern="HydRed", x=names(sw_input_prod_use))])) > 0) {				HD.datfile <- with(i_sw_input_prod, data.frame(Grass_HydRed_OnOff, Shrub_HydRed_OnOff, Tree_HydRed_OnOff, Forb_HydRed_OnOff))				swProd_HydrRedstro_use(swRunScenariosData[[1]])[use_HD] <- as.logical(HD.datfile[use_HD])			}			#biomass components TODO Check This			biomassComponents <- function(FunctGroup){				if(	sum(litt <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_Litter", sep=""), x=names(sw_input_prod_use))]) +						sum(biom <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_Biomass", sep=""), x=names(sw_input_prod_use))]) +						sum(live <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_FractionLive", sep=""), x=names(sw_input_prod_use))]) +						sum(laiconv <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_LAIconv", sep=""), x=names(sw_input_prod_use))])			> 0) {					for (m in st_mo){					  input_in_veg<-with(i_sw_input_prod,eval(parse(text=paste0("swRunScenariosData[[1]]@prod@MonthlyProductionValues_",tolower(FunctGroup),"[m,]"))))						mo.dat <- with(i_sw_input_prod, c(	ifelse(litt[m], eval(parse(text=paste(FunctGroup, "_Litter_m", m, sep=""))),input_in_veg[1]),						        ifelse(biom[m], eval(parse(text=paste(FunctGroup, "_Biomass_m", m, sep=""))), input_in_veg[2]),										ifelse(live[m], eval(parse(text=paste(FunctGroup, "_FractionLive_m", m, sep=""))), input_in_veg[3]),										ifelse(laiconv[m], eval(parse(text=paste(FunctGroup, "_LAIconv_m", m, sep=""))), input_in_veg[4])))						if(FunctGroup=="Grass")						swRunScenariosData[[1]]@prod@MonthlyProductionValues_grass[m,]  <- mo.dat						if(FunctGroup=="Shrub")						  swRunScenariosData[[1]]@prod@MonthlyProductionValues_shrub[m,]  <- mo.dat						if(FunctGroup=="Tree")						  swRunScenariosData[[1]]@prod@MonthlyProductionValues_tree[m,]  <- mo.dat						if(FunctGroup=="Forb")						  swRunScenariosData[[1]]@prod@MonthlyProductionValues_forb[m,]  <- mo.dat					}				}				if(FunctGroup=="Grass")					return(swProd_MonProd_grass(swRunScenariosData[[1]]))				if(FunctGroup=="Shrub")					return(swProd_MonProd_shrub(swRunScenariosData[[1]]))				if(FunctGroup=="Tree")					return(swProd_MonProd_tree(swRunScenariosData[[1]]))				if(FunctGroup=="Forb")					return(swProd_MonProd_forb(swRunScenariosData[[1]]))			}			swProd_MonProd_grass(swRunScenariosData[[1]]) <- biomassComponents(FunctGroup="Grass")			swProd_MonProd_shrub(swRunScenariosData[[1]]) <- biomassComponents(FunctGroup="Shrub")			swProd_MonProd_tree(swRunScenariosData[[1]])  <- biomassComponents(FunctGroup="Tree")			swProd_MonProd_forb(swRunScenariosData[[1]])  <- biomassComponents(FunctGroup="Forb")		}		#Moved adjust to southern Hemi		#add site information to siteparamin		if(print.debug) print("Start of siteparamin")		if(sum(sw_input_site_use[-1]) > 0){			site_swc_use <- as.logical(c(sw_input_site_use$SWC_min,sw_input_site_use$SWC_init,sw_input_site_use$SWC_wet))			if(any(site_swc_use)){				swSite_SWClimits(swRunScenariosData[[1]])[temp] <- c(i_sw_input_site$SWC_min,i_sw_input_site$SWC_init,i_sw_input_site$SWC_wet)[temp]			}			site_modelflag_use <- as.logical(c(sw_input_site_use$SWC_YearlyReset,sw_input_site_use$SWC_Deepdrain))			if(any(site_modelflag_use)){				swSite_ModelFlags(swRunScenariosData[[1]])[site_modelflag_use] <- c(i_sw_input_site$SWC_YearlyReset,i_sw_input_site$SWC_Deepdrain)[site_modelflag_use]			}			site_modelcoef_use <- as.logical(c(sw_input_site_use$PET_multiplier,sw_input_site_use$RunoffPercent_fromPondedWater))			if(any(site_modelcoef_use)){				swSite_ModelCoefficients(swRunScenariosData[[1]])[site_modelcoef_use] <- c(i_sw_input_site$PET_multiplier, i_sw_input_site$RunoffPercent_fromPondedWater)[site_modelcoef_use]			}			#replace if in treatment file			if(sw_input_site_use$Param_UnsaturatedPercolation){				swSite_DrainageCoefficient(swRunScenariosData[[1]]) <- i_sw_input_site$Param_UnsaturatedPercolation			}			if(sw_input_site_use$Latitude) {				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[1] <- i_sw_input_site$Latitude			}			if(sw_input_site_use$Altitude) {				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[2] <- i_sw_input_site$Altitude			}			if(sw_input_site_use$Slope){				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[3] <- i_sw_input_site$Slope			}			if(sw_input_site_use$Aspect){				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[4] <- i_sw_input_site$Aspect			}			#Moved sw_input_site_use$SoilTempC_atLowerBoundary			if(sw_input_site_use$SoilTemp_Flag){				swSite_SoilTemperatureFlag(swRunScenariosData[[1]]) <- i_sw_input_site$SoilTemp_Flag			}			rm(site_swc_use,site_modelflag_use,site_modelcoef_use)		}		swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[1] <- i_SWRunInformation$Y_WGS84 * pi / 180		if(is.finite(i_SWRunInformation$ELEV_m))	swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[2] <- i_SWRunInformation$ELEV_m		#add soil information to soilsin		if(print.debug) print("Start of soilsin")		done.Imperm_L1 <- FALSE		if(sw_input_soils_use$Imperm_L1 == 1 && any(create_treatments == "soilsin")){			tempdat <- swSoils_Layers(swRunScenariosData[[1]])			tempdat[1, "impermeability_frac"] <- i_sw_input_soils$Imperm_L1			swSoils_Layers(swRunScenariosData[[1]]) <- tempdat			done.Imperm_L1 <- TRUE		}		if(sum(sw_input_soils_use[-1] + ifelse(done.Imperm_L1, -1, 0)) - sum(use_transpregion <- as.numeric(sw_input_soils_use[paste("TranspRegion_L", ld, sep="")])) > 0){			tempdat <- matrix(data=NA, nrow=SoilLayer_MaxNo, ncol=12)			colnames(tempdat) <- c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")			#recalculate soil layer structure, because any(create_treatments=="soilsin") and soilsin may have a different soil layer structure than the datafiles			layers_depth.datafile <- (temp <- as.numeric(na.omit(unlist(i_sw_input_soillayers[match(paste("depth_L", 1:SoilLayer_MaxNo, sep=""), colnames(i_sw_input_soillayers))]))))[temp <= as.numeric(i_sw_input_soillayers["SoilDepth_cm"])]			layers_depth.soilsin <- swSoils_Layers(swRunScenariosData[[1]])[,1]			mergeDatafileWithSoilsin <- FALSE			if(identical(layers_depth.datafile, layers_depth.soilsin)){	#same soil layer structure in soilsin and datafile => combine data				#soil texture data from SoilWat input file				tempdat <- swSoils_Layers(swRunScenariosData[[1]])				colnames(tempdat) <- c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")#names might be diff				mergeDatafileWithSoilsin <- TRUE			} else { #different soil layer structure in soilsin and datafile AND since variables are flagged in sw_input_soils_use => use only datafile values				d <- max(1, min(length(layers_depth.datafile), findInterval(i_sw_input_soillayers$SoilDepth_cm - sqrt(.Machine$double.neg.eps), c(0, layers_depth.datafile)), na.rm=TRUE), na.rm=TRUE)				layers_depth <- adjustLayersDepth(layers_depth.datafile, d)				layers_width <- getLayersWidth(layers_depth)				ld <- setLayerSequence(d)				DeepestTopLayer <- setDeepestTopLayer(d)				topL <- setTopLayer(d)				bottomL <- setBottomLayer(d)			}			#flags for use of texture data from datafile			use_matricd <- as.numeric(sw_input_soils_use[paste("Matricd_L", ld, sep="")])			use_gravelC <- as.numeric(sw_input_soils_use[paste("GravelContent_L", ld, sep="")])			#use_pwp <- as.numeric(sw_input_soils_use[paste("WiltP_L", ld, sep="")])			sum_use_evco <- sum(sw_input_soils_use[paste("EvapCoeff_L", ld, sep="")])			sum_use_trco_grass <- sum(sw_input_soils_use[paste("Grass_TranspCoeff_L", ld, sep="")])			sum_use_trco_shrub <- sum(sw_input_soils_use[paste("Shrub_TranspCoeff_L", ld, sep="")])			sum_use_trco_tree <- sum(sw_input_soils_use[paste("Tree_TranspCoeff_L", ld, sep="")])			sum_use_trco_forb <- sum(sw_input_soils_use[paste("Forb_TranspCoeff_L", ld, sep="")])			use_sand <- as.numeric(sw_input_soils_use[paste("Sand_L", ld, sep="")])			use_clay <- as.numeric(sw_input_soils_use[paste("Clay_L", ld, sep="")])			use_imperm <- as.numeric(sw_input_soils_use[paste("Imperm_L", ld, sep="")])			if(mergeDatafileWithSoilsin || sum_use_evco > 0) EVCO_done <- TRUE			if(mergeDatafileWithSoilsin || (sum_use_trco_grass > 0 && sum_use_trco_shrub > 0 && sum_use_trco_tree > 0)) TRCO_done <- TRUE			#tr and ev coefficients data from datafile			evco <- as.numeric(i_sw_input_soils[paste("EvapCoeff_L", ld, sep="")])			trco_grass <- as.numeric(i_sw_input_soils[paste("Grass_TranspCoeff_L", ld, sep="")])			trco_shrub <- as.numeric(i_sw_input_soils[paste("Shrub_TranspCoeff_L", ld, sep="")])			trco_tree <- as.numeric(i_sw_input_soils[paste("Tree_TranspCoeff_L", ld, sep="")])			trco_forb <- as.numeric(i_sw_input_soils[paste("Forb_TranspCoeff_L", ld, sep="")])			#normalize transpiration and evaporation coefficients from datafile			if(sum_use_evco) evco <- evco / ifelse((temp <- sum(evco, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_grass) trco_grass <- trco_grass / ifelse((temp <- sum(trco_grass, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_shrub) trco_shrub <- trco_shrub / ifelse((temp <- sum(trco_shrub, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_tree) trco_tree <- trco_tree / ifelse((temp <- sum(trco_tree, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_forb) trco_forb <- trco_forb / ifelse((temp <- sum(trco_forb, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			#compile soil information from both sources			#changed ncol to 12, and added "soil_temp" to colnames...			soildat <- matrix(data=NA, nrow=d, ncol=12)			colnames(soildat) <- c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")			for (l in ld){				soildat[l, ] <- c(	layers_depth.datafile[l],						ifelse(use_matricd[l], as.numeric(i_sw_input_soils[paste("Matricd_L", l, sep="")]), tempdat[l, "matricd"]),						ifelse(use_gravelC[l], as.numeric(i_sw_input_soils[paste("GravelContent_L", l, sep="")]), tempdat[l, "gravelContent"]),						ifelse(!is.na(temp <- ifelse(sum_use_evco, evco[l], tempdat[l, "evco"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_grass, trco_grass[l], tempdat[l, "trco_grass"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_shrub, trco_shrub[l], tempdat[l, "trco_shrub"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_tree, trco_tree[l], tempdat[l, "trco_tree"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_forb, trco_forb[l], tempdat[l, "trco_forb"])), temp, 0),						ifelse(use_sand[l], as.numeric(i_sw_input_soils[paste("Sand_L", l, sep="")]), tempdat[l, "sand"]),						ifelse(use_clay[l], as.numeric(i_sw_input_soils[paste("Clay_L", l, sep="")]), tempdat[l, "clay"]),						ifelse(!is.na(temp <- ifelse(use_imperm[l], as.numeric(i_sw_input_soils[paste("Imperm_L", l, sep="")]), tempdat[l, "imperm"])), temp, 0),						0	#soiltemp information may depend on climatic conditions; it will be only added after weather/climate scenarios are completed				)			}			if(adjust.soilDepth){#adjust deepest soil layer if there is no soil information for the lowest layers, but needs to recalculate soil layer structure				for(temp in d:1){					#TODO: bulkd to matricd?					if(all(!is.na(soildat[temp, "matricd"]), soildat[temp, "matricd"] > 0, !is.na(soildat[temp, "sand"]), soildat[temp, "sand"] > 0, !is.na(soildat[temp, "clay"]), soildat[temp, "clay"] > 0)) break				}				if(d != temp){					d <- temp					layers_depth <- adjustLayersDepth(layers_depth, d)					layers_width <- getLayersWidth(layers_depth)					ld <- setLayerSequence(d)					DeepestTopLayer <- setDeepestTopLayer(d)					topL <- setTopLayer(d)					bottomL <- setBottomLayer(d)				}			}			# Resize swSoils Layers to proper size			if(length(ld)==1) {				swSoils_Layers(swRunScenariosData[[1]]) <- matrix(data=swSoils_Layers(swRunScenariosData[[1]])[ld,], nrow=length(ld), ncol=12, byrow=TRUE, dimnames=list(numeric(),c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")))			} else {				if(nrow(swSoils_Layers(swRunScenariosData[[1]])) != d) {					if(nrow(swSoils_Layers(swRunScenariosData[[1]])) > d) {						swSoils_Layers(swRunScenariosData[[1]]) <- swSoils_Layers(swRunScenariosData[[1]])[ld,]					} else {						swSoils_Layers(swRunScenariosData[[1]]) <- rbind( swSoils_Layers(swRunScenariosData[[1]]), matrix(NA,nrow=d-nrow(swSoils_Layers(swRunScenariosData[[1]])), ncol=ncol(swSoils_Layers(swRunScenariosData[[1]]))) )					}				}			}			this_soil <- soildat[1, ]			for (l in ld){				if(all(soildat[l, c("matricd", "sand", "clay")] > 0, soildat[l, "gravelContent"] >= 0, !is.na(soildat[l, ]))){					this_soil <- soildat[l, ]				} else {					#swLog_setLine(swRunScenariosData[[1]]) <- missingtext					print(paste("Site", i_sim, i_labels, ": Layer ",l,": soil data missing for this layer -> data used from previous layer */"))					this_soil <- c(soildat[l, "depth"], this_soil[2:3], soildat[l, "evco"], soildat[l, "trco_grass"], soildat[l, "trco_shrub"], soildat[l, "trco_tree"], soildat[l,"trco_forb"], this_soil[9:10], soildat[l, "imperm"], soildat[l, "soiltemp"])				}				swSoils_Layers(swRunScenariosData[[1]])[l,] <- this_soil			}		}		# Check soil		this_soil <- swSoils_Layers(swRunScenariosData[[1]])		temp <- this_soil[, grep("depth", colnames(this_soil), ignore.case = TRUE)]		check_depth <- !is.na(temp) & temp > 0 & diff(c(0, temp)) > 0		temp <- this_soil[, grep("density", colnames(this_soil), ignore.case = TRUE)]		check_density <- !is.na(temp) & temp > 0.3 & temp <= 2.65		temp <- this_soil[, grep("gravel", colnames(this_soil), ignore.case = TRUE)]		check_gravel <- !is.na(temp) & temp >= 0 & temp < 1		temp <- this_soil[, grep("sand", colnames(this_soil), ignore.case = TRUE)]		check_sand <- !is.na(temp) & temp > 0 & temp <= 1		temp <- this_soil[, grep("clay", colnames(this_soil), ignore.case = TRUE)]		check_clay <- !is.na(temp) & temp > 0 & temp <= 1				if (!all(check_depth, check_density, check_gravel, check_sand, check_clay)) {			print(paste("Run:", i_sim, i_labels, ": soil data didn't pass quality test."))			print(this_soil)			tasks$create <- 0L		}		#add transpiration regions information to siteparamin		if(print.debug) print("Start of transpregion")		if(sum(use_transpregion) > 0){			tr <- max(tr.layers <- na.omit(as.numeric(i_sw_input_soils[paste("TranspRegion_L", ld, sep="")]))) # max transpiration region			TranspirationRegions <- matrix(data=NA,nrow=4,ncol=2)			colnames(TranspirationRegions)<-c("ndx","layer")			ltreg.last <- 0			for(tri in 1:4){				ltreg <- ifelse(length(ind <- which(tr.layers==tri)) > 0, max(ind), -1)				ltreg <- ifelse(ltreg>ltreg.last, ltreg, ltreg.last+1)				ltreg <- ifelse(ltreg>d & tri==1, d, ltreg)				if(tri <= tr & tri <= d & ltreg <= d | tri == 1) TranspirationRegions[tri,] <- as.integer(c(tri,ltreg))				ltreg.last <- ltreg			}			tr_rows<-rowSums(is.na(TranspirationRegions))!=2 #used to get rid of NA rows			if(sum(tr_rows) == 0) {				stop("Transpiration Regions in Site can not be empty")			} else if(sum(tr_rows) == 1) {				swSite_TranspirationRegions(swRunScenariosData[[1]]) <- matrix(data=TranspirationRegions[tr_rows,],nrow=1,ncol=2,byrow=T,dimnames=list(numeric(),c("ndx","layer")))				TRRG_done <- TRUE			} else {				swSite_TranspirationRegions(swRunScenariosData[[1]]) <- TranspirationRegions[tr_rows,]				TRRG_done <- TRUE			}		}		#add weather setup information to weatherin		if(sw_input_weather_use$SnowFlag)			swWeather_UseSnow(swRunScenariosData[[1]]) <- as.logical(i_sw_input_weather$SnowFlag)		if(sw_input_weather_use$SnowDrift_Percent)			swWeather_pct_SnowDrift(swRunScenariosData[[1]]) <- i_sw_input_weather$SnowDrift_Percent		if(sw_input_weather_use$RunOffOnPerSnowmelt_Percent)			swWeather_pct_SnowRunoff(swRunScenariosData[[1]]) <- i_sw_input_weather$RunOffOnPerSnowmelt_Percent		swWeather_FirstYearHistorical(swRunScenariosData[[1]]) <- simstartyr		swOUT_TimeStep(swRunScenariosData[[1]]) <- sapply(simulation_timescales, function(x) ifelse(x=="daily", 1, ifelse(x=="weekly", 2, ifelse(x=="monthly", 3, ifelse(x=="yearly",4,5)))) )-1		#############Get Weather Data################		if (print.debug) print("Start of daily weather")		i_sw_weatherList <- list()				.local_weatherDirName <- function(i_sim) {	# Get name of weather file from output database			con <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)			temp <- DBI::dbGetQuery(con, paste("SELECT WeatherFolder FROM header WHERE P_id=", it_Pid(i_sim, 1)))[1,1]			DBI::dbDisconnect(con)			temp		}		if (!getCurrentWeatherDataFromDatabase) {			if (i_SWRunInformation$dailyweather_source == "Maurer2002_NorthAmerica") {				dirname.sw.runs.weather <- with(i_SWRunInformation, create_filename_for_Maurer2002_NorthAmerica(X_WGS84, Y_WGS84))				i_sw_weatherList[[1]] <- ExtractGriddedDailyWeatherFromMaurer2002_NorthAmerica(cellname=dirname.sw.runs.weather,startYear=simstartyr, endYear=endyr)						} else if (i_SWRunInformation$dailyweather_source == "DayMet_NorthAmerica") {				i_sw_weatherList[[1]] <- with(i_SWRunInformation, ExtractGriddedDailyWeatherFromDayMet_NorthAmerica(site_ids = NULL, coords_WGS84 = c(X_WGS84, Y_WGS84), start_year = simstartyr, end_year = endyr))						} else if (i_SWRunInformation$dailyweather_source == "LookupWeatherFolder") {	# Read weather data from folder				i_sw_weatherList[[1]] <- try(getWeatherData_folders(						LookupWeatherFolder = file.path(dir.sw.in.tr, "LookupWeatherFolder"),						weatherDirName = .local_weatherDirName(i_sim),						filebasename = filebasename,						startYear = simstartyr,						endYear = endyr),					silent = TRUE)			}					} else {			#---Extract weather data			weather_label_cur <- try(.local_weatherDirName(i_sim), silent = TRUE)			if (is.na(weather_label_cur))				weather_label_cur <- try({function() stop("Output DB ", basename(name.OutputDB), " has no information about weather data for run ", i_sim)}(), silent = TRUE)			if (inherits(weather_label_cur, "try-error")) {				i_sw_weatherList <- weather_label_cur							} else {				.local <- function(i) {					# Extract weather data from db					dat <- list()					sn <- if (getScenarioWeatherDataFromDatabase) scenario_No else 1L					for (k in seq_len(sn)) {						dat[[k]] <- dbW_getWeatherData(Label = weather_label_cur,													startYear = simstartyr,													endYear = endyr,													Scenario = climate.conditions[k])					}									dat				}				dbW_setConnection(dbFilePath = dbWeatherDataFile)				i_sw_weatherList <- try(.local(i_sim), silent = TRUE)				dbW_disconnectConnection()			}		}				#Check that extraction of weather data was successful		if(inherits(i_sw_weatherList, "try-error") || length(i_sw_weatherList) == 0) {			if(!be.quiet) print(paste(i_sim, i_labels, "i_sw_weatherList ERROR:", i_sw_weatherList))			tasks$create <- 0L		}		#copy and make climate scenarios from datafiles		if(tasks$create > 0L) for(sc in 1:scenario_No){			if(sc > 1){				swRunScenariosData[[sc]] <- swRunScenariosData[[1]]			} else {				if(do.GetClimateMeans){					if(print.debug) print("Start of get SiteClimate")					do.C4vars <- any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") || aon$dailyC4_TempVar					#redo SiteClimate_Ambient					SiteClimate_Ambient <- sw_SiteClimate_Ambient(weatherList=i_sw_weatherList[[1]], year.start=min(simTime$useyrs), year.end=max(simTime$useyrs), do.C4vars=do.C4vars, simTime2=simTime2)					}			}			if(!getScenarioWeatherDataFromDatabase) {				#get climate change information				use_pptValscen <- sw_input_climscen_values_use[, pptVal.colnames <- paste("PPTmm_m", st_mo, "_sc", formatC(sc-1, width=2, format="d", flag="0"), sep="")]				use_tempValMinScen <- sw_input_climscen_values_use[, tempValMin.colnames <- paste("TempC_min_m", st_mo, "_sc", formatC(sc-1, width=2, format="d", flag="0"), sep="")]				use_tempValMaxScen <- sw_input_climscen_values_use[, tempValMax.colnames <- paste("TempC_max_m", st_mo, "_sc", formatC(sc-1, width=2, format="d", flag="0"), sep="")]				use_pptscen <- sw_input_climscen_use[, ppt.colnames <- paste("PPTfactor_m", st_mo, "_sc", formatC(sc-1, width=2, format="d", flag="0"), sep="")]				use_tempMinScen <- sw_input_climscen_use[, tempMin.colnames <- paste("deltaTempC_min_m", st_mo, "_sc", formatC(sc-1, width=2, format="d", flag="0"), sep="")]				use_tempMaxScen <- sw_input_climscen_use[, tempMax.colnames <- paste("deltaTempC_max_m", st_mo, "_sc", formatC(sc-1, width=2, format="d", flag="0"), sep="")]				if(	sum(use_pptValscen) + sum(use_tempValMinScen) + sum(use_tempValMaxScen) > 0){					#convert climate change values to factors					#read values from datafile					pptVal_sc <- unlist(i_sw_input_climscen_values[, pptVal.colnames])					tVal_min_sc <- unlist(i_sw_input_climscen_values[, tempValMin.colnames])					tVal_max_sc <- unlist(i_sw_input_climscen_values[, tempValMax.colnames])					#calculate change factors					ppt_sc <- pptVal_sc / (10 * SiteClimate_Ambient$meanMonthlyPPTcm)					if(sum(abs(tVal_max_sc - tVal_min_sc)) > sqrt(.Machine$double.eps)){						t_min_sc <- tVal_min_sc - SiteClimate_Ambient$minMonthlyTempC						t_max_sc <- tVal_max_sc - SiteClimate_Ambient$maxMonthlyTempC					} else { #no information for tmin, tmax by GCM -> tmin=tmax=tmean						t_min_sc <- t_max_sc <- tVal_min_sc - SiteClimate_Ambient$meanMonthlyTempC					}				} else if(	sum(use_pptscen) + sum(use_tempMinScen) + sum(use_tempMaxScen) > 0){					#read climate change factors from datafile					ppt_sc <- unlist(i_sw_input_climscen[, ppt.colnames])					t_min_sc <- unlist(i_sw_input_climscen[, tempMin.colnames])					t_max_sc <- unlist(i_sw_input_climscen[, tempMax.colnames])				} else {					ppt_sc <- rep(1, times=12)					t_min_sc <- rep(0, times=12)					t_max_sc <- rep(0, times=12)				}				#guarantee that all entries are finite: this may not be the case for instance if any(meanMonthlyClimate$meanMonthlyPPTcm == 0)				ppt_sc <- temp_ppt_sc <- ifelse(is.finite(ppt_sc), ppt_sc, 1)				t_min_sc <- ifelse(is.finite(t_min_sc), t_min_sc, 0)				t_max_sc <- ifelse(is.finite(t_max_sc), t_max_sc, 0)				if(sc > 1){					if(any(create_treatments=="ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone") && !grepl("Both", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)){						if(grepl("Mean", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							t_min_sc <- rep(mean(t_min_sc), times=12)							t_max_sc <- rep(mean(t_max_sc), times=12)						}						if(grepl("Seasonality", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							t_min_sc <- t_min_sc - mean(t_min_sc)							t_max_sc <- t_max_sc - mean(t_max_sc)						}						if(grepl("None", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							t_min_sc <- rep(0, times=12)							t_max_sc <- rep(0, times=12)						}					}					if(any(create_treatments=="ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone") && !grepl("Both", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)){						temp_map_sc <- sum(SiteClimate_Ambient$meanMonthlyPPTcm * temp_ppt_sc)						if(grepl("Mean", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) ppt_sc = rep(temp_map_sc / SiteClimate_Ambient$MAP_cm, times=12)						if(grepl("Seasonality", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) ppt_sc = ppt_sc * SiteClimate_Ambient$MAP_cm / temp_map_sc						if(grepl("None", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) ppt_sc = rep(1, times=12)					}				}				ppt_old <- (temp <- swWeather_MonScalingParams(swRunScenariosData[[sc]]))[,1]				t_max_old <- temp[,2]				t_min_old <- temp[,3]				#write information into weatherin				if(sum(use_pptValscen) + sum(use_tempValMinScen) + sum(use_tempValMaxScen) + sum(use_pptscen) + sum(use_tempMinScen) + sum(use_tempMaxScen) > 0){					ppt_f <- ppt_sc					t_min_f <- t_min_sc					t_max_f <- t_max_sc				} else {					ppt_f <- ppt_old					t_min_f <- t_min_old					t_max_f <- t_max_old				}				MonthlyScalingParams<-matrix(data=c(ppt_f,t_max_f,t_min_f),nrow=12,ncol=3)				colnames(MonthlyScalingParams)<-c("PPT","MaxT","MinT")				rownames(MonthlyScalingParams)<-c("January","February","March","April","May","June","July","August","September","October","November","December")				swWeather_MonScalingParams(swRunScenariosData[[sc]])[, 1:3] <- MonthlyScalingParams				ClimatePerturbationsVals[sc,1:12] <- MonthlyScalingParams[,1]				ClimatePerturbationsVals[sc,13:24] <- MonthlyScalingParams[,2]				ClimatePerturbationsVals[sc,25:36] <- MonthlyScalingParams[,3]				#Update climate data with climate scenario information				if(do.GetClimateMeans){					SiteClimate_Scenario <- list()					SiteClimate_Scenario$meanMonthlyPPTcm <- SiteClimate_Ambient$meanMonthlyPPTcm * ppt_f					tmean_f <- apply(cbind(t_min_f, t_max_f), MARGIN=1, FUN=mean)					SiteClimate_Scenario$meanMonthlyTempC <- SiteClimate_Ambient$meanMonthlyTempC + tmean_f					SiteClimate_Scenario$minMonthlyTempC <- SiteClimate_Ambient$minMonthlyTempC + t_min_f					SiteClimate_Scenario$maxMonthlyTempC <- SiteClimate_Ambient$maxMonthlyTempC + t_max_f					SiteClimate_Scenario$MAP_cm <- sum(SiteClimate_Scenario$meanMonthlyPPTcm)					SiteClimate_Scenario$MAT_C <- mean(SiteClimate_Scenario$meanMonthlyTempC)					if(do.C4vars){						SiteClimate_Scenario$dailyTempMin <- SiteClimate_Ambient$dailyTempMin + t_min_f[simTime2$month_ForEachUsedDay]						SiteClimate_Scenario$dailyTempMean <- SiteClimate_Ambient$dailyTempMean + tmean_f[simTime2$month_ForEachUsedDay]						SiteClimate_Scenario$dailyC4vars <- sw_dailyC4_TempVar(SiteClimate_Scenario$dailyTempMin, SiteClimate_Scenario$dailyTempMean, simTime2)					}				}			} else {				SiteClimate_Scenario <- sw_SiteClimate_Ambient(weatherList=i_sw_weatherList[[sc]], year.start=min(simTime$useyrs), year.end=max(simTime$useyrs), do.C4vars=do.C4vars, simTime2=simTime2)				if(sc > 1){					ppt_sc <- (temp <- swWeather_MonScalingParams(swRunScenariosData[[sc]]))[,1]					t_max <- temp[,2]					t_min <- temp[,3]					if(any(create_treatments=="ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone") && !grepl("Both", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)){						if(grepl("Mean", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							# -(mean monthly of scenario - mean monthly of current) + (mean annual of scenario - mean annual of current)							t_min <- -(SiteClimate_Scenario$minMonthlyTempC - SiteClimate_Ambient$minMonthlyTempC) + (SiteClimate_Scenario$MAT_C - SiteClimate_Ambient$MAT_C)							t_max <- -(SiteClimate_Scenario$maxMonthlyTempC - SiteClimate_Ambient$maxMonthlyTempC) + (SiteClimate_Scenario$MAT_C - SiteClimate_Ambient$MAT_C)						}						if(grepl("Seasonality", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							# -(mean annual of scenario - mean annual of current)							t_min <- rep(-(SiteClimate_Scenario$MAT_C - SiteClimate_Ambient$MAT_C),12)							t_max <- rep(-(SiteClimate_Scenario$MAT_C - SiteClimate_Ambient$MAT_C),12)						}						if(grepl("None", i_sw_input_treatments$ClimateScenario_Temp_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							# -(mean monthly of scenario - mean monthly of current)							t_min <- -(SiteClimate_Scenario$minMonthlyTempC - SiteClimate_Ambient$minMonthlyTempC)							t_max <- -(SiteClimate_Scenario$maxMonthlyTempC - SiteClimate_Ambient$maxMonthlyTempC)						}					}					if(any(create_treatments=="ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone") && !grepl("Both", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)){						if(grepl("Mean", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							#Mean of weather == mean of scenario, seasonality of weather = seasonality of ambient							if(isTRUE(all.equal(SiteClimate_Ambient$MAP_cm, 0))){								SiteClimate_Ambient$MAP_cm <- sqrt(.Machine$double.eps)								if(isTRUE(all.equal(SiteClimate_Scenario$MAP_cm, 0))){									SiteClimate_Scenario$MAP_cm <- sqrt(.Machine$double.eps)									ppt_sc <- rep(0, times=12)								} else {									warning("Problem with scaling to 'mean' for ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone because of zero precipitation periods")								}							}							if(sum(ppt_sc) > 0){								if(sum(temp <- sapply(SiteClimate_Scenario$meanMonthlyPPTcm, FUN=function(x) isTRUE(all.equal(x, 0)))) > 0){									warning("Problem with scaling to 'mean' for ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone because of zero precipitation periods")									SiteClimate_Scenario$meanMonthlyPPTcm[temp] <- sqrt(.Machine$double.eps)								}								ppt_sc <- (SiteClimate_Ambient$meanMonthlyPPTcm / SiteClimate_Scenario$meanMonthlyPPTcm) * (SiteClimate_Scenario$MAP_cm / SiteClimate_Ambient$MAP_cm)							}						}						if(grepl("Seasonality", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							#Mean of weather == mean of ambient, seasonality of weather = seasonality of scenario							if(isTRUE(all.equal(SiteClimate_Scenario$MAP_cm, 0))){								SiteClimate_Scenario$MAP_cm <- sqrt(.Machine$double.eps)								if(isTRUE(all.equal(SiteClimate_Ambient$MAP_cm, 0))){									SiteClimate_Ambient$MAP_cm <- sqrt(.Machine$double.eps)									ppt_sc <- rep(0, times=12)								} else {									warning("Problem with scaling to 'mean' for ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone because of zero precipitation periods")								}							}							if(sum(ppt_sc) > 0){								ppt_sc <- rep((SiteClimate_Ambient$MAP_cm / SiteClimate_Scenario$MAP_cm),12)							}						}						if(grepl("None", i_sw_input_treatments$ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone, ignore.case=T)) {							#Mean of weather == mean of ambient, seasonality of weather = seasonality of ambient							if(isTRUE(all.equal(SiteClimate_Ambient$MAP_cm, 0)) && isTRUE(all.equal(SiteClimate_Scenario$MAP_cm, 0))){								SiteClimate_Ambient$MAP_cm <- SiteClimate_Scenario$MAP_cm <- sqrt(.Machine$double.eps)								ppt_sc <- rep(0, times=12)							}							if(sum(ppt_sc) > 0){								if(sum(temp <- sapply(SiteClimate_Scenario$meanMonthlyPPTcm, FUN=function(x) isTRUE(all.equal(x, 0)))) > 0){									warning("Problem with scaling to 'mean' for ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone because of zero precipitation periods")									SiteClimate_Scenario$meanMonthlyPPTcm[temp] <- sqrt(.Machine$double.eps)								}								ppt_sc <- (SiteClimate_Ambient$meanMonthlyPPTcm / SiteClimate_Scenario$meanMonthlyPPTcm)							}						}					}					if(sum(temp <- sapply(SiteClimate_Ambient$meanMonthlyPPTcm, FUN=function(x) isTRUE(all.equal(x, 0)))) > 0){						warning("Problem with scaling to 'mean' for ClimateScenario_PPT_PerturbationInMeanSeasonalityBothOrNone because of zero precipitation periods")						SiteClimate_Ambient$meanMonthlyPPTcm[temp] <- sqrt(.Machine$double.eps)					}					swWeather_MonScalingParams(swRunScenariosData[[sc]])[,1] <- ppt_sc					swWeather_MonScalingParams(swRunScenariosData[[sc]])[,2] <- t_max					swWeather_MonScalingParams(swRunScenariosData[[sc]])[,3] <- t_min					ClimatePerturbationsVals[sc,1:12] <- ppt_sc * SiteClimate_Scenario$meanMonthlyPPTcm / SiteClimate_Ambient$meanMonthlyPPTcm					ClimatePerturbationsVals[sc,13:24] <- t_max + (SiteClimate_Scenario$maxMonthlyTempC - SiteClimate_Ambient$maxMonthlyTempC)					ClimatePerturbationsVals[sc,25:36] <- t_min + (SiteClimate_Scenario$minMonthlyTempC - SiteClimate_Ambient$minMonthlyTempC)				}			}			if(any(create_treatments=="LookupShiftedPPTScenarios")){				ppt_f <- swWeather_MonScalingParams(swRunScenariosData[[sc]])[,1]				ppt_f <- ppt_f * as.numeric(ppt_scShift)				swWeather_MonScalingParams(swRunScenariosData[[sc]])[,1] <- ppt_f				if(getScenarioWeatherDataFromDatabase){					ClimatePerturbationsVals[sc,1:12] <- ppt_f * ClimatePerturbationsVals[sc,1:12]				} else {					ClimatePerturbationsVals[sc,1:12] <- ppt_f				}			}			#anything that depends on weather			#------3. Step: Lookup or extract external information that needs to be executed for each run			if(print.debug) print("Start of set soil temperature")			#TODO get this working LOW PR			if(pcalcs$EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature){				soilTlower <- mean(SiteClimate_Scenario$meanMonthlyTempC)				soilTUpper <- max(-1, mean(SiteClimate_Scenario$meanMonthlyTempC[c(1,12)]))				#temporaly save data				#out.temp <- data.frame(i_sim, i_labels, soilTUpper, soilTlower)				#write.csv(out.temp, file=paste(dir.out.temp, .Platform$file.sep, flag.icounter, "_", "SoilTempC_atLowerBoundary.csv", sep=""), quote=FALSE, row.names=FALSE)			}			if(sw_input_site_use$SoilTempC_atUpperBoundary) {				soilTUpper <- ifelse(exists("soilTUpper"), soilTUpper, i_sw_input_site$SoilTempC_atUpperBoundary)			}			if(sw_input_site_use$SoilTempC_atLowerBoundary){				soilTlower <- ifelse(exists("soilTlower"), soilTlower, i_sw_input_site$SoilTempC_atLowerBoundary)				swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])[8] <- soilTlower			}			if(pcalcs$EstimateInitialSoilTemperatureForEachSoilLayer){				init.soilTprofile <- EstimateInitialSoilTemperatureForEachSoilLayer(layers_depth=layers_depth, lower.Tdepth=as.numeric(swRunScenariosData[[sc]]@site@SoilTemperatureConstants[10]), soilTupper=soilTUpper, soilTlower=soilTlower)	#lower.Tdepth needs to be adjusted if it changes in soilparam.in				#temporaly save data #TODO get this working				#out.temp <- data.frame(i_sim, i_labels, t(c(init.soilTprofile, rep(NA, times=SoilLayer_MaxNo-length(init.soilTprofile)))))				#write.csv(out.temp, file=paste(dir.out.temp, .Platform$file.sep, flag.icounter, "_", "SoilTempC_InitProfile.csv", sep=""), quote=FALSE, row.names=FALSE)			}			#adjust init soil temperatures to climatic conditions			if(any(use_soil_temp <- as.logical(sw_input_soils_use[paste("SoilTemp_L", ld, sep="")]))){				temp <- 1:nrow(swSoils_Layers(swRunScenariosData[[sc]]))				if(exists("init.soilTprofile")) {					swSoils_Layers(swRunScenariosData[[sc]])[,12][use_soil_temp] <- init.soilTprofile				} else {					swSoils_Layers(swRunScenariosData[[sc]])[,12][use_soil_temp] <- as.numeric(i_sw_input_soils[paste("SoilTemp_L", temp, sep="")])				}			}			#- Calculate relative composition based on equations			if(print.debug) print("Start of PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996")			if(any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") && i_sw_input_treatments$PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996){				#Climate variables				if(any(create_treatments == "PotentialNaturalVegetation_Composition_basedOnReferenceOrScenarioClimate") && i_sw_input_treatments$PotentialNaturalVegetation_Composition_basedOnReferenceOrScenarioClimate=="Reference"){					MAP_mm <- SiteClimate_Ambient$MAP_cm*10					MAT_C <- SiteClimate_Ambient$MAT_C					monthly.ppt <- SiteClimate_Ambient$meanMonthlyPPTcm*10					monthly.temp <- SiteClimate_Ambient$meanMonthlyTempC					dailyC4vars <- SiteClimate_Ambient$dailyC4vars				} else {					MAP_mm <- SiteClimate_Scenario$MAP_cm*10					MAT_C <- SiteClimate_Scenario$MAT_C					monthly.ppt <- SiteClimate_Scenario$meanMonthlyPPTcm*10					monthly.temp <- SiteClimate_Scenario$meanMonthlyTempC					dailyC4vars <- SiteClimate_Scenario$dailyC4vars				}				#Rsoilwat				isNorth <-i_SWRunInformation$Y_WGS84 >= 0				use_Annuals_Fraction <- any(create_treatments == "PotentialNaturalVegetation_CompositionAnnuals_Fraction")				Annuals_Fraction <- i_sw_input_treatments$PotentialNaturalVegetation_CompositionAnnuals_Fraction				use_C4_Fraction <- any(create_treatments == "PotentialNaturalVegetation_CompositionC4_Fraction")				C4_Fraction <- i_sw_input_treatments$PotentialNaturalVegetation_CompositionC4_Fraction				use_C3_Fraction <- any(create_treatments == "PotentialNaturalVegetation_CompositionC3_Fraction")				C3_Fraction <- i_sw_input_treatments$PotentialNaturalVegetation_CompositionC3_Fraction				use_Shrubs_Fraction <- any(create_treatments == "PotentialNaturalVegetation_CompositionShrubs_Fraction")				Shrubs_Fraction <- i_sw_input_treatments$PotentialNaturalVegetation_CompositionShrubs_Fraction				use_Forbs_Fraction <- any(create_treatments == "PotentialNaturalVegetation_CompositionForb_Fraction")				Forbs_Fraction <- i_sw_input_treatments$PotentialNaturalVegetation_CompositionForb_Fraction				use_BareGround_Fraction <- any(create_treatments == "PotentialNaturalVegetation_CompositionBareGround_Fraction")				BareGround_Fraction <- i_sw_input_treatments$PotentialNaturalVegetation_CompositionBareGround_Fraction				#TODO: Include forbs or bareground in PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996				#save(SiteClimate_Ambient,SiteClimate_Scenario,MAP_mm,MAT_C,monthly.ppt,monthly.temp,dailyC4vars,isNorth,use_Annuals_Fraction, Annuals_Fraction,use_C4_Fraction, C4_Fraction,use_C3_Fraction, C3_Fraction,use_Shrubs_Fraction, Shrubs_Fraction,shrub.fraction.limit,file=file.path(dir.sw.runs, paste("Rsoilwat_composition_",i_sim,"_",sc,sep="")))				temp <- try(PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996(MAP_mm,MAT_C,monthly.ppt,monthly.temp,dailyC4vars,isNorth,shrub.fraction.limit,						use_Annuals_Fraction, Annuals_Fraction,						use_C4_Fraction, C4_Fraction,						use_C3_Fraction, C3_Fraction,						use_Shrubs_Fraction, Shrubs_Fraction,						use_Forbs_Fraction, Forbs_Fraction,						use_BareGround_Fraction, BareGround_Fraction), silent=TRUE)				if(inherits(temp, "try-error")){					tasks$create <- 0L				} else {					grass.fraction <- temp$Composition[1]					swProd_Composition(swRunScenariosData[[sc]]) <- temp$Composition					grasses.c3c4ann.fractions[[sc]] <- temp$grasses.c3c4ann.fractions				}			}			if(print.debug) print("Start of biomass adjustments")			if(any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") && i_sw_input_treatments$PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996 && ((any(create_treatments == "AdjMonthlyBioMass_Temperature") && i_sw_input_treatments$AdjMonthlyBioMass_Temperature) | (any(create_treatments == "AdjMonthlyBioMass_Precipitation") &&  i_sw_input_treatments$AdjMonthlyBioMass_Precipitation) )){				adjTemp <- any(create_treatments == "AdjMonthlyBioMass_Temperature") && i_sw_input_treatments$AdjMonthlyBioMass_Temperature				adjPrep <- any(create_treatments == "AdjMonthlyBioMass_Precipitation") & i_sw_input_treatments$AdjMonthlyBioMass_Precipitation				temp<-AdjMonthlyBioMass(tr_VegetationComposition=tr_VegetationComposition, AdjMonthlyBioMass_Temperature=adjTemp, AdjMonthlyBioMass_Precipitation=adjPrep, grasses.c3c4ann.fractions=grasses.c3c4ann.fractions[[sc]],growing.season.threshold.tempC=growing.season.threshold.tempC,isNorth=isNorth,MAP_mm=MAP_mm,monthly.temp=monthly.temp)				swProd_MonProd_grass(swRunScenariosData[[sc]])[,1:3] <- temp$grass[,1:3]				swProd_MonProd_shrub(swRunScenariosData[[sc]])[,1:3] <- temp$shrub[,1:3]				rm(adjTemp,adjPrep)			}			#adjust Root Profile - need composition fractions set above			if(print.debug) print("Start of AdjRootProfile")			if(any(create_treatments == "AdjRootProfile") && i_sw_input_treatments$AdjRootProfile && any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") && i_sw_input_treatments$PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996) {				trco_type_C3 <- ifelse(any(create_treatments == "RootProfile_C3") && any(colnames(tr_input_TranspCoeff) == i_sw_input_treatments$RootProfile_C3), i_sw_input_treatments$RootProfile_C3, "SchenkJackson2003_PCdry_grasses")				trco_type_C4 <- ifelse(any(create_treatments == "RootProfile_C4") && any(colnames(tr_input_TranspCoeff) == i_sw_input_treatments$RootProfile_C4), i_sw_input_treatments$RootProfile_C4, "SchenkJackson2003_PCdry_grasses")				trco_type_annuals <- ifelse(any(create_treatments == "RootProfile_Annuals") && any(colnames(tr_input_TranspCoeff) == i_sw_input_treatments$RootProfile_Annuals), i_sw_input_treatments$RootProfile_Annuals, "Jacksonetal1996_crops")				trco_type_shrubs <- ifelse(any(create_treatments == "RootProfile_Shrubs") && any(colnames(tr_input_TranspCoeff) == i_sw_input_treatments$RootProfile_Shrubs), i_sw_input_treatments$RootProfile_Shrubs, "SchenkJackson2003_PCdry_shrubs")				tro_type_forb <- ifelse(any(create_treatments == "RootProfile_Forbs") && any(colnames(tr_input_TranspCoeff) == i_sw_input_treatments$RootProfile_Forbs), i_sw_input_treatments$RootProfile_Forbs, "SchenkJackson2003_PCdry_forbs")#TODO: add 'SchenkJackson2003_PCdry_forbs' to 'TranspirationCoefficients_v2.csv'				tro_type_tree <- ifelse(any(create_treatments == "LookupTranspCoeffFromTable_Tree") && is.finite(i_sw_input_treatments$LookupTranspCoeffFromTable_Tree) && any(colnames(tr_input_TranspCoeff) == i_sw_input_treatments$LookupTranspCoeffFromTable_Tree), i_sw_input_treatments$LookupTranspCoeffFromTable_Tree, "FILL")				#TODO: Adjust trco_type_forb?				if(grass.fraction==0) { #if grass.fraction is 0 then Grass.trco will be 0					Grass.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type="FILL", layers_depth=layers_depth, adjustType="positive")				} else {					C3.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=trco_type_C3, layers_depth=layers_depth, adjustType="positive")					C4.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=trco_type_C4, layers_depth=layers_depth, adjustType="positive")					Annuals.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=trco_type_annuals, layers_depth=layers_depth, adjustType="positive")					Grass.trco <- C3.trco * grasses.c3c4ann.fractions[[sc]][1] + C4.trco * grasses.c3c4ann.fractions[[sc]][2] + Annuals.trco * grasses.c3c4ann.fractions[[sc]][3]				}				if(is.na(sum(Grass.trco))) Grass.trco <- rep(0, d)				Shrub.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=trco_type_shrubs, layers_depth=layers_depth, adjustType="inverse")				Tree.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=tro_type_tree, layers_depth=layers_depth, adjustType="inverse")				Forb.trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=tro_type_forb, layers_depth=layers_depth, adjustType="inverse")				swSoils_Layers(swRunScenariosData[[sc]])[,5] <- Grass.trco				swSoils_Layers(swRunScenariosData[[sc]])[,6] <- Shrub.trco				swSoils_Layers(swRunScenariosData[[sc]])[,7] <- Tree.trco				swSoils_Layers(swRunScenariosData[[sc]])[,8] <- Forb.trco				TRCO_done <- TRUE			}			if(print.debug) print("Start of vegetation scaling")			Grass_Scaling_use <- c("Grass_TotalBiomass_ScalingFactor", "Grass_LiveBiomass_ScalingFactor", "Grass_Litter_ScalingFactor")			Shrub_Scaling_use <- c("Shrub_TotalBiomass_ScalingFactor", "Shrub_LiveBiomass_ScalingFactor", "Shrub_Litter_ScalingFactor")			Tree_Scaling_use <- c("Tree_TotalBiomass_ScalingFactor", "Tree_LiveBiomass_ScalingFactor", "Tree_Litter_ScalingFactor")			Forb_Scaling_use <- c("Forb_TotalBiomass_ScalingFactor", "Forb_LiveBiomass_ScalingFactor", "Forb_Litter_ScalingFactor")			if(any(create_treatments %in% c(Grass_Scaling_use, Shrub_Scaling_use, Tree_Scaling_use, Forb_Scaling_use))){				finite01 <- function(x) {x[x < 0 | is.na(x)] <- 0; x[x > 1] <- 1; return(x)}				grass_LitterTotalLiveScalingFactors <- rep(1, 3)				if(any(create_treatments == "Grass_Litter_ScalingFactor") && is.finite(i_sw_input_treatments$Grass_Litter_ScalingFactor))					grass_LitterTotalLiveScalingFactors[1] <- i_sw_input_treatments$Grass_Litter_ScalingFactor				if(any(create_treatments == "Grass_TotalBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Grass_TotalBiomass_ScalingFactor))					grass_LitterTotalLiveScalingFactors[2] <- i_sw_input_treatments$Grass_TotalBiomass_ScalingFactor				if(any(create_treatments == "Grass_LiveBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Grass_LiveBiomass_ScalingFactor))					grass_LitterTotalLiveScalingFactors[3] <- i_sw_input_treatments$Grass_LiveBiomass_ScalingFactor				shrub_LitterTotalLiveScalingFactors <- rep(1, 3)				if(any(create_treatments == "Shrub_Litter_ScalingFactor") && is.finite(i_sw_input_treatments$Shrub_Litter_ScalingFactor))					shrub_LitterTotalLiveScalingFactors[1] <- i_sw_input_treatments$Shrub_Litter_ScalingFactor				if(any(create_treatments == "Shrub_TotalBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Shrub_TotalBiomass_ScalingFactor))					shrub_LitterTotalLiveScalingFactors[2] <- i_sw_input_treatments$Shrub_TotalBiomass_ScalingFactor				if(any(create_treatments == "Shrub_LiveBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Shrub_LiveBiomass_ScalingFactor))					shrub_LitterTotalLiveScalingFactors[3] <- i_sw_input_treatments$Shrub_LiveBiomass_ScalingFactor				tree_LitterTotalLiveScalingFactors <- rep(1, 3)				if(any(create_treatments == "Tree_Litter_ScalingFactor") && is.finite(i_sw_input_treatments$Tree_Litter_ScalingFactor))					tree_LitterTotalLiveScalingFactors[1] <- i_sw_input_treatments$Tree_Litter_ScalingFactor				if(any(create_treatments == "Tree_TotalBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Tree_TotalBiomass_ScalingFactor))					tree_LitterTotalLiveScalingFactors[2] <- i_sw_input_treatments$Tree_TotalBiomass_ScalingFactor				if(any(create_treatments == "Tree_LiveBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Tree_LiveBiomass_ScalingFactor))					tree_LitterTotalLiveScalingFactors[3] <- i_sw_input_treatments$Tree_LiveBiomass_ScalingFactor				forb_LitterTotalLiveScalingFactors <- rep(1, 3)				if(any(create_treatments == "Forb_Litter_ScalingFactor") && is.finite(i_sw_input_treatments$Forb_Litter_ScalingFactor))					forb_LitterTotalLiveScalingFactors[1] <- i_sw_input_treatments$Forb_Litter_ScalingFactor				if(any(create_treatments == "Forb_TotalBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Forb_TotalBiomass_ScalingFactor))					forb_LitterTotalLiveScalingFactors[2] <- i_sw_input_treatments$Forb_TotalBiomass_ScalingFactor				if(any(create_treatments == "Forb_LiveBiomass_ScalingFactor") && is.finite(i_sw_input_treatments$Forb_LiveBiomass_ScalingFactor))					forb_LitterTotalLiveScalingFactors[3] <- i_sw_input_treatments$Forb_LiveBiomass_ScalingFactor				ScalingSeason <- i_sw_input_treatments$Vegetation_Biomass_ScalingSeason_AllGrowingORNongrowing				if(is.na(ScalingSeason) || !any(c("All", "Growing", "Nongrowing") == ScalingSeason)) #set to All for default					ScalingSeason <- "All"				if(any(create_treatments == "Vegetation_Biomass_ScalingSeason_AllGrowingORNongrowing") && !is.na(ScalingSeason) && !(any(create_treatments == "Vegetation_Biomass_ScalingSeason_AllGrowingORNongrowing") && ScalingSeason == "All")) {					if(ScalingSeason == "Growing") { #Growing: apply 'Vegetation_Biomass_ScalingFactor' only to those months that have MAT > growing.season.threshold.tempC						if((templength<-length((temp<-SiteClimate_Scenario$meanMonthlyTempC>growing.season.threshold.tempC)[temp==TRUE]))>1) {							swProd_MonProd_grass(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_grass(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", grass_LitterTotalLiveScalingFactors)							swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", shrub_LitterTotalLiveScalingFactors)							swProd_MonProd_tree(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_tree(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", tree_LitterTotalLiveScalingFactors)							swProd_MonProd_forb(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_forb(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", forb_LitterTotalLiveScalingFactors)						} else if(templength==1) {							swProd_MonProd_grass(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_grass(swRunScenariosData[[sc]])[temp,1:3]*grass_LitterTotalLiveScalingFactors							swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp,1:3]*shrub_LitterTotalLiveScalingFactors							swProd_MonProd_tree(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_tree(swRunScenariosData[[sc]])[temp,1:3]*tree_LitterTotalLiveScalingFactors							swProd_MonProd_forb(swRunScenariosData[[sc]])[temp, 1:3] <-swProd_MonProd_forb(swRunScenariosData[[sc]])[temp, 1:3]*forb_LitterTotalLiveScalingFactors						} else {							print("To Cold to do Vegetation Scaling Season for Growing")						}					} else if(ScalingSeason == "Nongrowing") {# Nongrowing: apply 'Vegetation_Biomass_ScalingFactor' only to those months that have MAT <= growing.season.threshold.tempC						if((templength<-length((temp<-SiteClimate_Scenario$meanMonthlyTempC<=growing.season.threshold.tempC)[temp==TRUE]))>1) {							swProd_MonProd_grass(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_grass(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", grass_LitterTotalLiveScalingFactors)							swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", shrub_LitterTotalLiveScalingFactors)							swProd_MonProd_tree(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_tree(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", tree_LitterTotalLiveScalingFactors)							swProd_MonProd_forb(swRunScenariosData[[sc]])[temp, 1:3] <- sweep(swProd_MonProd_forb(swRunScenariosData[[sc]])[temp, 1:3], MARGIN=2, FUN="*", forb_LitterTotalLiveScalingFactors)						} else if (templength==1) {							swProd_MonProd_grass(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_grass(swRunScenariosData[[sc]])[temp,1:3]*grass_LitterTotalLiveScalingFactors							swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_shrub(swRunScenariosData[[sc]])[temp,1:3]*shrub_LitterTotalLiveScalingFactors							swProd_MonProd_tree(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_tree(swRunScenariosData[[sc]])[temp,1:3]*tree_LitterTotalLiveScalingFactors							swProd_MonProd_forb(swRunScenariosData[[sc]])[temp,1:3]<-swProd_MonProd_forb(swRunScenariosData[[sc]])[temp,1:3]*forb_LitterTotalLiveScalingFactors						} else {							print("To Hot to do Vegetation Scaling Season for NonGrowing")						}					}				} else {					swProd_MonProd_grass(swRunScenariosData[[sc]])[, 1:3] <- sweep(swProd_MonProd_grass(swRunScenariosData[[sc]])[, 1:3], MARGIN=2, FUN="*", grass_LitterTotalLiveScalingFactors)					swProd_MonProd_shrub(swRunScenariosData[[sc]])[, 1:3] <- sweep(swProd_MonProd_shrub(swRunScenariosData[[sc]])[, 1:3], MARGIN=2, FUN="*", shrub_LitterTotalLiveScalingFactors)					swProd_MonProd_tree(swRunScenariosData[[sc]])[, 1:3] <- sweep(swProd_MonProd_tree(swRunScenariosData[[sc]])[, 1:3], MARGIN=2, FUN="*", tree_LitterTotalLiveScalingFactors)					swProd_MonProd_forb(swRunScenariosData[[sc]])[, 1:3] <- sweep(swProd_MonProd_forb(swRunScenariosData[[sc]])[, 1:3], MARGIN=2, FUN="*", forb_LitterTotalLiveScalingFactors)				}				swProd_MonProd_grass(swRunScenariosData[[sc]])[, 3] <- finite01(swProd_MonProd_grass(swRunScenariosData[[sc]])[, 3])  #Check that live biomass fraction <= 1 & >= 0				swProd_MonProd_shrub(swRunScenariosData[[sc]])[, 3] <- finite01(swProd_MonProd_shrub(swRunScenariosData[[sc]])[, 3])  #Check that live biomass fraction <= 1 & >= 0				swProd_MonProd_tree(swRunScenariosData[[sc]])[, 3] <- finite01(swProd_MonProd_tree(swRunScenariosData[[sc]])[, 3])  #Check that live biomass fraction <= 1 & >= 0				swProd_MonProd_forb(swRunScenariosData[[sc]])[, 3] <- finite01(swProd_MonProd_forb(swRunScenariosData[[sc]])[, 3])  #Check that live biomass fraction <= 1 & >= 0			}			if(any(create_treatments == "Vegetation_Height_ScalingFactor")) {				#scale constant height				swProd_CanopyHeight(swRunScenariosData[[sc]])[5, ] <- pmax(0, swProd_CanopyHeight(swRunScenariosData[[sc]])[5, ] * i_sw_input_treatments$Vegetation_Height_ScalingFactor)				#scale tanfunc parameters: scale yinflec and range, leave xinflec and slope as is				swProd_CanopyHeight(swRunScenariosData[[sc]])[2:3, ] <- pmax(0, swProd_CanopyHeight(swRunScenariosData[[sc]])[2:3, ] * i_sw_input_treatments$Vegetation_Height_ScalingFactor)			}			#if southern hemisphere adjust if set, but not when already adjusted by, e.g., growing season			if(print.debug) print("Start of hemisphere adjustment")			if(accountNSHemispheres_veg && i_SWRunInformation$Y_WGS84 < 0 && !any(create_treatments == "AdjMonthlyBioMass_Temperature")){				swProd_MonProd_grass(swRunScenariosData[[sc]])[, 3] <- rbind(swProd_MonProd_grass(swRunScenariosData[[sc]])[7:12,], swProd_MonProd_grass(swRunScenariosData[[sc]])[1:6,])				swProd_MonProd_shrub(swRunScenariosData[[sc]])[, 3] <- rbind(swProd_MonProd_shrub(swRunScenariosData[[sc]])[7:12,], swProd_MonProd_shrub(swRunScenariosData[[sc]])[1:6,])				swProd_MonProd_tree(swRunScenariosData[[sc]])[, 3] <- rbind(swProd_MonProd_tree(swRunScenariosData[[sc]])[7:12,], swProd_MonProd_tree(swRunScenariosData[[sc]])[1:6,])				swProd_MonProd_forb(swRunScenariosData[[sc]])[, 3] <- rbind(swProd_MonProd_forb(swRunScenariosData[[sc]])[7:12,], swProd_MonProd_forb(swRunScenariosData[[sc]])[1:6,])			}			#--control transpiration regions for adjusted soil depth and rooting depth			if(print.debug) print("Start of control transpiration regions")			tri.file <- matrix(NA, nrow=4, ncol=2, dimnames=list(NULL, c("Used_TF", "DeepestLayer")))			for(tri in 1:4){				if(tri <= nrow(swSite_TranspirationRegions(swRunScenariosData[[sc]]))) {					tri.file[tri, 2] <- swSite_TranspirationRegions(swRunScenariosData[[sc]])[tri,2]					tri.file[tri, 1] <- 1				} else {					tri.file[tri, 2] <- NA#swSite_TranspirationRegions(swRunScenariosData[[sc]])[tri-1,2]+1					tri.file[tri, 1] <- 0				}			}			#get soil depth			max.tri.soil <- length(layers_depth)			#get rooting depth			if(nrow(swSoils_Layers(swRunScenariosData[[sc]])) > 1){				max.tri.root <- min(apply(swSoils_Layers(swRunScenariosData[[sc]])[, c(6,7,8), drop=FALSE], MARGIN=2, FUN=function(x) sum(x > 0)))			} else {				max.tri.root <- 1			}			#adjust maximum transpiration region for minimum soil depth and rooting depth			if(max(tri.file[tri.file[, 1] > 0, 2], na.rm=TRUE) > (max.tri <- min(max.tri.soil, max.tri.root))){				for(tri in 4:1) if(tri.file[tri, 1] > 0){						if(tri.file[tri, 2] > max.tri)							tri.file[tri, 2] <- swSite_TranspirationRegions(swRunScenariosData[[sc]])[tri,2] <- max.tri						if(tri > 1 && tri.file[tri, 2] <= tri.file[tri-1, 2])							swSite_TranspirationRegions(swRunScenariosData[[sc]]) <- matrix(swSite_TranspirationRegions(swRunScenariosData[[sc]])[-tri,], ncol=2)					}			}			#check transpiration regions once more and set TRRG_done			temp <- swSite_TranspirationRegions(swRunScenariosData[[sc]])			if(nrow(temp) > 0 && temp[1, 2] >= 1 ||				max(temp[, 2]) <= max.tri.root ) TRRG_done <- TRUE			if(print.debug) print(paste0(i_labels, " created scenario ", sc, ": tasks = ", paste(tasks, collapse=", "), ", evco = ", EVCO_done, ", trco = ", TRCO_done, ", trrg = ", TRRG_done))		}#end do scenario creations		if(!EVCO_done){			print("Evaporation coefficients not set for this run.")		} else if(!TRCO_done){			print("Transpiration coefficients not set for this run.")		} else if(!TRRG_done){			print("Transpiration regions not set for this run.")		}		if(tasks$create <= 0L || !EVCO_done || !TRCO_done || !TRRG_done){			tasks$create <- 0L			tasks$execute <- tasks$aggregate <- -1L		} else {			tasks$create <- 2L		}		if (saveRsoilwatInput)			save(swRunScenariosData, i_sw_weatherList, grasses.c3c4ann.fractions, ClimatePerturbationsVals, file = f_sw_input)	}#end if do create runs	if(makeInputForExperimentalDesign && expN > 0 && length(create_experimentals) > 0) {		#This file will be used to remake the input files for experimentals		infiletext <- c(paste(i_labels, paste(i_SWRunInformation[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_soillayers[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_treatments[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_cloud[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_prod[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_site[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_soils[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_weather[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_climscen[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infiletext <- c(infiletext, paste(i_labels, paste(i_sw_input_climscen_values[-1], collapse = ExpInput_Seperator), sep=ExpInput_Seperator))		infilename <- paste(dir.out.temp, .Platform$file.sep, flag.icounter, "_", "Experimental_InputData_All.csv", sep="")		infile <- file(infilename, "w+b")		writeLines(text = infiletext, con = infile, sep = "\n")		close(infile)	}#------------------------EXECUTE SOILWAT	if (tasks$execute == 1L && continueAfterAbort && saveRsoilwatOutput && file.exists(f_sw_output)) {		load(f_sw_output)	# load objects: runData		tasks$execute <- 2L	}		if (!exists("swRunScenariosData") || !exists("i_sw_weatherList"))		tasks$execute <- -1L		if (tasks$execute == 1L) {		runData <- list()		if (is.na(i_sw_input_treatments$Exclude_ClimateAmbient)) i_sw_input_treatments$Exclude_ClimateAmbient <- FALSE		sc1 <- if (any(create_treatments == "Exclude_ClimateAmbient") && i_sw_input_treatments$Exclude_ClimateAmbient && i_sim != 1L) 2L else 1L		tempError <- function() .Call("tempError")		DeltaX <- c(NA, 0L)			# first element: determined deltaX_Param value; will be used for all scenarios >= sc if modified			# second element: -1 == failed; 0 == no run yet; 1 == deltaX_Param successfully approved; 2 == deltaX_Param successfully modified				for (sc in sc1:scenario_No) {			if (print.debug) print(paste("Start of SoilWat execution for scenario:", sc))						scw <- if (getScenarioWeatherDataFromDatabase) sc else 1L			mDepth <- swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])["MaxDepth"]						if (DeltaX[2] > 0) {				if (print.debug) print(paste("Using pre-determined DeltaX =", DeltaX[1]))				if (DeltaX[2] == 2L) swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])["deltaX_Param"] <- DeltaX[1]				runData[[sc]] <- try(sw_exec(inputData = swRunScenariosData[[sc]],											 weatherList = i_sw_weatherList[[scw]],									echo = FALSE, quiet = FALSE),								silent = TRUE)						} else {				runData[[sc]] <- try(sw_exec(inputData = swRunScenariosData[[sc]],											 weatherList = i_sw_weatherList[[scw]],									echo = FALSE, quiet = FALSE),								silent = TRUE)				## Testing for Error in Soil Layers and then repeating the SW run with a modified deltaX				is_SOILTEMP_INSTABLE <- tempError()								if (is_SOILTEMP_INSTABLE) {					## Incrementing deltaX and recalling SOILWAT until the temperature is at least normal or the loop executes ten times					i_soil_rep <- 0					DeltaX[1] <- swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])["deltaX_Param"]					while (!inherits(runData[[sc]], "try-error") && is_SOILTEMP_INSTABLE && DeltaX[1] <= mDepth && i_soil_rep < 10) {						## Make sure that the increment for the soil layers is a multiple of the MaxDepth, modulus of 0 means no remainder and thus a multiple of the MaxDepth						repeat {							DeltaX[1] <- DeltaX[1] + increment_soiltemperature_deltaX_cm							if (mDepth %% DeltaX[1] == 0) break						}						## recall Soilwat with the new deltaX parameter and continue to do so with increasing deltax until resolved or executed 10 times						swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])["deltaX_Param"] <- min(DeltaX[1], mDepth)						if (print.debug) print(paste("Site", i_sim, i_labels, "SOILWAT called again with deltaX = ", swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])["deltaX_Param"], "cm because soil temperature stability criterion was not met." ))												runData[[sc]] <- try(sw_exec(inputData = swRunScenariosData[[sc]],											 weatherList = i_sw_weatherList[[scw]],									echo = FALSE, quiet = FALSE),								silent = TRUE)							## Test to check and see if SOILTEMP is stable so that the loop can break - this will be based on parts being > 1.0						is_SOILTEMP_INSTABLE <- tempError()						i_soil_rep <- i_soil_rep + 1					}										DeltaX[2] <- if (!inherits(runData[[sc]], "try-error") && !is_SOILTEMP_INSTABLE) 2L else -1L										#TODO: change deltaX_Param for all [> sc] as well					if (saveRsoilwatInput)						save(swRunScenariosData, i_sw_weatherList, grasses.c3c4ann.fractions, ClimatePerturbationsVals, file = f_sw_input)								} else {					DeltaX <- c(swSite_SoilTemperatureConsts(swRunScenariosData[[sc]])["deltaX_Param"], 1L)				}			}						if (inherits(runData[[sc]], "try-error") || DeltaX[2] < 0) {				tasks$execute <- 0L				break			}		}				if (saveRsoilwatOutput)			save(runData, file = f_sw_output)			}#end if do execute	if (tasks$execute > 0L && exists("runData"))		tasks$execute <- 2L#------------------------AGGREGATE SOILWAT OUTPUT	if (!exists("swRunScenariosData") || !exists("runData"))		tasks$aggregate <- -1L	if (tasks$aggregate == 1L) {		if(print.debug) print("Preparations for aggregation")		#get soil texture data for each layer		stemp <- swSoils_Layers(swRunScenariosData[[1]])		layers_depth <- stemp[, 1]		layers_width <- getLayersWidth(layers_depth)		soilDepth_cm <- max(stemp[, 1])		soilLayers_N <- length(stemp[, 1])		gravel <- stemp[,3]		sand <- stemp[,9]		clay <- stemp[,10]		#get soil aggregation layer for daily aggregations		if(AggLayer.daily){			aggLs <- setAggSoilLayerForAggDailyResponses(layers_depth)		} else {			aggLs <- as.list(ld)		}		aggLs_no <- length(aggLs)		texture <- list(sand.top=weighted.mean(sand[topL], layers_width[topL]),						sand.bottom=weighted.mean(sand[bottomL], layers_width[bottomL]),						clay.top=weighted.mean(clay[topL], layers_width[topL]),						clay.bottom=weighted.mean(clay[bottomL], layers_width[bottomL]),						gravel.top=weighted.mean(gravel[topL], layers_width[topL]),						gravel.bottom=weighted.mean(gravel[bottomL], layers_width[bottomL])					)		if(any(simulation_timescales=="daily") && daily_no > 0){			textureDAgg <- list(	gravel=sapply(1:aggLs_no, FUN=function(x) weighted.mean(gravel[aggLs[[x]]], layers_width[aggLs[[x]]])),									sand=sapply(1:aggLs_no, FUN=function(x) weighted.mean(sand[aggLs[[x]]], layers_width[aggLs[[x]]])),									clay=sapply(1:aggLs_no, FUN=function(x) weighted.mean(clay[aggLs[[x]]], layers_width[aggLs[[x]]]))								)		}		#data access functions		get_Response_aggL <- function(sc_i, response, tscale=c("dy", "dyAll", "mo", "moAll", "yr", "yrAll"), scaler=10, FUN, weights=NULL){			FUN <- match.fun(FUN)			tscale <- match.arg(tscale, choices=c("dy", "dyAll", "mo", "moAll", "yr", "yrAll"))			if(response %in% c(sw_transp, sw_hd)){#divide by 4, because: each soil layer (cm): total, trees, shrubs, forbs, grasses				responseRepeats <- 5			} else { #c(sw_vwc, sw_evsoil, sw_soiltemp, sw_swc, sw_swa)				responseRepeats <- 1			}			if((tscale == "dy") || (tscale == "dyAll"))				temp1 <- scaler * slot(slot(runData[[sc_i]],response),"Day")			if((tscale == "mo") || (tscale == "moAll"))				temp1 <- scaler * slot(slot(runData[[sc_i]],response),"Month")			if((tscale == "yr") || (tscale == "yrAll"))				temp1 <- scaler * slot(slot(runData[[sc_i]],response),"Year")			if(inherits(temp1, "try-error")) stop("Necessary SoilWat output files are not present for aggregation of results")			if(tscale == "dy"){				index.col <- 2				index.usetimestep <- simTime$index.usedy				timestep_ForEachEntry <- simTime2$doy_ForEachUsedDay			} else if(tscale == "dyAll"){				index.col <- 2				index.usetimestep <- 1:nrow(temp1)				timestep_ForEachEntry <- NULL			} else if(tscale == "mo"){				index.col <- 2				index.usetimestep <- simTime$index.usemo				timestep_ForEachEntry <- simTime2$month_ForEachUsedMonth			} else if(tscale == "moAll"){				index.col <- 2				index.usetimestep <- 1:nrow(temp1)				timestep_ForEachEntry <- NULL			} else if(tscale == "yr"){				index.col <- 1				index.usetimestep <- simTime$index.useyr				timestep_ForEachEntry <- NULL			} else if(tscale == "yrAll"){				index.col <- 1				index.usetimestep <- 1:nrow(temp1)				timestep_ForEachEntry <- NULL			}			layers <- 1:((ncol(temp1) - index.col) / responseRepeats)			if(max(layers) <= max(topL)){ #adjust topL and bottomL locally in case temp1 doesn't contain information for every layer, e.g., soil evaporation				topL <- layers				bottomL <- 0			} else if(max(layers) < max(bottomL)){				bottomL <- min(bottomL):max(layers)			}			if(length(topL) > 1) {				if(is.null(weights)){					val.top <- apply(temp1[index.usetimestep, index.col + topL, drop=FALSE], 1, FUN)				} else {					val.top <- apply(temp1[index.usetimestep, index.col + topL, drop=FALSE], 1, FUN, weights[topL])				}			} else {				val.top <- temp1[index.usetimestep, index.col + topL]			}			if(length(bottomL) > 1) {				if(is.null(weights)){					val.bottom <- apply(temp1[index.usetimestep, index.col + bottomL, drop=FALSE], 1, FUN)				} else {					val.bottom <- apply(temp1[index.usetimestep, index.col + bottomL, drop=FALSE], 1, FUN, weights[bottomL])				}			} else if(is.null(bottomL) || identical(bottomL, 0)) {				val.bottom <- matrix(data=0, nrow=length(index.usetimestep), ncol=1)			} else {				val.bottom  <- temp1[index.usetimestep, index.col + bottomL]			}			if(!is.null(timestep_ForEachEntry)){				aggMean.top <- aggregate(val.top, by=list(timestep_ForEachEntry), FUN=mean)[,2]				aggMean.bottom <- aggregate(val.bottom, by=list(timestep_ForEachEntry), FUN=mean)[,2]				return(list(top=val.top, bottom=val.bottom, aggMean.top=aggMean.top, aggMean.bottom=aggMean.bottom))			} else {				if(tscale == "dyAll" || tscale == "moAll" || tscale == "yrAll"){					return(list(val=temp1, top=val.top, bottom=val.bottom))				} else {					return(list(top=val.top, bottom=val.bottom))				}			}		}		get_SWPmatric_aggL <- function(vwcmatric){			val.top <- VWCtoSWP(vwcmatric$top, texture$sand.top, texture$clay.top)			val.bottom <- VWCtoSWP(vwcmatric$bottom, texture$sand.bottom, texture$clay.bottom)			if(!is.null(vwcmatric$aggMean.top)){				aggMean.top <- VWCtoSWP(vwcmatric$aggMean.top, texture$sand.top, texture$clay.top)				aggMean.bottom <- VWCtoSWP(vwcmatric$aggMean.bottom, texture$sand.bottom, texture$clay.bottom)				return(list(top=val.top, bottom=val.bottom, aggMean.top=aggMean.top, aggMean.bottom=aggMean.bottom))			}			if(!is.null(vwcmatric$val)){				if(all(as.integer(vwcmatric$val[,2])==vwcmatric$val[,2])){					index.header <- 1:2				} else {					index.header <- 1				}				val <- cbind(vwcmatric$val[, index.header], VWCtoSWP(vwcmatric$val[, -index.header], sand, clay))				return(list(val=val, top=val.top, bottom=val.bottom))			} else {				return(list(top=val.top, bottom=val.bottom))			}		}		get_Temp_yr <- function(sc){			return(list(mean=slot(slot(runData[[sc]],"TEMP"),"Year")[simTime$index.useyr, 4]))		}		get_Temp_mo <- function(sc){			return(list(min=slot(slot(runData[[sc]],"TEMP"),"Month")[simTime$index.usemo, 4], mean=slot(slot(runData[[sc]],"TEMP"),"Month")[simTime$index.usemo, 5]))		}		get_Temp_dy <- function(sc){			return(list(min=slot(slot(runData[[sc]],"TEMP"),"Day")[simTime$index.usedy, 4],							mean=slot(slot(runData[[sc]],"TEMP"),"Day")[simTime$index.usedy, 5],							max=slot(slot(runData[[sc]],"TEMP"),"Day")[simTime$index.usedy, 3]))		}		get_PPT_yr <- function(sc){			ppt <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Year")[simTime$index.useyr, 2]			rain <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Year")[simTime$index.useyr, 3]			snowfall <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Year")[simTime$index.useyr, 4]			snowmelt <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Year")[simTime$index.useyr, 5]			snowloss <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Year")[simTime$index.useyr, 6]			return(list(ppt=ppt, rain=rain, snowfall=snowfall, snowmelt=snowmelt, snowloss=snowloss))		}		get_PPT_mo <- function(sc){			return(list(ppt=10 * slot(slot(runData[[sc]],"PRECIP"),"Month")[simTime$index.usemo, 3], rain=10 * slot(slot(runData[[sc]],"PRECIP"),"Month")[simTime$index.usemo, 4], snowmelt=10 * slot(slot(runData[[sc]],"PRECIP"),"Month")[simTime$index.usemo, 6]))		}		get_PPT_dy <- function(sc){			ppt <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Day")[simTime$index.usedy, 3]			rain <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Day")[simTime$index.usedy, 4]			snowfall <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Day")[simTime$index.usedy, 5]			snowmelt <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Day")[simTime$index.usedy, 6]			snowloss <- 10 * slot(slot(runData[[sc]],"PRECIP"),"Day")[simTime$index.usedy, 7]			return(list(ppt=ppt, rain=rain, snowfall=snowfall, snowmelt=snowmelt, snowloss=snowloss))		}		get_PET_yr <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"PET"),"Year")[simTime$index.useyr, 2]))		}		get_PET_mo <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"PET"),"Month")[simTime$index.usemo, 3]))		}		get_AET_yr <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"AET"),"Year")[simTime$index.useyr, 2]))		}		get_AET_mo <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"AET"),"Month")[simTime$index.usemo, 3]))		}		get_AET_dy <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"AET"),"Day")[simTime$index.usedy, 3]))		}		get_SWE_mo <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"SNOWPACK"),"Month")[simTime$index.usemo, 3]))		}		get_SWE_dy <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"SNOWPACK"),"Day")[simTime$index.usedy, 3]))		}		get_Inf_yr <- function(sc){			return(list(inf=10 * slot(slot(runData[[sc]],"SOILINFILT"),"Year")[simTime$index.useyr, 2]))		}		get_Inf_mo <- function(sc){			return(list(inf=10 * slot(slot(runData[[sc]],"SOILINFILT"),"Month")[simTime$index.usemo, 3]))		}		get_Inf_dy <- function(sc){			return(list(inf=10 * slot(slot(runData[[sc]],"SOILINFILT"),"Day")[simTime$index.usedy, 3]))		}		get_Esurface_yr <- function(sc){			return(list(sum=10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Year")[simTime$index.useyr, 2], veg=apply(10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Year")[simTime$index.useyr, 3:6], 1, sum), litter=10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Year")[simTime$index.useyr, 7], surfacewater=10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Year")[simTime$index.useyr, 8]))		}		get_Esurface_dy <- function(sc){			return(list(sum=10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Day")[simTime$index.usedy, 3], veg=apply(10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Day")[simTime$index.usedy, 4:7], 1, sum), litter=10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Day")[simTime$index.usedy, 8], surfacewater=10*slot(slot(runData[[sc]],"EVAPSURFACE"),"Day")[simTime$index.usedy, 9]))		}		get_Interception_yr <- function(sc){			return(list(sum=10*slot(slot(runData[[sc]],"INTERCEPTION"),"Year")[simTime$index.useyr, 2], veg=apply(10*slot(slot(runData[[sc]],"INTERCEPTION"),"Year")[simTime$index.useyr, 3:6], 1, sum), litter=10*slot(slot(runData[[sc]],"INTERCEPTION"),"Year")[simTime$index.useyr, 7]))		}		get_DeepDrain_yr <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"DEEPSWC"),"Year")[simTime$index.useyr, 2]))		}		get_DeepDrain_mo <- function(sc) {			return(list(val=10 * slot(slot(runData[[sc]],"DEEPSWC"),"Month")[simTime$index.usemo, 3]))		}		get_DeepDrain_dy <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"DEEPSWC"),"Day")[simTime$index.usedy, 3]))		}		get_Runoff_mo <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"RUNOFF"),"Month")[simTime$index.usemo, 3], ponded=10 * slot(slot(runData[[sc]],"RUNOFF"),"Month")[simTime$index.usemo, 4], snowmelt=10 * slot(slot(runData[[sc]],"RUNOFF"),"Month")[simTime$index.usemo, 5]))		}		get_Runoff_yr <- function(sc){			return(list(val=10 * slot(slot(runData[[sc]],"RUNOFF"),"Year")[simTime$index.useyr, 2], ponded=10 * slot(slot(runData[[sc]],"RUNOFF"),"Year")[simTime$index.useyr, 3], snowmelt=10 * slot(slot(runData[[sc]],"RUNOFF"),"Year")[simTime$index.useyr, 4]))		}		#prepare SQL result container		SQL <- SQLcurrent <- character(0)		fid <- if (parallel_runs && parallel_backend == "mpi") {			mpi.comm.rank()					} else if (parallel_runs && parallel_backend == "snow") {			.nodeNumber		} else if (parallel_runs && parallel_backend == "multicore") {			sample.int(50000, 1)		} else {			0L		}		dbTempFile <- file.path(dir.out, "temp", paste("SQL_Node_", fid, ".sql", sep = ""))		dbTempFileCurrent <- file.path(dir.out, "temp", paste("SQL_Current_Node_", fid, ".sql", sep = ""))		#Performance Measuring		#if(aggregate.timing) OutputTiming <- list()		#if(aggregate.timing) GeneralOutputTiming <- matrix(NA,nrow=scenario_No,ncol=2)		#aggregate for each scenario		for (sc in 1:scenario_No){			if(print.debug) print(paste("Start of overall aggregation for scenario:", sc))			#HEADER GENERATION REMOVED#			#only exclude if 1.) Exclude_ClimateAmbient is true in treatments 2.) That Run is set to Exclude_ClimateAmbient 3.) Our current Scenario is Current			if(any(create_treatments == "Exclude_ClimateAmbient") && i_sw_input_treatments$Exclude_ClimateAmbient && sc==1 && i_sim!=1) {				Exclude_ClimateAmbient <- TRUE				#dbOverallColumns comes from database creation				P_id <- it_Pid(i_sim, sc)				temp <- paste(c(P_id, if (dbOverallColumns > 0) paste0(rep("NULL", dbOverallColumns), collapse = ",")), collapse = ",")				SQL1 <- paste0("INSERT INTO \"aggregation_overall_mean\" VALUES (", temp, ");")				SQL2 <- paste0("INSERT INTO \"aggregation_overall_sd\" VALUES (", temp, ");")				if(length(SQL) == 0) {					SQL <- paste(SQL1, SQL2, sep="\n")				} else {					SQL <- paste(SQL, SQL1, SQL2, sep="\n")				}			} else {				Exclude_ClimateAmbient <- FALSE			}			#overall aggregation. If Exclude_ClimateAmbient == TRUE then skip			if (!continueAfterAbort | (continueAfterAbort & !isdone.overallAggs[sc]) && !Exclude_ClimateAmbient) {				#delete data so that they are read anew for each scenario; each variable is checked that datafile is read in only once per scenario				to_del <- c("temp.yr", "temp.mo", "temp.dy",							"prcp.yr", "prcp.mo", "prcp.dy",							"PET.yr", "PET.mo", "PET.dy",							"AET.yr", "AET.mo", "AET.dy",							"soiltemp.yr", "soiltemp.mo", "soiltemp.dy",							"swcbulk.yr", "swcbulk.mo", "swcbulk.dy",							"swabulk.yr", "swabulk.mo", "swabulk.dy",							"swamatric.yr", "swamatric.mo", "swamatric.dy",							"vwcbulk.yr", "vwcbulk.mo", "vwcbulk.dy", "vwcbulk.dy.all",							"vwcmatric.yr", "vwcmatric.mo", "vwcmatric.dy", "vwcmatric.dy.all",							"swpmatric.yr", "swpmatric.mo", "swpmatric.dy", "swpmatric.dy.all",							"transp.yr", "transp.mo", "transp.dy", "transp.dy.all",							"Esoil.yr", "Esoil.mo", "Esoil.dy", "Esoil.dy.all",							"Esurface.yr", "Esurface.mo", "Esurface.dy",							"hydred.yr", "hydred.mo", "hydred.dy",							"inf.yr", "inf.mo", "inf.dy",							"runoff.yr", "runoff.mo", "runoff.dy",							"intercept.yr", "intercept.mo", "intercept.dy",							"deepDrain.yr", "deepDrain.mo", "deepDrain.dy")				to_del <- to_del[to_del %in% ls()]				if(length(to_del) > 0) try(rm(list=to_del), silent=TRUE)				#result vector column index indicating variable within set of n_variables per scenario				resMeans <- resSDs <- rep(NA, length=dbOverallColumns)				nv <- 1				#---Aggregation: SoilWat inputs			#0				if(aon$input_SoilProfile){					if(print.debug) print("Aggregation of input_SoilProfile")					resMeans[nv:(nv+7)] <- c(soilDepth_cm, soilLayers_N, unlist(texture))					nv <- nv+8					resMeans[nv]<-swRunScenariosData[[1]]@site@SoilTemperatureConstants[9]					nv <- nv+1				}			#1				if(aon$input_FractionVegetationComposition) {					if(print.debug) print("Aggregation of input_FractionVegetationComposition")					resMeans[nv:(nv+7)] <- c(swProd_Composition(swRunScenariosData[[sc]]), grasses.c3c4ann.fractions[[sc]])					nv <- nv+8				}			#2				if(aon$input_VegetationBiomassMonthly) {					if(print.debug) print("Aggregation of input_VegetationBiomassMonthly")					resMeans[nv:(nv+11)] <- swProd_MonProd_grass(swRunScenariosData[[sc]])[,1]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_grass(swRunScenariosData[[sc]])[,2]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_grass(swRunScenariosData[[sc]])[,2]*swProd_MonProd_grass(swRunScenariosData[[sc]])[,3]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_shrub(swRunScenariosData[[sc]])[,1]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_shrub(swRunScenariosData[[sc]])[,2]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_shrub(swRunScenariosData[[sc]])[,2]*swProd_MonProd_shrub(swRunScenariosData[[sc]])[,3]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_tree(swRunScenariosData[[sc]])[,1]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_tree(swRunScenariosData[[sc]])[,2]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_tree(swRunScenariosData[[sc]])[,2]*swProd_MonProd_tree(swRunScenariosData[[sc]])[,3]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_forb(swRunScenariosData[[sc]])[,1]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_forb(swRunScenariosData[[sc]])[,2]					nv <- nv+12					resMeans[nv:(nv+11)] <- swProd_MonProd_forb(swRunScenariosData[[sc]])[,2]*swProd_MonProd_forb(swRunScenariosData[[sc]])[,3]					nv <- nv+12				}			#3				if(aon$input_VegetationPeak) {					if(print.debug) print("Aggregation of input_VegetationPeak")					fracs <- swProd_Composition(swRunScenariosData[[sc]])[1:4] #get the fractional Composition of grasses, shrubs, and trees					tempdat <- matrix(data=NA, nrow=12, ncol=4)#matrix to hold biomass * percLive for grass,shrubs,trees					colnames(tempdat) <- c("grass", "shrub", "tree", "forb")					tempdat[,1] <- swProd_MonProd_grass(swRunScenariosData[[sc]])[,2]*swProd_MonProd_grass(swRunScenariosData[[sc]])[,3]					tempdat[,2] <- swProd_MonProd_shrub(swRunScenariosData[[sc]])[,2]*swProd_MonProd_shrub(swRunScenariosData[[sc]])[,3]					tempdat[,3] <- swProd_MonProd_tree(swRunScenariosData[[sc]])[,2]*swProd_MonProd_tree(swRunScenariosData[[sc]])[,3]					tempdat[,4] <- swProd_MonProd_forb(swRunScenariosData[[sc]])[,2]*swProd_MonProd_forb(swRunScenariosData[[sc]])[,3]					sumWeightedLiveBiomassByMonth <- apply(sweep(tempdat, MARGIN=2, fracs, FUN="*"), MARGIN=1, function(x) sum(x)) #sweep out fractionals, and sum over rows					maxMonth <- which(sumWeightedLiveBiomassByMonth==max(sumWeightedLiveBiomassByMonth)) #returns index, which is the month, of max bio					meanPeakMonth <- circ.mean(maxMonth, 12)					duration <- circ.range(maxMonth, 12)+1					resMeans[nv:(nv+1)] <- c(meanPeakMonth, duration) #just in case we get more then one month					nv <- nv+2				}			#4				if(any(simulation_timescales=="monthly") && aon$input_Phenology) {					if(print.debug) print("Aggregation of input_Phenology")					if(!exists("temp.mo")) temp.mo <- get_Temp_mo(sc) #see if we have data					monthly.temp <- aggregate(temp.mo$mean, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2] #get mean monthly temp					if(i_SWRunInformation$Y_WGS84 < 0) { #check for Southern Hemi						monthly.temp <- c(monthly.temp[7:12], monthly.temp[1:6]) #rearrange temp						Months_Above_Threshold <- c(7:12, 1:6)[which(monthly.temp > growing.season.threshold.tempC)] #get months above threshold, then map back to real months.					} else {						Months_Above_Threshold <- which(monthly.temp > growing.season.threshold.tempC) #get months above threshold					}					Input_PhenologyStart_Month <- Months_Above_Threshold[1] #get the first month					Input_PhenologyEnd_Month <- tail(Months_Above_Threshold, n=1) #get the last month					resMeans[nv:(nv+1)] <- c(Input_PhenologyStart_Month, Input_PhenologyEnd_Month)					nv <- nv+2				}			#5				if(aon$input_TranspirationCoeff){					if(print.debug) print("Aggregation of input_TranspirationCoeff")					Tcoeff <- swSoils_Layers(swRunScenariosData[[1]])[, 5:8]					if(is.null(dim(Tcoeff))) Tcoeff <- matrix(Tcoeff, nrow=1)					TaggLs <- sapply(aggLs, FUN=function(l) apply(Tcoeff[l,, drop=FALSE], 2, sum))					if(length(bottomL) > 0 && !identical(bottomL, 0)){						Ttb <- sapply(list(topL, bottomL), FUN=function(l) apply(Tcoeff[l,, drop=FALSE], 2, sum))					} else {						Ttb <- sapply(list(topL), FUN=function(l) apply(Tcoeff[l,, drop=FALSE], 2, sum))					}					iinv <- inv <- nv					for(iv in 1:4){						nv <- nv+SoilLayer_MaxNo #We don't know the max number of soil layers (aggLs_no) among all simulations, i.e., set to the maximum						resMeans[(inv+(iv-1)*SoilLayer_MaxNo):(nv-1)] <- c(TaggLs[iv, ], rep(NA, times=SoilLayer_MaxNo-aggLs_no))					}					inv <- nv					for(iv in 1:4){						nv <- nv+2						resMeans[(inv+(iv-1)*2):(nv-1)] <- Ttb[iv, ]					}					rm(Tcoeff, TaggLs, Ttb)				}			#6				if(aon$input_ClimatePerturbations) {					if(print.debug) print("Aggregation of input_ClimatePerturbations")					resMeans[nv:(nv+35)] <- as.vector(as.numeric(ClimatePerturbationsVals[sc,]))					nv <- nv+36				}				#---Aggregation: Climate and weather			#7				if(any(simulation_timescales=="yearly") & aon$yearlyTemp){					if(print.debug) print("Aggregation of yearlyTemp")					if(!exists("temp.yr"))	temp.yr <- get_Temp_yr(sc)					resMeans[nv] <- mean(temp.yr$mean)					resSDs[nv] <- sd(temp.yr$mean)					nv <- nv+1				}			#8				if(any(simulation_timescales=="yearly") & aon$yearlyPPT){					if(print.debug) print("Aggregation of yearlyPPT")					if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)					resMeans[nv] <- mean(prcp.yr$ppt)					resSDs[nv] <- sd(prcp.yr$ppt)					resMeans[nv+1] <- mean(snowofppt <- prcp.yr$snowfall/prcp.yr$ppt, na.rm=TRUE)					resSDs[nv+1] <- sd(snowofppt, na.rm=TRUE)					nv <- nv+2					rm(snowofppt)				}			#9				if(any(simulation_timescales=="daily") & any(simulation_timescales=="yearly") & aon$dailySnowpack){					if(print.debug) print("Aggregation of dailySnowpack")					if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)					if(!exists("prcp.dy")) prcp.dy <- get_PPT_dy(sc)					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					rainOnSnow <- aggregate(ifelse(SWE.dy$val > 0, prcp.dy$rain, 0), by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]#Fraction of rain that falls on snow					resMeans[nv] <- mean(temp <- rainOnSnow / prcp.yr$ppt, na.rm=TRUE)					resSDs[nv] <- sd(temp, na.rm=TRUE)					nv <- nv+1					rm(rainOnSnow)				}			#10				if(any(simulation_timescales=="daily") & aon$dailySnowpack){#daily snowpack: accountNSHemispheres_agg					if(print.debug) print("Aggregation of dailySnowpack2")					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					if(sum(SWE.dy$val) > 0){						snowyears <- simTime2$year_ForEachUsedDay_NSadj + ifelse(simTime2$doy_ForEachUsedDay_NSadj > 273, 1, 0)	# 1. snow-year: N-hemisphere: October 1st = 1 day of snow year; S-hemisphere: April 1st = 1 day of snow year						adjDays <- ifelse(simTime2$doy_ForEachUsedDay[1] == simTime2$doy_ForEachUsedDay_NSadj[1], 365 - 273, -91)						if(length(unique(snowyears))-2 > 0){							res.snow  <- matrix(data=0, nrow=length(unique(snowyears))-2, ncol=6, byrow=TRUE)							res.snow[,1]  <- unique(snowyears)[2:(length(unique(snowyears))-1)]  # 1. snowyear							snowyear.trim <- !is.na(pmatch(snowyears, res.snow[, 1], duplicates.ok=TRUE))							res.snow[,2] <- unlist(aggregate(SWE.dy$val[snowyear.trim], by=list(snowyears[snowyear.trim]), FUN=which.max)[, 2]) - adjDays # 2. doy of peak snowpack water-equivalent (mm)							res.snow[,5] <- unlist(aggregate(SWE.dy$val[snowyear.trim], by=list(snowyears[snowyear.trim]), FUN=function(s) sum(s>0))[, 2]) # 5. total number of days of snow cover							res.snow[,6] <- unlist(aggregate(SWE.dy$val[snowyear.trim], by=list(snowyears[snowyear.trim]), FUN=max)[, 2]) # 6. peak snowpack water-equivalent (mm)							#attempt to get rid of for loop							#r.lengths <- aggregate(SWE.dy$val, by=list(snowyears), FUN=function(s) rle(ifelse(s>0,1,0))$lengths )[-c(1,30),]							#r.values <- aggregate(SWE.dy$val, by=list(snowyears), FUN=function(s) rle(ifelse(s>0,1,0))$values )[-c(1,30),]							syi <- 1							for (sy in res.snow[,1]){								r <- rle(ifelse(SWE.dy$val[which(snowyears == sy)]>0,1,0))								res.snow[syi,4] <- r$lengths[which(r$values==1)][order(r$lengths[which(r$values==1)], decreasing=TRUE)[1]] # 4. number of continous days of snow cover								ind <- which(r$lengths==res.snow[syi,4])								res.snow[syi,3] <- cumsum(r$lengths)[ifelse(length(ind)>1, ind[which.max(r$values[ind])], ind)] - adjDays # 3. last day of continous snow cover								syi <- syi + 1							}							if(nrow(res.snow) > 1){								resMeans[nv:(nv+4)] <- c(apply(res.snow[, 2:3], 2, FUN=function(x) circ.mean(x, int=365, na.rm=TRUE)), apply(res.snow[,-(1:3)], 2, mean, na.rm=TRUE))								resSDs[nv:(nv+4)] <- c(apply(res.snow[, 2:3], 2, FUN=function(x) circ.sd(x, int=365, na.rm=TRUE)), apply(res.snow[,-(1:3)], 2, sd, na.rm=TRUE))							} else {								resMeans[nv:(nv+4)] <- res.snow[1,-1]								resSDs[nv:(nv+4)] <- 0							}							rm(snowyears, snowyear.trim, res.snow, adjDays)						} else {							resMeans[nv:(nv+4)] <- resSDs[nv:(nv+4)] <- 0						}					} else {						resMeans[nv:(nv+4)] <- resSDs[nv:(nv+4)] <- 0					}					nv <- nv+5				}			#11				if(any(simulation_timescales=="daily") & aon$dailyFrostInSnowfreePeriod){					if(print.debug) print("Aggregation of dailyFrostInSnowfreePeriod")					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					for(iTmin in Tmin_crit_C){						frostWithoutSnow <- aggregate(SWE.dy$val == 0 & temp.dy$min < iTmin, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]#Numbers of days with min.temp < 0 and snow == 0						resMeans[nv] <- mean(frostWithoutSnow, na.rm=TRUE)						resSDs[nv] <- sd(frostWithoutSnow, na.rm=TRUE)						nv <- nv+1					}					rm(frostWithoutSnow)				}			#12				if(any(simulation_timescales=="daily") & aon$dailyHotDays){					if(print.debug) print("Aggregation of dailyHotDays")					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					for(iTmax in Tmax_crit_C){						HotDays <- aggregate(temp.dy$max > iTmax, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]#Numbers of days with max.temp > 0						resMeans[nv] <- mean(HotDays, na.rm=TRUE)						resSDs[nv] <- sd(HotDays, na.rm=TRUE)						nv <- nv+1					}					rm(HotDays)				}			#13				if(any(simulation_timescales=="daily") & aon$dailyPrecipitationEventSizeDistribution){	#daily weather frequency distributions					if(print.debug) print("Aggregation of dailyPrecipitationEventSizeDistribution")					if(!exists("prcp.dy")) prcp.dy <- get_PPT_dy(sc)					#prcp-event sizes in bins					events <- lapply(simTime$useyrs, FUN=function(y) floor((temp <- prcp.dy$ppt[simTime2$year_ForEachUsedDay == y])[temp>0]/bin.prcpSizes)*bin.prcpSizes)					bins.summary <- (0:6) * bin.prcpSizes	#aggregate to maximal 7 bins					bins.available <- sort(unique(unlist(events))) #bins present					counts.available <- as.matrix(sapply(simTime$useyrs - startyr + 1, FUN=function(y) sapply(bins.available, FUN=function(b) sum(events[[y]] == b))))					counts.summary <- matrix(data=0, ncol=simTime$no.useyr, nrow=length(bins.summary))					counts.summary[bins.summary %in% bins.available, ] <- counts.available[bins.available %in% bins.summary, ]					if(max(bins.summary) < max(bins.available)){ #if bins available that are outside the summary bins, then sum them up into the highest summary bin						if(length(bins.suming <- which(bins.available >= max(bins.summary))) > 1){							counts.summary[length(bins.summary), ] <- apply(counts.available[bins.suming, ], MARGIN=2, FUN=sum)						} else {							counts.summary[length(bins.summary), ] <- counts.available[bins.suming, ]						}					}					eventsPerYear <- apply(counts.summary, MARGIN=2, FUN=sum)					freq.summary <- sweep(counts.summary, MARGIN=2, STATS=eventsPerYear, FUN="/")					resMeans[nv] <- mean(eventsPerYear)					resSDs[nv] <- sd(eventsPerYear)					resMeans[(nv+1):(nv+7)] <- apply(freq.summary, MARGIN=1, FUN=mean)					resSDs[(nv+1):(nv+7)] <- apply(freq.summary, MARGIN=1, FUN=sd)					nv <- nv+8					rm(events, counts.available, counts.summary, freq.summary, eventsPerYear)				}			#14				if(any(simulation_timescales=="yearly") & aon$yearlyAET){					if(print.debug) print("Aggregation of yearlyAET")					if(!exists("AET.yr")) AET.yr <- get_AET_yr(sc)					resMeans[nv] <- mean(AET.yr$val)					resSDs[nv] <- sd(AET.yr$val)					nv <- nv+1				}			#15				if(any(simulation_timescales=="yearly") & aon$yearlyPET){					if(print.debug) print("Aggregation of yearlyPET")					if(!exists("PET.yr")) PET.yr <- get_PET_yr(sc)					resMeans[nv] <- mean(PET.yr$val)					resSDs[nv] <- sd(PET.yr$val)					nv <- nv+1				}			#16				#correl monthly swp (top and bottom) vs. pet and ppt vs. temp, use product moment correlation coefficient {eqn. 11.6, \Sala, 1997 #45}				if(any(simulation_timescales=="monthly") & aon$monthlySeasonalityIndices){					if(print.debug) print("Aggregation of monthlySeasonalityIndices")					if(!exists("vwcmatric.mo")) vwcmatric.mo <- get_Response_aggL(sc, sw_vwcmatric, "mo", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.mo")) swpmatric.mo <- get_SWPmatric_aggL(vwcmatric.mo)					if(!exists("temp.mo")) temp.mo <- get_Temp_mo(sc)					if(!exists("prcp.mo")) prcp.mo <- get_PPT_mo(sc)					if(!exists("PET.mo")) PET.mo <- get_PET_mo(sc)					cor2  <- function(y) cor(y[,1], y[,2])					#in case var(ppt or swp)==0 => cor is undefined: exclude those years					resMeans[nv] <- mean( temp <- by(data.frame(PET.mo$val, swpmatric.mo$top), INDICES=simTime2$yearno_ForEachUsedMonth, FUN=cor2), na.rm=TRUE )					resSDs[nv] <- sd(temp, na.rm=TRUE)					if(length(bottomL) > 0 && !identical(bottomL, 0)){						resMeans[nv+1] <- mean( temp <- by(data.frame(PET.mo$val, swpmatric.mo$bottom), INDICES=simTime2$yearno_ForEachUsedMonth, FUN=cor2), na.rm=TRUE )						resSDs[nv+1] <- sd(temp, na.rm=TRUE)					}					resMeans[nv+2] <- mean( temp <- by(data.frame(temp.mo$mean, prcp.mo$ppt), INDICES=simTime2$yearno_ForEachUsedMonth, FUN=cor2), na.rm=TRUE )					resSDs[nv+2] <- sd(temp, na.rm=TRUE)					nv <- nv+3				}				#---Aggregation: Climatic dryness			#17				if(any(simulation_timescales=="yearly") & any(simulation_timescales=="monthly") & aon$yearlymonthlyTemperateDrylandIndices){					if(print.debug) print("Aggregation of yearlymonthlyTemperateDrylandIndices")					if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)					if(!exists("PET.yr")) PET.yr <- get_PET_yr(sc)					if(!exists("temp.mo")) temp.mo <- get_Temp_mo(sc)					get.drylandindices <- function(annualPPT, annualPET, monthlyTemp){						ai <- annualPPT/annualPET	#Deichmann, U. & L. Eklundh. 1991. Global digital datasets for land degradation studies: a GIS approach. Global Environment Monitoring System (GEMS), United Nations Environment Programme (UNEP), Nairobi, Kenya.						TD <- ifelse((temp <- apply(matrix(data=monthlyTemp, ncol=12, byrow=TRUE), MARGIN=1, FUN=function(x) sum(x >= 10))) >= 4 & temp < 8, 1, 0) #Trewartha & Horn 1980, page 284: temperate areas						criteria12 <- ifelse(TD == 1 & ai < 0.5, 1, 0)						return(list(ai=ai, TD=TD, criteria12=criteria12))					}					di.ts <- get.drylandindices(annualPPT=prcp.yr$ppt, annualPET=PET.yr$val, monthlyTemp=temp.mo$mean)					di.normals <- get.drylandindices(annualPPT=mean(prcp.yr$ppt), annualPET=mean(PET.yr$val), monthlyTemp=aggregate(temp.mo$mean, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)$x)					resMeans[nv:(nv+2)] <- unlist(di.normals)					resMeans[(nv+3):(nv+5)] <- apply(temp <- cbind(di.ts$ai, di.ts$TD, di.ts$criteria12), MARGIN=2, FUN=mean, na.rm=TRUE)					resSDs[(nv+3):(nv+5)] <- apply(temp, MARGIN=2, FUN=sd, na.rm=TRUE)					nv <- nv+6					rm(di.ts, di.normals)				}			#18				if(any(simulation_timescales=="yearly") & aon$yearlyDryWetPeriods){					if(print.debug) print("Aggregation of yearlyDryWetPeriods")					if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)					temp.rle <- rle(sign(prcp.yr$ppt - mean(prcp.yr$ppt)))					resMeans[nv:(nv+1)] <- c(quantile(temp.rle$lengths[temp.rle$values==-1], probs=0.9, type=7), quantile(temp.rle$lengths[temp.rle$values==1], probs=0.9, type=7))					nv <- nv+2					rm(temp.rle)				}			#19				if(any(simulation_timescales=="daily") & aon$dailyWeatherGeneratorCharacteristics){#daily response to weather generator treatments					if(print.debug) print("Aggregation of dailyWeatherGeneratorCharacteristics")					if(!exists("prcp.dy")) prcp.dy <- get_PPT_dy(sc)					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					dws <- sapply(st_mo, FUN=function(m)								return(list(mean=mean(temp <- unlist(sapply(simTime$useyrs, FUN=function(y) ((temp <- rle(prcp.dy$ppt[simTime2$month_ForEachUsedDay == m & simTime2$year_ForEachUsedDay == y] > 0))$lengths[temp$values]) )), na.rm=TRUE),												sd=sd(temp, na.rm=TRUE))))					dds <- sapply(st_mo, FUN=function(m)								return(list(mean=mean(temp <- unlist(sapply(simTime$useyrs, FUN=function(y) ((temp <- rle(prcp.dy$ppt[simTime2$month_ForEachUsedDay == m & simTime2$year_ForEachUsedDay == y] == 0))$lengths[temp$values]) )), na.rm=TRUE),												sd=sd(temp, na.rm=TRUE))))					#tv <- sapply(st_mo, FUN=function(m) sd(temp.dy$mean[simTime2$month_ForEachUsedDay == m], na.rm=TRUE) )					tv <- sapply(st_mo, FUN=function(m)								return(list(mean=mean(temp <- unlist(sapply(simTime$useyrs, FUN=function(y) sd(temp.dy$mean[simTime2$month_ForEachUsedDay == m & simTime2$year_ForEachUsedDay == y], na.rm=TRUE) )), na.rm=TRUE),												sd=sd(temp, na.rm=TRUE))))					resMeans[nv+st_mo-1] <- unlist(dws[1, ])					resSDs[nv+st_mo-1] <- unlist(dws[2, ])					resMeans[nv+st_mo-1+12] <- unlist(dds[1, ])					resSDs[nv+st_mo-1+12] <- unlist(dds[2, ])					resMeans[nv+st_mo-1+24] <- unlist(tv[1, ])					resSDs[nv+st_mo-1+24] <- unlist(tv[2, ])					nv <- nv+36					rm(dws, dds, tv)				}			#20				if(any(simulation_timescales=="daily") & aon$dailyPrecipitationFreeEventDistribution){	#daily weather frequency distributions					if(print.debug) print("Aggregation of dailyPrecipitationFreeEventDistribution")					if(!exists("prcp.dy")) prcp.dy <- get_PPT_dy(sc)					#duration of prcp-free days in bins					durations <- lapply(simTime$useyrs, FUN=function(y) floor(((temp <- rle(prcp.dy$ppt[simTime2$year_ForEachUsedDay == y] == 0))$lengths[temp$values]-1)/bin.prcpfreeDurations)*bin.prcpfreeDurations )					if(length(unlist(durations))==0) {if(!be.quiet) print("Unable to complete aggregation of dailyPrecipitationFreeEventDistribution")						}else{					bins.summary <- (0:3) * bin.prcpfreeDurations	#aggregate to maximal 4 bins					bins.available <- sort(unique(unlist(durations)))	#bins present					counts.available <- as.matrix(sapply(simTime$useyrs - startyr + 1, FUN=function(y) sapply(bins.available, FUN=function(b) sum(durations[[y]] == b))))					counts.summary <- matrix(data=0, ncol=simTime$no.useyr, nrow=length(bins.summary))					counts.summary[bins.summary %in% bins.available, ] <- counts.available[bins.available %in% bins.summary, ]					if(max(bins.summary) < max(bins.available)){ #if bins available that are outside the summary bins, then sum them up into the highest summary bin						if(length(bins.suming <- which(bins.available >= max(bins.summary))) > 1){							counts.summary[length(bins.summary), ] <- apply(counts.available[bins.suming, ], MARGIN=2, FUN=sum)						} else {							counts.summary[length(bins.summary), ] <- counts.available[bins.suming, ]						}					}					eventsPerYear <- apply(counts.summary, MARGIN=2, FUN=sum)					freq.summary <- sweep(counts.summary, MARGIN=2, STATS=eventsPerYear, FUN="/")					resMeans[nv] <- mean(eventsPerYear)					resSDs[nv] <- sd(eventsPerYear)					resMeans[(nv+1):(nv+4)] <- apply(freq.summary, MARGIN=1, FUN=mean)					resSDs[(nv+1):(nv+4)] <- apply(freq.summary, MARGIN=1, FUN=sd)					nv <- nv+5					rm(durations, counts.available, counts.summary, freq.summary, eventsPerYear)				}				}			#21				if(any(simulation_timescales=="monthly") & aon$monthlySPEIEvents){					if(print.debug) print("Aggregation of monthlySPEIEvents")					require(SPEI)					#standardized precipitation-evapotranspiration index, SPEI: Vicente-Serrano, S.M., Beguer, S., Lorenzo-Lacruz, J., Camarero, J.s.J., Lopez-Moreno, J.I., Azorin-Molina, C., Revuelto, J.s., Morn-Tejeda, E. & Sanchez-Lorenzo, A. (2012) Performance of Drought Indices for Ecological, Agricultural, and Hydrological Applications. Earth Interactions, 16, 1-27.					if(!exists("PET.mo")) PET.mo <- get_PET_mo(sc)					if(!exists("prcp.mo")) prcp.mo <- get_PPT_mo(sc)					#n_variables is set for 4*4*3 with length(binSPEI_m) == 4 && length(probs) == 3					binSPEI_m <- c(1, 12, 24, 48) #months					probs <- c(0.025, 0.5, 0.975)					iresp <- rep(1:4, each=length(probs))					for(iscale in seq_along(binSPEI_m)){						rvec <- rep(NA, times=4 * length(probs))						if(binSPEI_m[iscale] < length(prcp.mo$ppt)){							spei_m <- as.numeric(spei(prcp.mo$ppt - PET.mo$val, scale=binSPEI_m[iscale])$fitted)							spei_m <- spei_m[!is.na(spei_m)]							runs <- rle(spei_m >= 0)							if(sum(runs$values) > 0){								rvec[iresp==1] <- quantile(runs$lengths[runs$values], probs=probs, type=7) #duration of positive spells								rvec[iresp==2] <- quantile(spei_m[spei_m >= 0], probs=probs, type=7) #intensity of positive spells							}							if(sum(!runs$values) > 0){								rvec[iresp==3] <- quantile(runs$lengths[!runs$values], probs=probs, type=7) #duration of negative spells								rvec[iresp==4] <- quantile(spei_m[spei_m < 0], probs=probs, type=7) #intensity of positive spells							}						}						resMeans[nv:(nv+length(rvec)-1)] <- rvec						nv <- nv+length(rvec)					}				}				#---Aggregation: Climatic control			#22				if(any(simulation_timescales=="monthly") & aon$monthlyPlantGrowthControls){	#Nemani RR, Keeling CD, Hashimoto H et al. (2003) Climate-Driven Increases in Global Terrestrial Net Primary Production from 1982 to 1999. Science, 300, 1560-1563.					if(print.debug) print("Aggregation of monthlyPlantGrowthControls")					if(!exists("temp.mo")) temp.mo <- get_Temp_mo(sc)					if(!exists("PET.mo")) PET.mo <- get_PET_mo(sc)					if(!exists("prcp.mo")) prcp.mo <- get_PPT_mo(sc)					DayNumber_ForEachUsedMonth <- rle(simTime2$month_ForEachUsedDay)$lengths					DayNumber_ForEachUsedYear <- rle(simTime2$year_ForEachUsedDay)$lengths					#temperature control					control_temp <- aggregate(ifelse(temp.mo$min > 5, 1, ifelse(temp.mo$min < -5, 0, (5 + temp.mo$min) / 10)) * DayNumber_ForEachUsedMonth, by=list(simTime2$yearno_ForEachUsedMonth), FUN=sum)[, 2] / DayNumber_ForEachUsedYear					#moisture control					aridity <- (prcp.mo$rain + prcp.mo$snowmelt) / PET.mo$val					control_water <- aggregate(ifelse(aridity > 0.75, 1, ifelse(aridity < 0, 0, aridity/0.75)) * DayNumber_ForEachUsedMonth, by=list(simTime2$yearno_ForEachUsedMonth), FUN=sum)[, 2] / DayNumber_ForEachUsedYear					#radiation control					cloudiness <- swCloud_SkyCover(swRunScenariosData[[sc]])					cloudiness <- rep(cloudiness, times=simTime$no.useyr)					control_radiation <- aggregate((1 - ifelse(cloudiness < 10, 0, (cloudiness - 10) / 100 * 0.5 )) * DayNumber_ForEachUsedMonth, by=list(simTime2$yearno_ForEachUsedMonth), FUN=sum)[, 2] / DayNumber_ForEachUsedYear					temp <- data.frame(control_temp, control_water, control_radiation)					resMeans[nv:(nv+2)] <- apply(temp, 2, mean, na.rm=TRUE)					resSDs[nv:(nv+2)] <- apply(temp, 2, sd, na.rm=TRUE)					nv <- nv+3					rm(DayNumber_ForEachUsedMonth, DayNumber_ForEachUsedYear, control_temp, control_water, control_radiation, aridity, temp, cloudiness)				}			#23				if(any(simulation_timescales=="daily") & aon$dailyC4_TempVar){#Variables to estimate percent C4 species in North America: Teeri JA, Stowe LG (1976) Climatic patterns and the distribution of C4 grasses in North America. Oecologia, 23, 1-12.					if(print.debug) print("Aggregation of dailyC4_TempVar")					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					resMeans[nv:(nv+2)] <- (temp <- as.numeric(sw_dailyC4_TempVar(dailyTempMin=temp.dy$min, dailyTempMean=temp.dy$mean, simTime2)))[1:3]	#accountNSHemispheres_agg					resSDs[nv:(nv+2)] <- temp[4:6]					nv <- nv+3				}			#24				if(any(simulation_timescales=="daily") & aon$dailyDegreeDays){	#Degree days based on daily temp					if(print.debug) print("Aggregation of dailyDegreeDays")					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					degday <- ifelse(temp.dy$mean > DegreeDayBase, temp.dy$mean - DegreeDayBase, 0) #degree days					temp <- aggregate(degday, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]					resMeans[nv] <- mean(temp)					resSDs[nv] <- sd(temp)					nv <- nv+1					rm(degday)				}			#25				regimes_done <- FALSE				if(any(simulation_timescales=="daily") && aon$dailyNRCS_SoilMoistureTemperatureRegimes){					if(print.debug) print("Aggregation of dailyNRCS_SoilMoistureTemperatureRegimes")				  #Based on references provided by Chambers, J. C., D. A. Pyke, J. D. Maestas, M. Pellant, C. S. Boyd, S. B. Campbell, S. Espinosa, D. W. Havlina, K. E. Mayer, and A. Wuenschel. 2014. Using Resistance and Resilience Concepts to Reduce Impacts of Invasive Annual Grasses and Altered Fire Regimes on the Sagebrush Ecosystem and Greater Sage-Grouse: A Strategic Multi-Scale Approach. Gen. Tech. Rep. RMRS-GTR-326. U.S. Department of Agriculture, Forest Service, Rocky Mountain Research Station, Fort Collins, CO.				  #Soil Survey Staff. 2014. Keys to soil taxonomy, 12th ed., USDA Natural Resources Conservation Service, Washington, DC.				  #Soil Survey Staff. 2010. Keys to soil taxonomy, 11th ed., USDA Natural Resources Conservation Service, Washington, DC.				  				  #function for the calculation of consecutive days				  consec<-function(x){				    result<-rle(diff(x))				    result				    if(x[1]==TRUE){				      result2<-max(result$length[(seq(1,length(result$length),4))])				    }else{				      if(length(result$length)>2)				        result2<-max(result$length[seq(3,length(result$length),4)])+1				      if(length(result$length)==2)				        result2<-result$lengths[2]				      if(length(result$length)==1)  				        result2<-result$lengths[1]				    }				    return(result2)				  }				  #Result containers				  Tregime_names <- c("Hyperthermic", "Thermic", "Mesic", "Frigid", "Cryic", "Gelic")				  Tregime <- rep(0, times=length(Tregime_names))				  names(Tregime) <- Tregime_names				  Sregime_names <- c("Anyhydrous","Aridic", "Udic", "Ustic", "Xeric")				  Sregime <- rep(0, times=length(Sregime_names))				  names(Sregime) <- Sregime_names				  				  MCS_depth <- Lanh_depth <- rep(NA, 2)				  Fifty_depth <- permafrost <- CSPartSummer <- SoilAbove0C <- SoilAbove5C<-DryDaysCumAbove5C<-MoistDaysConsecAbove8C<-DryDaysConsecSummer<-MoistDaysConsecAny<-MoistDaysCumAny<-DryDaysCumAny<-MoistDaysConsecWinter <- NA				  if(swSite_SoilTemperatureFlag(swRunScenariosData[[sc]])){#we need soil temperature				  if(!exists("soiltemp.yr.all")) soiltemp.yr.all <- get_Response_aggL(sc, sw_soiltemp, "yrAll", scaler=1, FUN=weighted.mean, weights=layers_width)				  				  #Parameters				  SWP_dry <- -1.5	#dry means SWP below -1.5 MPa (Soil Survey Staff 2014: p.29)				  SWP_sat <- -0.033	#saturated means SWP above -0.033 MPa				  impermeability <- 0.9 #impermeable layer				  				  #Particle-size class of the soil				  sand_temp <- weighted.mean(sand, layers_width)				  clay_temp <- weighted.mean(clay, layers_width)				  				  #Required soil layers				  stemp <- swSoils_Layers(swRunScenariosData[[sc]])				  #50cm soil depth or impermeable layer (whichever is shallower; Soil Survey Staff 2014: p.31)				  imp_depth <- which(stemp[, "impermeability_frac"] >= impermeability)				  imp_depth <- min(imp_depth, max(stemp[, "depth_cm"]))	#Interpret maximum soil depth as possible impermeable layer				  Fifty_depth <- min(50, imp_depth)				  				  #Definition of MCS (Soil Survey Staff 2014: p.29): The moisture control section (MCS) of a soil: the depth to which a dry (tension of more than 1500 kPa, but not air-dry) soil will be moistened by 2.5 cm of water within 24 hours. The lower boundary is the depth to which a dry soil will be moistened by 7.5 cm of water within 48 hours.				  #Practical depth definition of MCS				  #	- 10 to 30 cm below the soil surface if the particle-size class of the soil is fine-loamy, coarse-silty, fine-silty, or clayey				  #	- 20 to 60 cm if the particle-size class is coarse-loamy				  #	- 30 to 90 cm if the particle-size class is sandy.				  MCS_depth <- if(clay_temp >= 0.18) { c(10, 30)				  } else if(sand_temp < 0.15){ c(10, 30)				  } else if(sand_temp >= 0.50){ c(30, 90)				  } else c(20, 60)				  #If 7.5 cm of water moistens the soil to a densic, lithic, paralithic, or petroferric contact or to a petrocalcic or petrogypsic horizon or a duripan, the contact or the upper boundary of the cemented horizon constitutes the lower boundary of the soil moisture control section. If a soil is moistened to one of these contacts or horizons by 2.5 cm of water, the soil moisture control section is the boundary of the contact itself. The control section of such a soil is considered moist if the contact or upper boundary of the cemented horizon has a thin film of water. If that upper boundary is dry, the control section is considered dry.				  adjustLayer_byImp <- function(depths, imp_depth){				    if(any(imp_depth < depths[1])){				      depths <- imp_depth				      if(nrow(stemp) >= 2){				        if((temp <- findInterval(imp_depth, stemp[, "depth_cm"])) > 1){				          depths <- c(stemp[temp - 1, "depth_cm"], imp_depth)				        } else {				          depths <- c(imp_depth, stemp[temp + 1, "depth_cm"])				        }				      }				    } else if(any(imp_depth < depths[2])){				      depths <- c(depths[1], imp_depth)				    }				    return(depths)				  }				  MCS_depth <- adjustLayer_byImp(depths=MCS_depth, imp_depth=imp_depth)				  				  #Soil layer 10-70 cm used for anhydrous layer definition; adjusted for impermeable layer				  Lanh_depth <- adjustLayer_byImp(depths=c(10, 70), imp_depth=imp_depth)				  				  #Set soil depths and intervals accounting for shallow soil profiles				  #50cm soil depth or impermeable layer (whichever is shallower; Soil Survey Staff 2014: p.31)				  i_depth50 <- findInterval(Fifty_depth, vec=stemp[, "depth_cm"])				  				  #Permafrost (Soil Survey Staff 2014: p.28) is defined as a thermal condition in which a material (including soil material) remains below 0 C for 2 or more years in succession				  permafrost <- any(apply(soiltemp.yr.all$val[simTime$index.useyr, -1, drop=FALSE], 2, FUN=function(x) {				    temp <- rle(x < 0)				    res <- (any(temp$values) && any(temp$lengths[temp$values] >= 2))				  }))				  				  ##Calculate soil temperature at necessary depths using a weighted mean				  if(calc50<-stemp[i_depth50, "depth_cm"] != Fifty_depth) {				  stemp<-stemp[c(1:i_depth50,NA,(i_depth50+1):dim(stemp)[1]),]				  weights50 <- c(abs(Fifty_depth-stemp[i_depth50+2,"depth_cm"]),abs(Fifty_depth-stemp[i_depth50,"depth_cm"]))				  stemp[(i_depth50+1),1]<-Fifty_depth				  i_depth50 <- findInterval(Fifty_depth, vec=stemp[, "depth_cm"])				  }				  				  i_MCS1 <- findInterval(MCS_depth[1], vec=stemp[, "depth_cm"])				  if(calcMCS1<-MCS_depth[1] %in% stemp[,"depth_cm"] == FALSE) {				    stemp<-stemp[c(1:i_MCS1,NA,(i_MCS1+1):dim(stemp)[1]),]				    weightsMCS1 <- c(abs(MCS_depth[1]-stemp[i_MCS1+2,"depth_cm"]),abs(MCS_depth[1]-stemp[i_MCS1,"depth_cm"]))				    stemp[(i_MCS1+1),1]<-MCS_depth[1]				    i_MCS1 <- findInterval(MCS_depth[1], vec=stemp[, "depth_cm"])				  }				  				  i_MCS2 <- findInterval(MCS_depth[2], vec=stemp[, "depth_cm"])				  if(calcMCS2<-MCS_depth[2] %in% stemp[,"depth_cm"] == FALSE) {				    stemp<-stemp[c(1:i_MCS2,NA,(i_MCS2+1):dim(stemp)[1]),]				    weightsMCS2 <- c(abs(MCS_depth[2]-stemp[i_MCS2+2,"depth_cm"]),abs(MCS_depth[2]-stemp[i_MCS2,"depth_cm"]))				    stemp[(i_MCS2+1),1]<-MCS_depth[2]				    i_MCS2 <- findInterval(MCS_depth[2], vec=stemp[, "depth_cm"])				  }				  				  #Calculations				  if(all(c(Fifty_depth, MCS_depth) %in% stemp[, "depth_cm"]) && sd(soiltemp.yr.all$val[,-1]) > 0){ #Test for presence of required soil depths and for simulated soil temperature output				    if(!exists("soiltemp.mo.all")) soiltemp.mo.all <- get_Response_aggL(sc, sw_soiltemp, "moAll", scaler=1, FUN=weighted.mean, weights=layers_width)				    if(!exists("soiltemp.dy.all")) soiltemp.dy.all <- get_Response_aggL(sc, sw_soiltemp, "dyAll", scaler=1, FUN=weighted.mean, weights=layers_width)				    if(!exists("vwcmatric.dy.all")) vwcmatric.dy.all <- get_Response_aggL(sc, sw_vwcmatric, "dyAll", 1, FUN=weighted.mean, weights=layers_width)				    if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- get_SWPmatric_aggL(vwcmatric.dy.all)				    if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)				    if(!exists("prcp.mo")) prcp.mo <- get_PPT_mo(sc)				    				    #create soil temperature at necessary layers using weighted means				    if(calc50){				    soiltemp.yr.all$val<-soiltemp.yr.all$val[,c(1:(i_depth50),NA,(i_depth50+1):dim(soiltemp.yr.all$val)[2])]				    soiltemp.yr.all$val[,(i_depth50+1)]<-apply(soiltemp.yr.all$val,1,function(x) weighted.mean(x[c(i_depth50,i_depth50+2)],weights50))  				    				    soiltemp.mo.all$val<-soiltemp.mo.all$val[,c(1:(1+i_depth50),NA,(i_depth50+2):dim(soiltemp.mo.all$val)[2])]				    soiltemp.mo.all$val[,(i_depth50+2)]<-apply(soiltemp.mo.all$val,1,function(x) weighted.mean(x[c(i_depth50+1,i_depth50+3)],weights50))				    				    soiltemp.dy.all$val<-soiltemp.dy.all$val[,c(1:(1+i_depth50),NA,(i_depth50+2):dim(soiltemp.dy.all$val)[2])]				    soiltemp.dy.all$val[,(i_depth50+2)]<-apply(soiltemp.dy.all$val,1,function(x) weighted.mean(x[c(i_depth50+1,i_depth50+3)],weights50))				    				    swpmatric.dy.all$val<-swpmatric.dy.all$val[,c(1:(1+i_depth50),NA,(i_depth50+2):dim(swpmatric.dy.all$val)[2])]				    swpmatric.dy.all$val[,(i_depth50+2)]<-apply(swpmatric.dy.all$val,1,function(x) weighted.mean(x[c(i_depth50+1,i_depth50+3)],weights50))				    }				    				    if(calcMCS1){				      soiltemp.yr.all$val<-soiltemp.yr.all$val[,c(1:(i_MCS1),NA,(i_MCS1+1):dim(soiltemp.yr.all$val)[2])]				      soiltemp.yr.all$val[,(i_MCS1+1)]<-apply(soiltemp.yr.all$val,1,function(x) weighted.mean(x[c(i_MCS1,i_MCS1+2)],weightsMCS1))  				      				      soiltemp.mo.all$val<-soiltemp.mo.all$val[,c(1:(1+i_MCS1),NA,(i_MCS1+2):dim(soiltemp.mo.all$val)[2])]				      soiltemp.mo.all$val[,(i_MCS1+2)]<-apply(soiltemp.mo.all$val,1,function(x) weighted.mean(x[c(i_MCS1+1,i_MCS1+3)],weightsMCS1))				      				      soiltemp.dy.all$val<-soiltemp.dy.all$val[,c(1:(1+i_MCS1),NA,(i_MCS1+2):dim(soiltemp.dy.all$val)[2])]				      soiltemp.dy.all$val[,(i_MCS1+2)]<-apply(soiltemp.dy.all$val,1,function(x) weighted.mean(x[c(i_MCS1+1,i_MCS1+3)],weightsMCS1))				      				      swpmatric.dy.all$val<-swpmatric.dy.all$val[,c(1:(1+i_MCS1),NA,(i_MCS1+2):dim(swpmatric.dy.all$val)[2])]				      swpmatric.dy.all$val[,(i_MCS1+2)]<-apply(swpmatric.dy.all$val,1,function(x) weighted.mean(x[c(i_MCS1+1,i_MCS1+3)],weightsMCS1))				    }				    				    if(calcMCS2){				      soiltemp.yr.all$val<-soiltemp.yr.all$val[,c(1:(i_MCS2),NA,(i_MCS2+1):dim(soiltemp.yr.all$val)[2])]				      soiltemp.yr.all$val[,(i_MCS2+1)]<-apply(soiltemp.yr.all$val,1,function(x) weighted.mean(x[c(i_MCS2,i_MCS2+2)],weightsMCS2))  				      				      soiltemp.mo.all$val<-soiltemp.mo.all$val[,c(1:(1+i_MCS2),NA,(i_MCS2+2):dim(soiltemp.mo.all$val)[2])]				      soiltemp.mo.all$val[,(i_MCS2+2)]<-apply(soiltemp.mo.all$val,1,function(x) weighted.mean(x[c(i_MCS2+1,i_MCS2+3)],weightsMCS2))				      				      soiltemp.dy.all$val<-soiltemp.dy.all$val[,c(1:(1+i_MCS2),NA,(i_MCS2+2):dim(soiltemp.dy.all$val)[2])]				      soiltemp.dy.all$val[,(i_MCS2+2)]<-apply(soiltemp.dy.all$val,1,function(x) weighted.mean(x[c(i_MCS2+1,i_MCS2+3)],weightsMCS2))				      				      swpmatric.dy.all$val<-swpmatric.dy.all$val[,c(1:(1+i_MCS2),NA,(i_MCS2+2):dim(swpmatric.dy.all$val)[2])]				      swpmatric.dy.all$val[,(i_MCS2+2)]<-apply(swpmatric.dy.all$val,1,function(x) weighted.mean(x[c(i_MCS2+1,i_MCS2+3)],weightsMCS2))				    }				    #MCS (Soil Survey Staff 2014: p.29)				    #What soil layer info used for MCS				    if(is.na(MCS_depth[2]) || isTRUE(all.equal(MCS_depth[1], MCS_depth[2]))){				      i_MCS <- findInterval(MCS_depth[1], vec=stemp[, "depth_cm"])				    } else {				      i_MCS <- (1+findInterval(MCS_depth[1], vec=stemp[, "depth_cm"])):findInterval(MCS_depth[2], vec=stemp[, "depth_cm"])				    }				    MCS <- swpmatric.dy.all$val[simTime$index.usedy, 2 + i_MCS, drop=FALSE]				    #Repeat for Anhydrous soil layer moisture delineation				    if(is.na(Lanh_depth[2]) || isTRUE(all.equal(Lanh_depth[1], Lanh_depth[2]))){				      i_Lanh_depth <- findInterval(Lanh_depth[1], vec=stemp[, "depth_cm"])				    } else {				      i_Lanh_depth <- (1+findInterval(Lanh_depth[1], vec=stemp[, "depth_cm"])):findInterval(Lanh_depth[2], vec=stemp[, "depth_cm"])				    }				    				    #---Calculate variables				    #Water year starting Oct 1				    wateryears <- simTime2$year_ForEachUsedDay_NSadj + ifelse(simTime2$doy_ForEachUsedDay_NSadj > 273, 1, 0)	# 1. water-year: N-hemisphere: October 1st = 1 day of water year; S-hemisphere: April 1st = 1 day of water year				    wyears <- (temp <- unique(wateryears))[-length(temp)]#eliminate last year				    				    				    #mean soil temperature in Lahn depths (10 - 70 cm)				    iL <- length(i_Lanh_depth)				    if(iL == 1) {MATLanh<- soiltemp.yr.all$val[simTime$index.useyr,(1+i_Lanh_depth[1])]				    }else{				      MATLanh<- apply(soiltemp.yr.all$val[simTime$index.useyr,(1+i_Lanh_depth[1]):(1+i_Lanh_depth[iL])],1,FUN=weighted.mean)				    }				    #mean soil temperatures at 50cm depth				    MAT50 <- soiltemp.yr.all$val[simTime$index.useyr, 1 + i_depth50]				    T50jja <- soiltemp.mo.all$val[simTime$index.usemo, 2 + i_depth50][simTime2$month_ForEachUsedMonth_NSadj %in% 6:8]				    T50jja <- apply(matrix(T50jja,ncol=length(unique(simTime$index.useyr))),2,function(s) mean(s))				    T50djf <- soiltemp.mo.all$val[simTime$index.usemo, 2 + i_depth50][simTime2$month_ForEachUsedMonth_NSadj %in% c(12, 1:2)]				    T50djf <- apply(matrix(T50djf,ncol=length(unique(simTime$index.useyr))),2,function(s) mean(s))				    T50 <- soiltemp.dy.all$val[simTime$index.usedy, 2 + i_depth50]				    #Moist and dry at 50cm depth for MCS and Lahn calcs				    Days_str <- swpmatric.dy.all$val[simTime$index.usedy, ]				    				    #CSPartSummer: Is the soil saturated with water during some part of the summer June1 (=regular doy 244) - Aug31 (=regular doy 335)				    CSPartSummer <- mean(sapply(wyears, FUN=function(yr){				      i_temp <- (wateryears == yr)				      i_temp <- i_temp & (simTime2$doy_ForEachUsedDay >= 244 & simTime2$doy_ForEachUsedDay <= 335)				      temp <- apply(swpmatric.dy.all$val[simTime$index.usedy, -(1:2)], 1, FUN=function(x) all(x >= SWP_sat)) 				      rtemp <- rle(temp)				      res <- if(any(rtemp$values)) max(rtemp$lengths[rtemp$values]) else 0				      return(res)}))				    #---Soil temperature regime: based on Chambers et al. 2014: Appendix 3 and on Soil Survey Staff 2010: p.28/Soil Survey Staff 2014: p.31				    #we ignore distinction between iso- and not iso-				    if(mean(MAT50) >= 22){				      Tregime["Hyperthermic"] <- 1				    } else if(mean(MAT50) >= 15){				      Tregime["Thermic"] <- 1				    } else if(mean(MAT50) >= 8){				      Tregime["Mesic"] <- 1				    } else if(mean(MAT50) < 8 && mean(MAT50) > 0){				      if(CSPartSummer > 0){ #ignoring organic soils, Saturated with water				        if(mean(T50jja) > 0 && mean(T50jja) < 13){ #ignoring O-horizon				          Tregime["Cryic"] <- 1				        } else {				          Tregime["Frigid"] <- 1				        }				      } else {#ignoring O-horizon and histic epipedon, Not saturated with water				        if(mean(T50jja) > 0 && mean(T50jja) < 15){				          Tregime["Cryic"] <- 1				        } else {				          Tregime["Frigid"] <- 1				        }				      }				    } else if(mean(MAT50) <= 0 || permafrost){ #limit should be 1 C for Gelisols				      Tregime["Gelic"] <- 1				    }				    #Normal years for soil moisture regimes (Soil Survey Staff 2014: p.29)				    #Should have a time period of 30 years to determine normal years				    MAP <- c(mean(prcp.yr$ppt), sd(prcp.yr$ppt))				    normal1 <- (prcp.yr$ppt >= MAP[1] - MAP[2]) & (prcp.yr$ppt <= MAP[1] + MAP[2])				    MMP <- aggregate(prcp.mo$ppt, by=list(simTime2$month_ForEachUsedMonth), FUN=function(x) c(mean(x), sd(x)))[, -1]				    normal2 <- aggregate(prcp.mo$ppt, by=list(simTime2$yearno_ForEachUsedMonth_NSadj), FUN=function(x) sum((x >= MMP[,1] - MMP[,2]) & (x <= MMP[,1] + MMP[,2])) >= 8)[, -1]				    wyears_normal <- wyears[normal1 & normal2]				    wyears_normal <- (simstartyr+1):endyr				    wyears_index <- findInterval(wyears_normal,wyears)				    				    if(!be.quiet) if(length(wyears_normal) <= 2) {print("Number of normal years not long enough to calculated NRCS Soil Moisture Regimes. Try increasing length of simulation")}				    if(length(wyears_normal) > 2){				      #Structures used Lanh delinieation				      #days where T @ 50 is > 0c				      T50_at0C <-lapply(wyears_normal, FUN=function(yr) T50[wateryears == yr] > 0)				      #Days where moists in half of the Lanh soil depth				      Lanh_Moist <- lapply(wyears_normal, FUN=function(Year) Days_str[wateryears == Year,(2+i_Lanh_depth)] > SWP_dry)				      if(iL == 1){Lanh_Dry_Half<-lapply(Lanh_Moist,function(x) y<-ifelse(x == TRUE, FALSE, TRUE))#IF moist in one layer, moist in greater than half				      }else{				        Lanh_Dry_Half<-lapply(Lanh_Moist,function(x) y<-ifelse((rowSums(x) <= (.5 * dim(x)[2])) == TRUE, TRUE, FALSE))#True - dry in greater than half of layers				      }				      #Conditions for Anhydrous soil delineation				      LanhConditionalDF<-data.frame(Years = rep(wyears_normal,lapply(T50_at0C,length)),				                                DOY = unlist(lapply(wyears_normal,FUN=function(x) 1:length(simTime2$year_ForEachUsedDay_NSadj [simTime2$year_ForEachUsedDay_NSadj  == x])))[1:length(unlist(T50_at0C))],				                                T50_at0C = unlist(T50_at0C),				                                Lanh_Dry_Half = unlist(Lanh_Dry_Half),				                                MAT50 = rep(MAT50[wyears_index],lapply(T50_at0C,length)),				                                MATLanh = rep(MATLanh[wyears_index],lapply(T50_at0C,length))				                                )				      #Mean Annual soil temperature is less than or equal to 0C				      LanhConditionalDF$COND1<-LanhConditionalDF$MAT50 <= 0				      #Soil temperature in the Lahn Depth is never greater than 5 				      LanhConditionalDF$COND2<-LanhConditionalDF$MATLanh <= 5				      #In the Lahn Depth, 1/2 of soil dry > 1/2 CUMULATIVE days when Mean Annual ST > 0C				      LanhConditionalDF$COND3_Test <- (LanhConditionalDF$Lanh_Dry_Half == LanhConditionalDF$T50_at0C)#TRUE = where are both these conditions met				      LanhConditionalDF <- ddply(LanhConditionalDF,.(Years),transform, HalfDryDaysCumAbove0C = sum(COND3_Test == TRUE),SoilAbove0C=sum(T50_at0C == TRUE))#Number of days where 1/2 soil layers are are dry while temp >0				      LanhConditionalDF$COND3 <- LanhConditionalDF$HalfDryDaysCumAbove0C > (.5 * LanhConditionalDF$SoilAbove0C)#TRUE = Half of soil layers are dry greater than half the days where MAST >0c				      				      LanhConditionalDF2<-unique(LanhConditionalDF[,c('Years','COND1','COND2','COND3')])				      LanhConditionalDF3<-apply(LanhConditionalDF2[,2:length(LanhConditionalDF2)],2,function(x) length(which(x==TRUE)) >= length(which(x==FALSE)))				      #Structures used for MCS delineation				      #days where T @ 50cm exceeds 5C and 8C				      T50_at5C <-lapply(wyears_normal, FUN=function(yr) T50[wateryears == yr] > 5)				      T50_at8C <-lapply(wyears_normal, FUN=function(yr) T50[wateryears == yr] > 8)				      #days where any or  all soil layers are moist				      MCS_Moist <- lapply(wyears_normal, FUN=function(Year) Days_str[wateryears == Year,(2+i_MCS)] > SWP_dry)				      MCS_Dry <- lapply(wyears_normal, FUN=function(Year) Days_str[wateryears == Year,(2+i_MCS)] < SWP_dry)				      iM <- length(i_MCS)				      if(iM == 1) {				        MCS_Moist_All<-MCS_Moist				        MCS_Dry_All<-MCS_Dry				      }else{				        MCS_Moist_All<-lapply(MCS_Moist,function(x) y<-ifelse(eval(parse(text=paste0("x[,",1:iM,"]",c(rep("&",iM-1),"")))) == TRUE,TRUE,FALSE))				        MCS_Dry_All<-lapply(MCS_Dry,function(x) y<-ifelse(eval(parse(text=paste0("x[,",1:iM,"]",c(rep("&",iM-1),"")))) == TRUE,TRUE,FALSE))				      }				      #Build Conditional Data.frame				      ConditionalDF<-data.frame(Years = rep(wyears_normal,lapply(T50_at5C,length)),				                                DOY = unlist(lapply(wyears_normal,FUN=function(x) 1:length(simTime2$year_ForEachUsedDay_NSadj [simTime2$year_ForEachUsedDay_NSadj  == x])))[1:length(unlist(T50_at5C))],				                                T50_at5C=unlist(T50_at5C),				                                T50_at8C=unlist(T50_at8C),				                                MCS_Moist_All=unlist(MCS_Moist_All),				                                MCS_Dry_All=unlist(MCS_Dry_All),				                                MAT50 = rep(MAT50[wyears_index],lapply(T50_at5C,length)),				                                T50jja = rep(T50jja[wyears_index],lapply(T50_at5C,length)),				                                T50djf = rep(T50djf[wyears_index],lapply(T50_at5C,length))				                                )				      				      #COND1 - Dry in ALL parts for more than half of the CUMLATIVE days per year when the soil temperature at a depth of 50cm is above 5C  				      ConditionalDF$COND1_Test <- ifelse(ConditionalDF$MCS_Dry_All == TRUE & ConditionalDF$T50_at5C ==TRUE,TRUE,FALSE)#TRUE = where are both these conditions met				      ConditionalDF <- ddply(ConditionalDF,.(Years),transform, DryDaysCumAbove5C = sum(COND1_Test == TRUE), SoilAbove5C = sum(T50_at5C ==TRUE))#Number of days where soils are are dry while temp50_5C				      ConditionalDF$COND1 <- ConditionalDF$DryDaysCumAbove5C > (.5 * ConditionalDF$SoilAbove5C)#TRUE = Dry Soils are greater than 1/2 cumulative days/year				      				      #COND1.1 - Moist in SOME or ALL parts for more than half of the CUMLATIVE days per year when the soil temperature at a depth of 50cm is above 5				      #!MCs_Dry_All = MCS_ Moist Any				      ConditionalDF$COND1_1_Test <- ifelse(ConditionalDF$MCS_Dry_All == FALSE & ConditionalDF$T50_at5C ==TRUE,TRUE,FALSE)#TRUE = where are both these conditions met				      ConditionalDF <- ddply(ConditionalDF,.(Years),transform, AnyMoistDaysCumAbove5C = sum(COND1_1_Test == TRUE))#Number of days where soils are are dry while temp50_5C				      ConditionalDF$COND1_1 <- ConditionalDF$AnyMoistDaysCumAbove5C > (.5 * ConditionalDF$SoilAbove5C)#TRUE = Dry Soils are greater than 1/2 cumulative days/year?				      				      #Cond2 - Moist in SOME or all parts for less than 90 CONSECUTIVE days when the the soil temperature at a depth of 50cm is above 8C                                             				      ConditionalDF$COND2_Test <- ifelse(ConditionalDF$MCS_Dry_All == FALSE & ConditionalDF$T50_at8C == TRUE, TRUE,FALSE)#TRUE = where are both these conditions met				      COND2_Value <- ddply(ConditionalDF,.(Years),function(x) consec(x$COND2_Test))#Consecutive days of Moist soil				      COND2_Value <-rename(COND2_Value,replace=c("V1"="MoistDaysConsecAbove8C"))				      ConditionalDF <- suppressMessages(join(ConditionalDF,COND2_Value))				      ConditionalDF$COND2 <- ConditionalDF$MoistDaysConsecAbove8C < 90 & ConditionalDF$MoistDaysConsecAbove8C > 0 # TRUE = moist less than 90 consecutive days , FALSE = moist more than 90 consecutive days				      				      #COND3 - MCS is Not dry in ANY part as long as 90 CUMLATIVE days - Can't be dry longer than 90 cum days				      ConditionalDF <- ddply(ConditionalDF,.(Years),transform, DryDaysCumAny = sum(MCS_Moist_All == FALSE))#Number of days where any soils are dry				      ConditionalDF$COND3 <- ConditionalDF$DryDaysCumAny < 90 #TRUE = Not Dry for as long 90 cumlative days,FALSE = Dry as long as as 90 Cumlative days				      				      #COND4 - The means annual soil temperature at 50cm is < or > 22C 				      ConditionalDF$COND4 <- ConditionalDF$MAT50>22 #TRUE - Greater than 22, False - Less than 22				      				      #COND5 - The absolute difference between the temperature in winter @ 50cm and the temperature in summer @ 50cm is > or < 6				      ConditionalDF$COND5 <-  abs(ConditionalDF$T50djf - ConditionalDF$T50jja) > 6 #TRUE - Greater than 6, FALSE - Less than 6				      				      #COND6 - Dry in ALL parts LESS than 45 CONSECUTIVE days in the 4 months following the summer solstice				      DryDaysConsecSummer <- ddply(ConditionalDF[ConditionalDF$DOY %in% c(172:293),],.(Years),function(x) consec(x$MCS_Dry_All))#Consecutive days of dry soil after summer solsitice				      DryDaysConsecSummer <- rename (DryDaysConsecSummer,replace = c("V1" = "DryDaysConsecSummer"))				      ConditionalDF <- suppressMessages(join(ConditionalDF,DryDaysConsecSummer))				      ConditionalDF$COND6 <- ConditionalDF$DryDaysConsecSummer < 45 # TRUE = dry less than 45 consecutive days 				      				      #COND7 - MCS is MOIST in SOME parts for more than 180 CUMLATIVE days				      ConditionalDF <- ddply(ConditionalDF,.(Years),transform, MoistDaysCumAny = sum(MCS_Dry_All == FALSE))#Number of days where any soils are moist 				      ConditionalDF$COND7 <- ConditionalDF$MoistDaysCumAny > 180 #TRUE = Not Dry or Moist for as long 180 cumlative days				      				      #Cond8 - MCS is MOIST in SOME parts for more than 90 CONSECUTIVE days				      MoistDaysConsecAny <- ddply(ConditionalDF,.(Years),function(x) consec(!x$MCS_Dry_All))#Consecutive days of moist soil 				      MoistDaysConsecAny <- rename (MoistDaysConsecAny,replace = c("V1" = "MoistDaysConsecAny"))				      ConditionalDF <- suppressMessages(join(ConditionalDF,MoistDaysConsecAny))				      ConditionalDF$COND8 <- ConditionalDF$MoistDaysConsecAny > 90 # TRUE = Moist more than 90 Consecutive Days 				      				      #COND9 - Moist in ALL parts MORE than 45 CONSECUTIVE days in the 4 months following the winter solstice				      MoistDaysConsecWinter <- ddply(ConditionalDF[ConditionalDF$DOY %in% c(355:365,1:111),],.(Years),function(x) consec(x$MCS_Moist_All))#Consecutive days of moist soil after winter solsitice				      MoistDaysConsecWinter <- rename (MoistDaysConsecWinter,replace = c("V1" = "MoistDaysConsecWinter"))				      ConditionalDF<-suppressMessages(join(ConditionalDF,MoistDaysConsecWinter))				      ConditionalDF$COND9<-ConditionalDF$MoistDaysConsecWinter > 45 # TRUE = moist more than 45 consecutive days 				      				      ConditionalDF2<-unique(ConditionalDF[,c('Years','COND1','COND1_1','COND2','COND3','COND4','COND5','COND6','COND7','COND8','COND9')])				      ConditionalDF3<-apply(ConditionalDF2[,2:length(ConditionalDF2)],2,function(x) length(which(x==TRUE)) >= length(which(x==FALSE)))				      				      #---Soil moisture regime: based on Chambers et al. 2014: Appendix 3 and on Soil Survey Staff 2010: p.26-28/Soil Survey Staff 2014: p.28-31				      #we ignore 'Aquic'				      				      #Anhydrous condition: Soil Survey Staff 2010: p.16/Soil Survey Staff 2014: p.18				      #we ignore test for 'ice-cemented permafrost' and 'rupture-resistance class'				      if(LanhConditionalDF3['COND1'] ==TRUE && LanhConditionalDF3['COND2'] == TRUE && LanhConditionalDF3['COND3'] == TRUE) Sregime["Anhydrous"] <- 1				      				      #Aridic soil moisture regime; The limits set for soil temperature exclude from these soil moisture regimes soils in the very cold and dry polar regions and in areas at high elevations. Such soils are considered to have anhydrous condition				      if(ConditionalDF3['COND1'] == TRUE && ConditionalDF3['COND2'] == TRUE && ConditionalDF3['COND3'] == FALSE) Sregime["Aridic"] <- 1				      				      #Udic soil moisture regime - #we ignore test for 'three- phase system' during T50 > 5				      if(ConditionalDF3['COND3'] == TRUE) 				          if(ConditionalDF3['COND4'] == FALSE && ConditionalDF3['COND5'] == TRUE){				            if(ConditionalDF3['COND6'] == TRUE) Sregime["Udic"] <- 1				          }else{				          Sregime["Udic"] <- 1				        }				      				      #Ustic soil moisture regime				        if(!permafrost)				          if(ConditionalDF3['COND4'] == TRUE || ConditionalDF3['COND5'] == FALSE)				            if(ConditionalDF3['COND3'] == FALSE && (ConditionalDF3['COND7'] == TRUE || ConditionalDF3['COND8'] == TRUE)) Sregime["Ustic"] <- 1				        if(!permafrost)				            if(ConditionalDF3['COND4'] == FALSE && ConditionalDF3['COND5'] == TRUE)				              if(ConditionalDF3['COND3']==FALSE && ConditionalDF3['COND1'] == FALSE)				                if(ConditionalDF3['COND9']==TRUE){				                  if(ConditionalDF3['COND6']==TRUE) Sregime["Ustic"] <- 1				                } else {				                  Sregime["Ustic"]<-1				                }				     #Xeric soil moisture regime				       if(ConditionalDF3['COND6'] == FALSE && ConditionalDF3['COND9'] == TRUE &&				          ConditionalDF3['COND4'] ==  FALSE  && ConditionalDF3['COND5'] ==TRUE &&				          (ConditionalDF3['COND1_1'] == TRUE || ConditionalDF3['COND2'] == FALSE)){				         Sregime["Xeric"] <- 1				       }				      regimes_done <- TRUE				      				      SoilAbove0C<-round(mean(LanhConditionalDF$SoilAbove0C),0)				      SoilAbove5C<-round(mean(ConditionalDF$SoilAbove5C),0)				      DryDaysCumAbove5C<-round(mean(ConditionalDF$DryDaysCumAbove5C),0)				      MoistDaysConsecAbove8C<-round(mean(ConditionalDF$MoistDaysConsecAbove8C),0)				      DryDaysConsecSummer<-round(mean(ConditionalDF$DryDaysConsecSummer),0)				      MoistDaysConsecAny<-round(mean(ConditionalDF$MoistDaysConsecAny),0)				      MoistDaysCumAny<-round(mean(ConditionalDF$MoistDaysCumAny),0)				      DryDaysCumAny<-round(mean(ConditionalDF$DryDaysCumAny),0)				      MoistDaysConsecWinter<-round(mean(ConditionalDF$MoistDaysConsecWinter),0)				      				      rm(i_MCS, MCS, i_Lanh_depth, iL)				  				    } else {				      Sregime[] <- NA				      Tregime[] <- NA				    }				    				    rm(wateryears, wyears, i_depth50, T50, MAP, normal1, normal2, wyears_normal,wyears_index)				    				  } else {				    Tregime[] <- NA				    Sregime[] <- NA				  }				  }  				  print(i_labels)				  print(Sregime)				  print(Tregime)				  				  resMeans[nv:(nv+4+15+length(Tregime_names)+length(Sregime_names))] <- c(Fifty_depth, MCS_depth[1:2], Lanh_depth[1:2], as.integer(permafrost),				                                                                           mean(MATLanh),mean(MAT50), mean(T50jja), mean(T50djf),CSPartSummer,   				                                                                          SoilAbove0C,SoilAbove5C,DryDaysCumAbove5C,MoistDaysConsecAbove8C,  				                                                                          DryDaysConsecSummer,MoistDaysConsecAny,MoistDaysCumAny,DryDaysCumAny,MoistDaysConsecWinter,				                                                                            Tregime, Sregime)				  nv <- nv+4+15+length(Tregime_names)+length(Sregime_names)+1				  				  to_del <- c("SWP_dry", "SWP_sat", "impermeability", "Tregime_names", "Sregime_names", "stemp", "sand_temp", "clay_temp", "imp_depth", 				              "MCS_depth", "Fifty_depth", "Lanh_depth", "permafrost", "MAT50","MATLanh","T50jja", "T50djf", "CSPartSummer", "T50_at5C", "T50_at8C","T50_at0C",				              "MCS_Moist","MoistDaysConsecAbove8C","MCS_Moist_All","DryDaysCumAny","Lanh_Dry_Half","Lanh_Moist","LanhConditionalDF","LanhConditionalDF2","LanhConditionalDF3",				              "MoistDaysConsecAny","MoistDaysConsecWinter","ConditionalDF","ConditionalDF2","ConditionalDF3","SoilAbove0C","SoilAbove5C","DryDaysCumAbove5C",				              "DryDaysConsecSummer","MoistDaysCumAny","calc50","calcMCS1","calcMS2","i_MCS","i_MCS1","i_MCS2","iL","MCS","iM")				  				  to_del <- to_del[to_del %in% ls()]				  if(length(to_del) > 0) try(rm(list=to_del), silent=TRUE)				  				  }				  			#26				if(any(simulation_timescales=="daily") && aon$dailyNRCS_Chambers2014_ResilienceResistance && aon$dailyNRCS_SoilMoistureTemperatureRegimes){	#Requires "dailyNRCS_SoilMoistureTemperatureRegimes"					#Based on Table 1 in Chambers, J. C., D. A. Pyke, J. D. Maestas, M. Pellant, C. S. Boyd, S. B. Campbell, S. Espinosa, D. W. Havlina, K. E. Mayer, and A. Wuenschel. 2014. Using Resistance and Resilience Concepts to Reduce Impacts of Invasive Annual Grasses and Altered Fire Regimes on the Sagebrush Ecosystem and Greater Sage-Grouse: A Strategic Multi-Scale Approach. Gen. Tech. Rep. RMRS-GTR-326. U.S. Department of Agriculture, Forest Service, Rocky Mountain Research Station, Fort Collins, CO.					if(print.debug) print("Aggregation of dailyNRCS_Chambers2014_ResilienceResistance")					if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)					#Result containers					cats <- c("Low", "ModeratelyLow", "Moderate", "ModeratelyHigh", "High")					resilience <- resistance <- rep(0, times=length(cats))					names(resilience) <- names(resistance) <- cats					if(regimes_done){						#---Table 1 in Chambers et al. 2014						rows_resilience <- c("ModeratelyHigh", "ModeratelyHigh", "Moderate", "Low", "Low")						rows_resistance <- c("High", "Moderate", "ModeratelyLow", "Moderate", "Low")						#Ecological type						Table1_EcologicalType <- matrix(c("Cryic", "Xeric", "Frigid", "Xeric", "Mesic", "Xeric", "Frigid", "Aridic", "Mesic", "Aridic"), ncol=2, byrow=TRUE)						Type <- as.logical(Tregime[Table1_EcologicalType[, 1]]) & as.logical(Sregime[Table1_EcologicalType[, 2]])						#Characteristics						MAP <- mean(prcp.yr$ppt)						Table1_Characteristics_mm <- matrix(c(14, Inf, 12, 22, 12, 16, 6, 12, 8, 12), ncol=2, byrow=TRUE) * 2.54 * 10						Characteristics <- MAP >= Table1_Characteristics_mm[, 1] & MAP <= Table1_Characteristics_mm[, 2]						#Resilience and Resistance						RR <- which(Type & Characteristics)						for(ir in RR){							resilience[rows_resilience[ir]] <- 1							resistance[rows_resistance[ir]] <- 1						}						rm(rows_resilience, rows_resistance, Table1_EcologicalType, Type,							MAP, Table1_Characteristics_mm, Characteristics, RR)					} else {						resilience <- resistance <- rep(NA, times=length(cats))					}					resMeans[nv:(nv+2*length(cats)-1)] <- c(resilience, resistance)					nv <- nv + 2*length(cats)					rm(cats, resilience, resistance, Tregime, Sregime)				}				rm(regimes_done)				#---Aggregation: Yearly water balance			#27				if(any(simulation_timescales=="yearly") & aon$yearlyWaterBalanceFluxes) {					if(print.debug) print("Aggregation of yearlyWaterBalanceFluxes")					if(!exists("prcp.yr")) prcp.yr <- get_PPT_yr(sc)					if(!exists("Esurface.yr")) Esurface.yr <- get_Esurface_yr(sc)					if(!exists("intercept.yr")) intercept.yr <- get_Interception_yr(sc)					if(!exists("inf.yr")) inf.yr <- get_Inf_yr(sc)					if(!exists("runoff.yr")) runoff.yr <- get_Runoff_yr(sc)					if(!exists("transp.yr")) transp.yr <- get_Response_aggL(sc, sw_transp, "yr", 10, sum)					if(!exists("AET.yr")) AET.yr <- get_AET_yr(sc)					if(!exists("PET.yr")) PET.yr <- get_PET_yr(sc)					if(!exists("Esoil.yr")) Esoil.yr <- get_Response_aggL(sc, sw_evsoil, "yr", 10, sum)					if(!exists("deepDrain.yr")) deepDrain.yr <- get_DeepDrain_yr(sc)					rain_toSoil <- prcp.yr$rain - intercept.yr$sum					transp.tot <- transp.yr$top + transp.yr$bottom					evap_soil.tot <- as.vector(Esoil.yr$top + Esoil.yr$bottom)					evap.tot <- evap_soil.tot + Esurface.yr$sum + prcp.yr$snowloss					temp1 <- 10 * slot(slot(runData[[sc]],sw_percolation),"Year")					if(length(topL) > 1 && length(bottomL) > 0 && !identical(bottomL, 0)) {						drain.topTobottom <- temp1[simTime$index.useyr, 1+DeepestTopLayer]					} else {						drain.topTobottom <- NA					}					temp1 <- 10 * slot(slot(runData[[sc]],sw_hd),"Year")					if(length(topL) > 1) {						hydred.topTobottom <- apply(temp1[simTime$index.useyr, 1+topL, drop=FALSE], 1, sum)					} else {						hydred.topTobottom <- temp1[simTime$index.useyr,1+topL]					}					if( any(simulation_timescales=="daily")) {						temp1 <- 10 * slot(slot(runData[[sc]],sw_swcbulk),"Day")						if(simTime$index.usedy[1] == 1){ #simstartyr == startyr, then (simTime$index.usedy-1) misses first value							index.usedyPlusOne <- simTime$index.usedy[-length(simTime$index.usedy)]+1						} else {							index.usedyPlusOne <- simTime$index.usedy						}						if(length(topL) > 1) {							swcdyflux <- apply(temp1[index.usedyPlusOne,2+ld], 1, sum) - apply(temp1[index.usedyPlusOne-1,2+ld], 1, sum)						} else {							swcdyflux <- temp1[index.usedyPlusOne,2+ld] - temp1[index.usedyPlusOne-1,2+ld]						}						swc.flux <- aggregate(swcdyflux, by=list(temp1[index.usedyPlusOne,1]), FUN=sum)[,2]					} else {						swc.flux <- NA					}					#mean fluxes					resMeans[nv:(nv+22)] <- apply(fluxtemp <- cbind(prcp.yr$rain, rain_toSoil, prcp.yr$snowfall, prcp.yr$snowmelt, prcp.yr$snowloss, intercept.yr$sum, intercept.yr$veg, intercept.yr$litter, Esurface.yr$veg, Esurface.yr$litter, inf.yr$inf, runoff.yr$val, evap.tot, evap_soil.tot, Esoil.yr$top, Esoil.yr$bottom, transp.tot, transp.yr$top, transp.yr$bottom, hydred.topTobottom, drain.topTobottom, deepDrain.yr$val, swc.flux), 2, mean)					resMeans[nv+23] <- ifelse(sum(transp.tot)==0, 0, mean(transp.yr$bottom/transp.tot))					resMeans[nv+24] <- ifelse(sum(AET.yr$val)==0, 0, mean(transp.tot/AET.yr$val))					resMeans[nv+25] <- ifelse(sum(AET.yr$val)==0, 0, mean(evap_soil.tot/AET.yr$val))					resMeans[nv+26] <- ifelse(sum(PET.yr$val)==0, 0, mean(AET.yr$val/PET.yr$val))					resMeans[nv+27] <- ifelse(sum(PET.yr$val)==0, 0, mean(transp.tot/PET.yr$val))					resMeans[nv+28] <- ifelse(sum(PET.yr$val)==0, 0, mean(evap_soil.tot/PET.yr$val))					#sd of fluxes					resSDs[nv:(nv+22)] <- apply(fluxtemp, 2, sd)					resSDs[nv+23] <- ifelse(sum(transp.tot)==0, 0, sd(transp.yr$bottom/transp.tot))					resSDs[nv+24] <- ifelse(sum(AET.yr$val)==0, 0, sd(transp.tot/AET.yr$val))					resSDs[nv+25] <- ifelse(sum(AET.yr$val)==0, 0, sd(evap_soil.tot/AET.yr$val))					resSDs[nv+26] <- ifelse(sum(PET.yr$val)==0, 0, sd(AET.yr$val/PET.yr$val))					resSDs[nv+27] <- ifelse(sum(PET.yr$val)==0, 0, sd(transp.tot/PET.yr$val))					resSDs[nv+28] <- ifelse(sum(PET.yr$val)==0, 0, sd(evap_soil.tot/PET.yr$val))					nv <- nv+29					rm(rain_toSoil, transp.tot, evap_soil.tot, drain.topTobottom, hydred.topTobottom, index.usedyPlusOne, swcdyflux, swc.flux)				}			#27.2				if(any(simulation_timescales=="daily") & aon$dailySoilWaterPulseVsStorage){					if(print.debug) print("Aggregation of dailySoilWaterPulseVsStorage")					if(!exists("inf.dy")) inf.dy <- get_Inf_dy(sc)					if(!exists("transp.dy.all")) transp.dy.all <- get_Response_aggL(sc, sw_transp, "dyAll", 10, sum)					if(!exists("Esoil.dy.all")) Esoil.dy.all <- get_Response_aggL(sc, sw_evsoil, "dyAll", 10, sum)					if(!exists("deepDrain.dy")) deepDrain.dy <- get_DeepDrain_dy(sc)					percolation <- 10 * slot(slot(runData[[sc]],sw_percolation), "Day")[simTime$index.usedy, 2 + head(ld, n=-1)]					hydred <- 10 * slot(slot(runData[[sc]],sw_hd), "Day")[simTime$index.usedy, 2 + ld]					# Water balance					outputs_by_layer <- inputs_by_layer <- matrix(0, nrow=length(simTime$index.usedy), ncol=length(ld))					# Inputs: infiltration + received hydraulic redistribution + received percolation					inputs_by_layer[, 1] <- inputs_by_layer[, 1] + inf.dy$inf					inputs_by_layer <- inputs_by_layer + ifelse(hydred > 0, hydred, 0)					inputs_by_layer[, -1] <- inputs_by_layer[, -1] + ifelse(percolation > 0, percolation, 0)					# Outputs: soil evaporation + transpiration + deep drainage + hydraulic redistribution donor + percolation donor					itemp <- 1:(ncol(Esoil.dy.all$val) - 2)					outputs_by_layer[, itemp] <- outputs_by_layer[, itemp] + Esoil.dy.all$val[simTime$index.usedy, -(1:2)]					itemp <- grepl("transp_total", colnames(transp.dy.all$val))					outputs_by_layer[, 1:sum(itemp)] <- outputs_by_layer[, 1:sum(itemp)] + transp.dy.all$val[simTime$index.usedy, itemp]					itemp <- ncol(outputs_by_layer)					outputs_by_layer[, itemp] <- outputs_by_layer[, itemp] + deepDrain.dy$val					outputs_by_layer[, -itemp] <- outputs_by_layer[, -itemp] + ifelse(percolation < 0, -percolation, 0)					outputs_by_layer <- outputs_by_layer + ifelse(hydred < 0, -hydred, 0)					# balance					balance <- inputs_by_layer - outputs_by_layer					extraction <- balance < 0					storage_use <- by(cbind(extraction, outputs_by_layer), INDICES=simTime2$year_ForEachUsedDay_NSadj, FUN=function(x) {						res1 <- apply(x[, ld], MARGIN=2, FUN=rle)						res2 <- apply(x[, max(ld) + ld], MARGIN=2, FUN=function(y) list(out=y))						return(modifyList(res1, res2))})					# median duration among extracting spells for each layer and each year					extraction_duration_days <- sapply(storage_use, FUN=function(x) sapply(x, FUN=function(dat) mean(dat$lengths[as.logical(dat$values)])))					# median annual sum of all extracted water during extracting spells for each layer and each year					extraction_summed_mm <- sapply(storage_use, FUN=function(x) sapply(x, FUN=function(dat) {							dat$values <- as.logical(dat$values)							temp <- dat							if(any(dat$values)) temp$values[dat$values] <- 1:sum(dat$values) # give unique ID to each extraction spell							if(any(!dat$values)){								temp$values[!dat$values] <- 0 # we are not interested in positive spells								has_zero <- TRUE							} else {								has_zero <- FALSE							}							storage_ids <- inverse.rle(temp)							x <- tapply(dat$out, INDEX=storage_ids, sum) # sum up extracted water for each extraction spell							if(has_zero && length(x) > 0) x <- x[-1] # remove first element because this represents the positive spells (id = 0)							return(sum(x))						}))					# aggregate across years for each soil layer					resMeans[nv:(nv+max(ld)-1)] <- round(apply(extraction_duration_days, 1, mean), 1)					resSDs[nv:(nv+max(ld)-1)] <- round(apply(extraction_duration_days, 1, sd), 1)					nv <- nv+SoilLayer_MaxNo					resMeans[nv:(nv+max(ld)-1)] <- round(apply(extraction_summed_mm, 1, mean), 2)					resSDs[nv:(nv+max(ld)-1)] <- round(apply(extraction_summed_mm, 1, sd), 2)					nv <- nv+SoilLayer_MaxNo					rm(percolation, hydred, inputs_by_layer, outputs_by_layer, balance, extraction, storage_use, extraction_duration_days, extraction_summed_mm)				}				#---Aggregation: Daily extreme values			#28				if(any(simulation_timescales=="daily") & aon$dailyTranspirationExtremes) {#mean and SD of DOY and value of minimum/maximum					if(print.debug) print("Aggregation of dailyTranspirationExtremes")					if(!exists("transp.dy")) transp.dy <- get_Response_aggL(sc, sw_transp, "dy", 10, FUN=sum)					extremes <- as.matrix(aggregate(cbind(transp.dy$top + transp.dy$bottom), by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					resMeans[nv:(nv+1)] <- apply(temp <- extremes[, c(2:3), drop=FALSE], MARGIN=2, FUN=mean)					resSDs[nv:(nv+1)] <- apply(temp, MARGIN=2, FUN=sd)					nv <- nv+2					resMeans[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+1)] <- apply(extremes[, 4:5], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+2					rm(extremes)				}			#29				if(any(simulation_timescales=="daily") & aon$dailyTotalEvaporationExtremes) {					if(print.debug) print("Aggregation of dailyTotalEvaporationExtremes")					if(!exists("Esoil.dy")) Esoil.dy <- get_Response_aggL(sc, sw_evsoil, "dy", 10, FUN=sum)					if(!exists("Esurface.dy")) Esurface.dy <- get_Esurface_dy(sc)					extremes <- as.matrix(aggregate(cbind(Esoil.dy$top + Esoil.dy$bottom + Esurface.dy$sum), by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					resMeans[nv:(nv+1)] <- apply(temp <- extremes[, c(2:3), drop=FALSE], MARGIN=2, FUN=mean)					resSDs[nv:(nv+1)] <- apply(temp, MARGIN=2, FUN=sd)					nv <- nv+2					resMeans[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+2					rm(extremes)				}			#30				if(any(simulation_timescales=="daily") & aon$dailyDrainageExtremes) {					if(print.debug) print("Aggregation of dailyDrainageExtremes")					if(!exists("deepDrain.dy")) deepDrain.dy <- get_DeepDrain_dy(sc)					extremes <- as.matrix(aggregate(deepDrain.dy$val, by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					resMeans[nv:(nv+1)] <- apply(temp <- extremes[, c(2:3), drop=FALSE], MARGIN=2, FUN=mean)					resSDs[nv:(nv+1)] <- apply(temp, MARGIN=2, FUN=sd)					nv <- nv+2					resMeans[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+2					rm(extremes)				}			#31				if(any(simulation_timescales=="daily") & aon$dailyInfiltrationExtremes) {					if(print.debug) print("Aggregation of dailyInfiltrationExtremes")					if(!exists("inf.dy")) inf.dy <- get_Inf_dy(sc)					extremes <- as.matrix(aggregate(inf.dy$inf, by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					resMeans[nv:(nv+1)] <- apply(temp <- extremes[, c(2:3), drop=FALSE], MARGIN=2, FUN=mean)					resSDs[nv:(nv+1)] <- apply(temp, MARGIN=2, FUN=sd)					nv <- nv+2					resMeans[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+2					rm(extremes)				}			#32				if(any(simulation_timescales=="daily") & aon$dailyAETExtremes) {					if(print.debug) print("Aggregation of dailyAETExtremes")					if(!exists("AET.dy")) AET.dy <- get_AET_dy(sc)					extremes <- as.matrix(aggregate(AET.dy$val, by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					resMeans[nv:(nv+1)] <- apply(temp <- extremes[, c(2:3), drop=FALSE], MARGIN=2, FUN=mean)					resSDs[nv:(nv+1)] <- apply(temp, MARGIN=2, FUN=sd)					nv <- nv+2					resMeans[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+1)] <- apply(extremes[, 4:5, drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+2					rm(extremes)				}			#33				if(any(simulation_timescales=="daily") & aon$dailySWPextremes){					if(print.debug) print("Aggregation of dailySWPextremes")					if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)					if(length(bottomL) > 0 && !identical(bottomL, 0)) {						extremes <- as.matrix(aggregate(cbind(swpmatric.dy$top, swpmatric.dy$bottom), by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					} else {						extremes <- cbind(temp <- as.matrix(aggregate(swpmatric.dy$top, by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365)))), matrix(NA, nrow=nrow(temp), ncol=ncol(temp)-1))					}					resMeans[nv:(nv+3)] <- apply(extremes[, c(2:3, 6:7), drop=FALSE], MARGIN=2, FUN=mean, na.rm=TRUE)					resSDs[nv:(nv+3)] <- apply(extremes[, c(2:3, 6:7), drop=FALSE], MARGIN=2, FUN=sd, na.rm=TRUE)					nv <- nv+4					resMeans[nv:(nv+3)] <- apply(extremes[, c(4:5, 8:9), drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+3)] <- apply(extremes[, c(4:5, 8:9), drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+4					rm(extremes)				}			#34				if(any(simulation_timescales=="daily") & aon$dailyRechargeExtremes){					if(print.debug) print("Aggregation of dailyRechargeExtremes")					if(!exists("swcbulk.dy")) swcbulk.dy <- get_Response_aggL(sc, sw_swcbulk, "dy", 10, FUN=sum)					recharge.dy <- NULL					recharge.dy$top <- swcbulk.dy$top / (SWPtoVWC(-0.033, texture$sand.top, texture$clay.top) * 10 * sum(layers_width[topL]))					if(length(bottomL) > 0 && !identical(bottomL, 0)) {						recharge.dy$bottom <- swcbulk.dy$bottom / (SWPtoVWC(-0.033, texture$sand.bottom, texture$clay.bottom) * 10 * sum(layers_width[bottomL]))						extremes <- as.matrix(aggregate(cbind(recharge.dy$top, recharge.dy$bottom), by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365))))					} else {						extremes <- cbind(temp <- as.matrix(aggregate(recharge.dy$top, by=list(simTime2$year_ForEachUsedDay), FUN=function(x) c(max(x), min(x), circ.mean(which(x==max(x)), int=365), circ.mean(which(x==min(x)), int=365)))), matrix(NA, nrow=nrow(temp), ncol=ncol(temp)-1))					}					resMeans[nv:(nv+3)] <- apply(extremes[, c(2:3, 6:7), drop=FALSE], MARGIN=2, FUN=function(x) mean(pmin(1, x), na.rm=TRUE))					resSDs[nv:(nv+3)] <- apply(extremes[, c(2:3, 6:7), drop=FALSE], MARGIN=2, FUN=function(x) sd(pmin(1, x), na.rm=TRUE))					nv <- nv+4					resMeans[nv:(nv+3)] <- apply(extremes[, c(4:5, 8:9), drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365))					resSDs[nv:(nv+3)] <- apply(extremes[, c(4:5, 8:9), drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365))					nv <- nv+4					rm(recharge.dy, extremes)				}				#---Aggregation: Ecological dryness			#35				if(any(simulation_timescales=="daily") & aon$dailyWetDegreeDays){	#Wet degree days on daily temp and swp					if(print.debug) print("Aggregation of dailyWetDegreeDays")					if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					degday <- ifelse(temp.dy$mean > DegreeDayBase, temp.dy$mean - DegreeDayBase, 0) #degree days					for(icrit in seq(along=SWPcrit_MPa)){						wet.top <- swpmatric.dy$top >= SWPcrit_MPa[icrit]						if(length(bottomL) > 0 && !identical(bottomL, 0)) {							wet.bottom <- swpmatric.dy$bottom >= SWPcrit_MPa[icrit]						} else {							wet.bottom <- matrix(data=NA, nrow=length(swpmatric.dy$bottom), ncol=1)						}						wetdegday.top <- ifelse(wet.top > 0, degday, 0)						wetdegday.bottom <- ifelse(wet.bottom > 0, degday, 0)						wetdegday.any <- ifelse(wet.top + wet.bottom > 0, degday, 0)						temp <- aggregate(data.frame(wetdegday.top, wetdegday.bottom, wetdegday.any), by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2:4, drop=FALSE]						resMeans[(nv+3*(icrit-1)):(nv+3*(icrit-1)+2)] <- apply(temp, MARGIN=2, FUN=mean)						resSDs[(nv+3*(icrit-1)):(nv+3*(icrit-1)+2)] <- apply(temp, MARGIN=2, FUN=sd)					}					nv <- nv+3*length(SWPcrit_MPa)					rm(degday, wet.top, wet.bottom, wetdegday.top, wetdegday.bottom, wetdegday.any)				}			#36				if(any(simulation_timescales=="monthly") & aon$monthlySWPdryness){#dry periods based on monthly swp data: accountNSHemispheres_agg					if(print.debug) print("Aggregation of monthlySWPdryness")					if(!exists("vwcmatric.mo")) vwcmatric.mo <- get_Response_aggL(sc, sw_vwcmatric, "mo", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.mo")) swpmatric.mo <- get_SWPmatric_aggL(vwcmatric.mo)					adjMonths <- ifelse(simTime2$month_ForEachUsedMonth[1] == simTime2$month_ForEachUsedMonth_NSadj[1], 0, 6)					drymonths.top <- drymonths.bottom <- array(data=0, dim=c(length(SWPcrit_MPa), 12, simTime$no.useyr))					for(icrit in seq(along=SWPcrit_MPa)){						drymonths.top[icrit, , ] <- aggregate(swpmatric.mo$top, by=list(simTime2$month_ForEachUsedMonth_NSadj), FUN=function(x) ifelse(x <= SWPcrit_MPa[icrit], 1, 0))[, -1]						drymonths.bottom[icrit, , ] <- aggregate(swpmatric.mo$bottom, by=list(simTime2$month_ForEachUsedMonth_NSadj), FUN=function(x) ifelse(x <= SWPcrit_MPa[icrit], 1, 0))[, -1]					}					years.top <- apply(drymonths.top, MARGIN=c(1, 3), FUN=sum)					years.bottom <- apply(drymonths.bottom, MARGIN=c(1, 3), FUN=sum)					resMeans[nv:(nv+2*length(SWPcrit_MPa)-1)] <- c(apply(years.top, MARGIN=1, FUN=mean), apply(years.bottom, MARGIN=1, FUN=mean))					resSDs[nv:(nv+2*length(SWPcrit_MPa)-1)] <- c(apply(years.top, MARGIN=1, FUN=sd), apply(years.bottom, MARGIN=1, FUN=sd))					nv <- nv+2*length(SWPcrit_MPa)					start.top <- apply(drymonths.top, MARGIN=c(1, 3), FUN=match, x=1, nomatch=0)					start.top[start.top != 0] <- ifelse((temp <- (start.top[start.top != 0] + adjMonths) %% 12) == 0, 12, temp)					start.bottom <- apply(drymonths.bottom, MARGIN=c(1, 3), FUN=match, x=1, nomatch=0)					start.bottom[start.bottom != 0] <- ifelse((temp <- (start.bottom[start.bottom != 0] + adjMonths) %% 12) == 0, 12, temp)					resMeans[nv:(nv+2*length(SWPcrit_MPa)-1)] <- c(apply(start.top, MARGIN=1, FUN=function(x) circ.mean(x, int=12)), apply(start.bottom, MARGIN=1, FUN=function(x) circ.mean(x, int=12)))					resSDs[nv:(nv+2*length(SWPcrit_MPa)-1)] <- c(apply(start.top, MARGIN=1, FUN=function(x) circ.sd(x, int=12)), apply(start.bottom, MARGIN=1, FUN=function(x) circ.sd(x, int=12)))					nv <- nv+2*length(SWPcrit_MPa)					rm(drymonths.top, drymonths.bottom, years.top, start.top, years.bottom, start.bottom, adjMonths)				}			#37				if(any(simulation_timescales=="daily") & aon$dailySWPdrynessANDwetness){#Dry and wet periods based on daily swp: accountNSHemispheres_agg					if(print.debug) print("Aggregation of dailySWPdrynessANDwetness")					if(!exists("vwcmatric.dy.all")) vwcmatric.dy.all <- get_Response_aggL(sc, sw_vwcmatric, "dyAll", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- get_SWPmatric_aggL(vwcmatric.dy.all) #swp.dy.all is required to get all layers					adjDays <- simTime2$doy_ForEachUsedDay_NSadj[1] - simTime2$doy_ForEachUsedDay[1]					durationDryPeriods.min <- 10 # days					for(icrit in seq(along=SWPcrit_MPa)){						wet_crit <- swpmatric.dy.all$val >= SWPcrit_MPa[icrit]						if(length(topL) > 1) {							wet.top <- apply(wet_crit[simTime$index.usedy,2+topL], 1, sum)						} else {							wet.top <- wet_crit[simTime$index.usedy,2+topL]						}						if(length(bottomL) > 1) {							wet.bottom <- apply(wet_crit[simTime$index.usedy,2+bottomL], 1, sum)						} else if(length(bottomL) > 0 && !identical(bottomL, 0)) {							wet.bottom  <- ifelse(wet_crit[simTime$index.usedy,2+bottomL], 1, 0)						}						AtLeastOneWet.top <- ifelse(wet.top>0,1,0)						AllWet.top <- ifelse(wet.top==length(topL),1,0)						AllDry.top <- ifelse(wet.top==0,1,0)						AtLeastOneDry.top <- ifelse(wet.top<length(topL),1,0)						if(length(bottomL) > 0 && !identical(bottomL, 0)){							AtLeastOneWet.bottom <- ifelse(wet.bottom>0,1,0)							AllWet.bottom <- ifelse(wet.bottom==length(bottomL),1,0)							AllDry.bottom <- ifelse(wet.bottom==0,1,0)							AtLeastOneDry.bottom <- ifelse(wet.bottom<length(bottomL),1,0)						}						#wet periods						res.wet <- matrix(data=0, nrow=length(unique(simTime2$year_ForEachUsedDay_NSadj)), ncol=8)						res.wet[, 1] <- aggregate(AtLeastOneWet.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)[,2] # total number of days per year when at least one top layer is wet						res.wet[, 3] <- aggregate(AtLeastOneWet.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=max.duration )[,2] # maximum number of continous days when at least one top layers is wet						res.wet[, 5] <- aggregate(AllWet.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)[,2] # total number of days per year when all top layer are wet						res.wet[, 7] <- aggregate(AllWet.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=max.duration )[,2] # maximum number of continous days when all top layers are wet						if(length(bottomL) > 0 && !identical(bottomL, 0)){							res.wet[, 2] <- aggregate(AtLeastOneWet.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)[,2]	# total number of days per year when at least one bottom layer is wet							res.wet[, 4] <- aggregate(AtLeastOneWet.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=max.duration )[,2] # maximum number of continous days when at least one bottom layers is wet							res.wet[, 6] <- aggregate(AllWet.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)[,2]  # total number of days per year when all bottom layer are wet							res.wet[, 8] <- aggregate(AllWet.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=max.duration )[,2] # maximum number of continous days when all bottom layers are wet						}						#dry periods						res.dry <- matrix(data=0, nrow=length(unique(simTime2$year_ForEachUsedDay_NSadj)), ncol=8)						res.dry[,3] <- aggregate(AllDry.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)[,2] #total number of days/year when all top layers are dry						res.dry[,4] <- aggregate(AllDry.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=max.duration )[,2] #maximum number of continous days when all top layers are dry						res.dry[,1] <- aggregate(AtLeastOneDry.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=startDoyOfDuration, duration=durationDryPeriods.min)[,2] - adjDays	# start days/year when at least one of top layers are dry for at least ten days						res.dry[,2] <- aggregate(AtLeastOneDry.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=endDoyAfterDuration, duration=durationDryPeriods.min)[,2] - adjDays	# end days/year when at least one of top layers have been dry for at least ten days						res.dry[,3] <- ifelse(res.dry[,2]-res.dry[,1]>0, res.dry[,3], 0) #correct [,c(3,7)] for years when start<end otherwise set 0						if(length(bottomL) > 0 && !identical(bottomL, 0)){							res.dry[,7] <- aggregate(AllDry.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)[,2]#total number of days/year when all bottom layers are dry							res.dry[,8] <- aggregate(AllDry.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=max.duration )[,2] #maximum number of continous days when all bottom layers are dry							res.dry[,5] <- aggregate(AtLeastOneDry.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=startDoyOfDuration, duration=durationDryPeriods.min)[,2] - adjDays	# start days/year when at least one of bottom layers are dry for at least ten days							res.dry[,6] <- aggregate(AtLeastOneDry.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=endDoyAfterDuration, duration=durationDryPeriods.min)[,2] - adjDays # end days/year when at least one of bottom layers have been dry for at least ten days							res.dry[,7] <- ifelse(res.dry[,6]-res.dry[,5]>0, res.dry[,7], 0) #correct [,c(3,7)] for years when start<end otherwise set 0						}						#aggregate results						resMeans[(nv+16*(icrit-1)):(nv+16*icrit-1)] <- c(apply(temp <- data.frame(res.wet, res.dry[, -c(1:2, 5:6)]), MARGIN=2, FUN=mean, na.rm=TRUE),								apply(res.dry[, c(1:2, 5:6), drop=FALSE], MARGIN=2, FUN=function(x) circ.mean(x, int=365, na.rm=TRUE)))						resSDs[(nv+16*(icrit-1)):(nv+16*icrit-1)] <- c(apply(temp, MARGIN=2, FUN=sd, na.rm=TRUE),								apply(res.dry[, c(1:2, 5:6), drop=FALSE], MARGIN=2, FUN=function(x) circ.sd(x, int=365, na.rm=TRUE)))					}					nv <- nv+16*length(SWPcrit_MPa)					rm(res.dry, wet.top, wet_crit, AtLeastOneWet.top, AllWet.top, AllDry.top)					if(length(bottomL) > 0 && !identical(bottomL, 0)) rm(wet.bottom, AtLeastOneWet.bottom, AllWet.bottom, AllDry.bottom)				}			#38				if(any(simulation_timescales=="daily") & aon$dailySuitablePeriodsDuration){					if(print.debug) print("Aggregation of dailySuitablePeriodsDuration")					if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					quantiles <- c(0.05, 0.5, 0.95)					snowfree <- SWE.dy$val == 0					niceTemp <- temp.dy$mean >= DegreeDayBase					for(icrit in seq(along=SWPcrit_MPa)){						wet.top <- swpmatric.dy$top >= SWPcrit_MPa[icrit]						if(length(bottomL) > 0 && !identical(bottomL, 0)){							wet.bottom <- swpmatric.dy$bottom >= SWPcrit_MPa[icrit]						} else {							wet.bottom <- rep(FALSE, length(wet.top))						}						durations.top <- sapply(simTime$useyrs, FUN=function(y) {if(length(temp <- (temp <- rle((snowfree & niceTemp & wet.top)[simTime2$year_ForEachUsedDay == y]))$lengths[temp$values]) > 0) {return(max(temp))} else {return(0)}} )						durations.bottom <- sapply(simTime$useyrs, FUN=function(y) {if(length(temp <- (temp <- rle((snowfree & niceTemp & wet.bottom)[simTime2$year_ForEachUsedDay == y]))$lengths[temp$values]) > 0) {return(max(temp))} else {return(0)}} )						resMeans[nv:(nv+2*length(quantiles)-1)] <- c(quantile(durations.top, probs=quantiles, type=8), quantile(durations.bottom, probs=quantiles, type=8))						nv <- nv+2*length(quantiles)					}					rm(wet.top, wet.bottom, durations.top, snowfree, niceTemp)				}			#39				if(any(simulation_timescales=="daily") & aon$dailySuitablePeriodsAvailableWater){					if(print.debug) print("Aggregation of dailySuitablePeriodsAvailableWater")					if(!exists("swcbulk.dy")) swcbulk.dy <- get_Response_aggL(sc, sw_swcbulk, "dy", 10, FUN=sum)					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					suitable <- (SWE.dy$val == 0) & (temp.dy$mean >= DegreeDayBase)					cut0 <- function(x) {x[x < 0] <- 0; return(x)}					for(icrit in seq(along=SWPcrit_MPa)){						SWCcritT <- SWPtoVWC(SWPcrit_MPa[icrit], texture$sand.top, texture$clay.top) * 10 * sum(layers_width[topL])						swa.top <- ifelse(suitable, cut0(swcbulk.dy$top - SWCcritT), 0)						if(length(bottomL) > 0 && !identical(bottomL, 0)){							SWCcritB <- SWPtoVWC(SWPcrit_MPa[icrit], texture$sand.bottom, texture$clay.bottom) * 10 * sum(layers_width[bottomL])							swa.bottom <- ifelse(suitable, cut0(swcbulk.dy$bottom - SWCcritB), 0)						} else {							swa.bottom <- rep(0, length(swa.top))						}						temp <- aggregate(cbind(swa.top, swa.bottom), by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=sum)						resMeans[nv:(nv+1)] <- apply(temp[, -1, drop=FALSE], 2, mean)						resSDs[nv:(nv+1)] <- apply(temp[, -1, drop=FALSE], 2, sd)						nv <- nv+2					}					rm(swa.top, swa.bottom, suitable)				}			#40				if(any(simulation_timescales=="daily") & aon$dailySuitablePeriodsDrySpells){					if(print.debug) print("Aggregation of dailySuitablePeriodsDrySpells")					if(!exists("vwcmatric.dy.all")) vwcmatric.dy.all <- get_Response_aggL(sc, sw_vwcmatric, "dyAll", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- get_SWPmatric_aggL(vwcmatric.dy.all) #swp.dy.all is required to get all layers					if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					suitable <- (SWE.dy$val == 0) & (temp.dy$mean >= DegreeDayBase)					adjDays <- simTime2$doy_ForEachUsedDay_NSadj[1] - simTime2$doy_ForEachUsedDay[1]					durationDryPeriods.min <- 10 # days					for(icrit in seq(along=SWPcrit_MPa)){						dry_crit <- swpmatric.dy.all$val < SWPcrit_MPa[icrit]						if(length(topL) > 1) {							dry.top <- apply(dry_crit[simTime$index.usedy,2+topL], 1, sum)						} else {							dry.top <- dry_crit[simTime$index.usedy,2+topL]						}						dry.top <- (suitable & dry.top >= length(topL))						if(length(bottomL) > 1) {							dry.bottom <- apply(dry_crit[simTime$index.usedy,2+bottomL], 1, sum)						} else if(length(bottomL) > 0 && !identical(bottomL, 0)) {							dry.bottom <- ifelse(dry_crit[simTime$index.usedy,2+bottomL], 1, 0)						}						if(length(bottomL) > 0 && !identical(bottomL, 0)){							dry.bottom <- (suitable & dry.bottom >= length(bottomL))						} else {							dry.bottom <- rep(FALSE, length(dry.top))						}						temp <- aggregate(cbind(dry.top, dry.bottom), by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=function(x) c(if(any((temp <- rle(x))$values)) c(mean(temp$lengths[temp$values]), max(temp$lengths[temp$values])) else c(0, 0), sum(x), startDoyOfDuration(x, duration=durationDryPeriods.min) - adjDays))						resMeans[nv:(nv+7)] <- c(apply(temp$dry.top[, 1:3, drop=FALSE], 2, mean), circ.mean(x=temp$dry.top[, 4], int=365), apply(temp$dry.bottom[, 1:3, drop=FALSE], 2, mean), circ.mean(x=temp$dry.bottom[, 4], int=365))						resSDs[nv:(nv+7)] <- c(apply(temp$dry.top[, 1:3, drop=FALSE], 2, sd), circ.sd(x=temp$dry.top[, 4], int=365), apply(temp$dry.bottom[, 1:3, drop=FALSE], 2, sd), circ.sd(x=temp$dry.bottom[, 4], int=365))						nv <- nv+8					}					rm(dry.top, dry.bottom, suitable, dry_crit, adjDays, durationDryPeriods.min)				}			#41				if(any(simulation_timescales=="daily") & aon$dailySWPdrynessDurationDistribution){#cummulative frequency distribution of durations of dry soils in each of the four seasons and for each of the SWP.crit					if(print.debug) print("Aggregation of dailySWPdrynessDurationDistribution")					if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)					deciles <- (0:10)*10/100					quantiles <- (0:4)/4					mo_seasons <- matrix(data=c(12,1:11), ncol=3, nrow=4, byrow=TRUE)					season.flag <- c("DJF", "MAM", "JJA", "SON")					seasonal.years <- c(simTime2$year_ForEachUsedDay[-(1:31)], rep(-9999, times=31))	#shift beginning of year to Dec 1					for(icrit in seq(along=SWPcrit_MPa)){						wet.top <- swpmatric.dy$top >= SWPcrit_MPa[icrit]						if(length(bottomL) > 0 && !identical(bottomL, 0)) wet.bottom <- swpmatric.dy$bottom >= SWPcrit_MPa[icrit]						for(season in 1:nrow(mo_seasons)){							durations.top <- sapply(simTime$useyrs, FUN=function(y) {if(length(temp <- (temp <- rle(wet.top[seasonal.years == y & (simTime2$month_ForEachUsedDay %in% mo_seasons[season,])] == 0))$lengths[temp$values]) > 0) {return(max(temp))} else {return(0)}} )							if(length(bottomL) > 0 && !identical(bottomL, 0)) durations.bottom <- sapply(simTime$useyrs, FUN=function(y) {if(length(temp <- (temp <- rle(wet.bottom[seasonal.years == y & (simTime2$month_ForEachUsedDay %in% mo_seasons[season,])] == 0))$lengths[temp$values]) > 0) {return(max(temp))} else {return(0)}} )							resMeans[nv:(nv+length(quantiles)-1)] <- quantile(durations.top, probs=quantiles, type=7)							resMeans[(nv+length(quantiles)):(nv+2*length(quantiles)-1)] <- if(length(bottomL) > 0 && !identical(bottomL, 0)) quantile(durations.bottom, probs=quantiles, type=7) else 0							nv <- nv+2*length(quantiles)						}					}					rm(wet.top, durations.top)					if(length(bottomL) > 0 && !identical(bottomL, 0)) rm(wet.bottom)				}			#42				if(any(simulation_timescales=="daily") && aon$dailySWPdrynessEventSizeDistribution){					if(print.debug) print("Aggregation of dailySWPdrynessEventSizeDistribution")					if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)					binSize <- c(1, 8, 15, 29, 57, 183, 367) #closed interval lengths in [days] within a year; NOTE: n_variables is set for binsN == 6					binsN <- length(binSize) - 1					EventDistribution <- function(data) {#data is the values for one year adj for SWPcrit_MPa; TRUE==dry						bins <- rep(0, times=binsN)						if(length(temp <- (temp <- rle(data))$lengths[temp$values]) > 0) {							for(z in 1:length(temp)) {								bins[findInterval(temp[z],binSize)] <- bins[findInterval(temp[z],binSize)] + 1							}						}						return(bins)					}					for(icrit in seq(along=SWPcrit_MPa)){						dry.top <- swpmatric.dy$top[simTime$index.usedy] < SWPcrit_MPa[icrit]						if(length(bottomL) > 0 && !identical(bottomL, 0)) {							dry.bottom <- swpmatric.dy$bottom[simTime$index.usedy] < SWPcrit_MPa[icrit]						}						#apply over each year, rle just on selected year store runs in vec, if that is greater than 0 then add to that years bins else return 0s for that year. Will result in a matrix of 4 by Years						binsYears.top <- aggregate(dry.top, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=EventDistribution)$x						eventsPerYear <- apply(binsYears.top, MARGIN=1, FUN=sum)						freqBins <- sweep(binsYears.top, MARGIN=1, STATS=eventsPerYear, FUN="/")						events.top <- c(mean(eventsPerYear, na.rm=TRUE), sd(eventsPerYear, na.rm=TRUE))						bin_top_mean <- apply(freqBins, MARGIN = 2, mean, na.rm=TRUE) #mean of each bin size across a year - vector of binsN						bin_top_sd <- apply(freqBins, MARGIN = 2, sd, na.rm=TRUE) # sd of each bin size across a year - vector of binsN						resMeans[nv] <- events.top[1]						resSDs[nv] <- events.top[2]						resMeans[(nv+1):(nv+binsN)] <- bin_top_mean						resSDs[(nv+1):(nv+binsN)] <- bin_top_sd						if(length(bottomL) > 0 && !identical(bottomL, 0)) {							binsYears.bottom <- aggregate(dry.bottom, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=EventDistribution)$x							eventsPerYear <- apply(binsYears.bottom, MARGIN=1, FUN=sum)							freqBins <- sweep(binsYears.bottom, MARGIN=1, STATS=eventsPerYear, FUN="/")							events.bottom <- c(mean(eventsPerYear, na.rm=TRUE), sd(eventsPerYear, na.rm=TRUE))							bin_bottom_mean <- apply(freqBins, MARGIN = 2, mean, na.rm=TRUE)							bin_bottom_sd <- apply(freqBins, MARGIN = 2, sd, na.rm=TRUE)							resMeans[nv+binsN+1] <- events.bottom[1]							resSDs[nv+binsN+1] <- events.bottom[2]							resMeans[(nv+binsN+2):(nv+2*binsN+1)] <- bin_bottom_mean							resSDs[(nv+binsN+2):(nv+2*binsN+1)] <- bin_bottom_sd						}						nv <- nv+2+2*binsN					}					rm(dry.top, binsN, binSize, events.top, eventsPerYear, freqBins)					if(length(bottomL) > 0 && !identical(bottomL, 0)) rm(dry.bottom, events.bottom)				}			#43				if(any(simulation_timescales=="daily") && aon$dailySWPdrynessIntensity) {					if(print.debug) print("Aggregation of dailySWPdrynessIntensity")					if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)					cut0 <- function(x) {x[x < 0] <- 0; return(x)}					SWCtop <- vwcmatric.dy$top * sum(layers_width[topL])*10					if(length(bottomL) > 0 && !identical(bottomL, 0)) SWCbottom <- vwcmatric.dy$bottom * sum(layers_width[bottomL])*10					for(icrit in seq(along=SWPcrit_MPa)){						#amount of SWC required so that layer wouldn't be dry						SWCcritT <- SWPtoVWC(SWPcrit_MPa[icrit], texture$sand.top, texture$clay.top) * sum(layers_width[topL])*10						missingSWCtop <- cut0(SWCcritT - SWCtop)						IntensitySum_top <- c(mean(temp <- sapply(simTime$useyrs, FUN=function(y) sum(missingSWCtop[simTime2$year_ForEachUsedDay == y])), na.rm=TRUE), sd(temp, na.rm=TRUE))						IntensityMean_top <- c(mean(temp <- sapply(simTime$useyrs, FUN=function(y) mean((temp <- missingSWCtop[simTime2$year_ForEachUsedDay == y])[temp > 0], na.rm=TRUE)), na.rm=TRUE), sd(temp, na.rm=TRUE))						IntensityDurationAndNumber_top <- c(apply(temp <- sapply(simTime$useyrs, FUN=function(y) c(mean(temp <- (temp <- rle(missingSWCtop[simTime2$year_ForEachUsedDay == y] > 0))$lengths[temp$values]), length(temp))), 1, mean), apply(temp, 1, sd))[c(1, 3, 2, 4)]						if(length(bottomL) > 0 && !identical(bottomL, 0)) {							SWCcritB <- SWPtoVWC(SWPcrit_MPa[icrit], texture$sand.bottom, texture$clay.bottom) * sum(layers_width[bottomL])*10							missingSWCbottom <- cut0(SWCcritB - SWCbottom)							IntensitySum_bottom <- c(mean(temp <- sapply(simTime$useyrs, FUN=function(y) sum(missingSWCbottom[simTime2$year_ForEachUsedDay == y])), na.rm=TRUE), sd(temp, na.rm=TRUE))							IntensityMean_bottom <- c(mean(temp <- sapply(simTime$useyrs, FUN=function(y) mean((temp <- missingSWCbottom[simTime2$year_ForEachUsedDay == y])[temp > 0], na.rm=TRUE)), na.rm=TRUE), sd(temp, na.rm=TRUE))							IntensityDurationAndNumber_bottom <- c(apply(temp <- sapply(simTime$useyrs, FUN=function(y) c(mean(temp <- (temp <- rle(missingSWCbottom[simTime2$year_ForEachUsedDay == y] > 0))$lengths[temp$values]), length(temp))), 1, mean), apply(temp, 1, sd))[c(1, 3, 2, 4)]						}						resMeans[nv:(nv+3)] <- c(IntensitySum_top[1], IntensityMean_top[1], IntensityDurationAndNumber_top[c(1, 3)])						resSDs[nv:(nv+3)] <- c(IntensitySum_top[2], IntensityMean_top[2], IntensityDurationAndNumber_top[c(2, 4)])						resMeans[(nv+4):(nv+7)] <- if(length(bottomL) > 0 && !identical(bottomL, 0)) c(IntensitySum_bottom[1], IntensityMean_bottom[1], IntensityDurationAndNumber_bottom[c(1, 3)]) else rep(0, 4)						resSDs[(nv+4):(nv+7)] <- if(length(bottomL) > 0 && !identical(bottomL, 0)) c(IntensitySum_bottom[2], IntensityMean_bottom[2], IntensityDurationAndNumber_bottom[c(2, 4)]) else rep(0, 4)						nv <- nv+8					}					rm(	SWCcritT, missingSWCtop, IntensitySum_top, IntensityMean_top, IntensityDurationAndNumber_top)					if(length(bottomL) > 0 && !identical(bottomL, 0)) rm(SWCcritB, missingSWCbottom, IntensitySum_bottom, IntensityMean_bottom, IntensityDurationAndNumber_bottom)				}				#---Aggregation: Mean monthly values			#44				if(any(simulation_timescales=="monthly") & aon$monthlyTemp){					if(print.debug) print("Aggregation of monthlyTemp")					if(!exists("temp.mo")) temp.mo <- get_Temp_mo(sc)					resMeans[nv+st_mo-1] <- aggregate(temp.mo$mean, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate(temp.mo$mean, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#45				if(any(simulation_timescales=="monthly") & aon$monthlyPPT){					if(print.debug) print("Aggregation of monthlyPPT")					if(!exists("prcp.mo")) prcp.mo <- get_PPT_mo(sc)					resMeans[nv+st_mo-1] <- aggregate(prcp.mo$ppt, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate(prcp.mo$ppt, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#46				if(any(simulation_timescales=="monthly") & aon$monthlySnowpack){					if(print.debug) print("Aggregation of monthlySnowpack")					if(!exists("SWE.mo")) SWE.mo <- get_SWE_mo(sc)					resMeans[nv+st_mo-1] <- aggregate(SWE.mo$val, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate(SWE.mo$val, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#47				if(any(simulation_timescales == "monthly") & aon$monthlySoilTemp) {					if(print.debug) print("Aggregation of monthlySoilTemp")					if(!exists("soiltemp.mo")) soiltemp.mo <- get_Response_aggL(sc, sw_soiltemp, "mo", scaler=1, FUN=weighted.mean, weights=layers_width)					resMeans[nv+st_mo-1] <- soiltemp.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- soiltemp.mo$aggMean.bottom					nv <- nv+24				}			#48				if(any(simulation_timescales=="monthly") & aon$monthlyRunoff){					if(print.debug) print("Aggregation of monthlyRunoff")					if(!exists("runoff.mo")) runoff.mo <- get_Runoff_mo(sc)					resMeans[nv+st_mo-1] <- aggregate(runoff.mo$val, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate(runoff.mo$val, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#49				if(any(simulation_timescales=="monthly") & aon$monthlyHydraulicRedistribution){					if(print.debug) print("Aggregation of monthlyHydraulicRedistribution")					if(!exists("hydred.mo")) hydred.mo <- get_Response_aggL(sc, sw_hd, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- hydred.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- hydred.mo$aggMean.bottom					nv <- nv+24				}			#50				if(any(simulation_timescales=="monthly") & aon$monthlyInfiltration){					if(print.debug) print("Aggregation of monthlyInfiltration")					if(!exists("inf.mo")) inf.mo <- get_Inf_mo(sc)					resMeans[nv+st_mo-1] <- aggregate( inf.mo$inf , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate( inf.mo$inf , by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#51				if(any(simulation_timescales=="monthly") & aon$monthlyDeepDrainage){					if(print.debug) print("Aggregation of monthlyDeepDrainage")					if(!exists("deepDrain.mo")) deepDrain.mo <- get_DeepDrain_mo(sc)					resMeans[nv+st_mo-1] <- aggregate( deepDrain.mo$val , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate( deepDrain.mo$val , by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#52				if(any(simulation_timescales=="monthly") & aon$monthlySWPmatric){					if(print.debug) print("Aggregation of monthlySWPmatric")					if(!exists("vwcmatric.mo")) vwcmatric.mo <- get_Response_aggL(sc, sw_vwcmatric, "mo", 1, FUN=weighted.mean, weights=layers_width)					if(!exists("swpmatric.mo")) swpmatric.mo <- get_SWPmatric_aggL(vwcmatric.mo)					resMeans[nv+st_mo-1] <- swpmatric.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- swpmatric.mo$aggMean.bottom					nv <- nv+24				}			#53 a.)				if(any(simulation_timescales=="monthly") & aon$monthlyVWCbulk){					if(print.debug) print("Aggregation of monthlyVWC")					if(!exists("vwcbulk.mo")) vwcbulk.mo <- get_Response_aggL(sc, sw_vwcbulk, "mo", 1, FUN=weighted.mean, weights=layers_width)					resMeans[nv+st_mo-1] <- vwcbulk.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- vwcbulk.mo$aggMean.bottom					nv <- nv+24				}			#53 b.)				if(any(simulation_timescales=="monthly") & aon$monthlyVWCmatric){					if(print.debug) print("Aggregation of monthlyVWCmatric")					if(!exists("vwcmatric.mo")) vwcmatric.mo <- get_Response_aggL(sc, sw_vwcmatric, "mo", 1, FUN=weighted.mean, weights=layers_width)					resMeans[nv+st_mo-1] <- vwcmatric.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- vwcmatric.mo$aggMean.bottom					nv <- nv+24				}			#54				if(any(simulation_timescales=="monthly") & aon$monthlySWCbulk){					if(print.debug) print("Aggregation of monthlySWCbulk")					if(!exists("swcbulk.mo")) swcbulk.mo <- get_Response_aggL(sc, sw_swcbulk, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- swcbulk.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- swcbulk.mo$aggMean.bottom					nv <- nv+24				}			#55 a.)				if(any(simulation_timescales=="monthly") & aon$monthlySWAbulk){					if(print.debug) print("Aggregation of monthlySWA")					if(!exists("swabulk.mo")) swabulk.mo <- get_Response_aggL(sc, sw_swabulk, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- swabulk.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- swabulk.mo$aggMean.bottom					nv <- nv+24				}			#55 b.)				if(any(simulation_timescales=="monthly") & aon$monthlySWAmatric){					if(print.debug) print("Aggregation of monthlySWA")					if(!exists("swamatric.mo")) swamatric.mo <- get_Response_aggL(sc, sw_swamatric, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- swamatric.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- swamatric.mo$aggMean.bottom					nv <- nv+24				}			#56				if(any(simulation_timescales=="monthly") & aon$monthlyTranspiration){					if(print.debug) print("Aggregation of monthlyTranspiration")					if(!exists("transp.mo")) transp.mo <- get_Response_aggL(sc, sw_transp, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- transp.mo$aggMean.top					resMeans[nv+st_mo-1+12] <- transp.mo$aggMean.bottom					nv <- nv+24				}			#57				if(any(simulation_timescales=="monthly") & aon$monthlySoilEvaporation){					if(print.debug) print("Aggregation of monthlySoilEvaporation")					if(!exists("Esoil.mo")) Esoil.mo <- get_Response_aggL(sc, sw_evsoil, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- aggregate(temp <- Esoil.mo$top + Esoil.mo$bottom, by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate(temp, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#58				if(any(simulation_timescales=="monthly") & aon$monthlyAET){					if(print.debug) print("Aggregation of monthlyAET")					if(!exists("AET.mo")) AET.mo <- get_AET_mo(sc)					resMeans[nv+st_mo-1] <- aggregate( AET.mo$val , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate( AET.mo$val , by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#59				if(any(simulation_timescales=="monthly") & aon$monthlyPET){					if(print.debug) print("Aggregation of monthlyPET")					if(!exists("PET.mo")) PET.mo <- get_PET_mo(sc)					resMeans[nv+st_mo-1] <- aggregate( PET.mo$val , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate( PET.mo$val , by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+12				}			#60				if(any(simulation_timescales=="monthly") & aon$monthlyAETratios){					if(print.debug) print("Aggregation of monthlyAETratios")					if(!exists("AET.mo")) AET.mo <- get_AET_mo(sc)					if(!exists("Esoil.mo")) Esoil.mo <- get_Response_aggL(sc, sw_evsoil, "mo", 10, FUN=sum)					if(!exists("transp.mo")) transp.mo <- get_Response_aggL(sc, sw_transp, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- aggregate( temp <- ifelse( AET.mo$val == 0, 0, (transp.mo$top + transp.mo$bottom) / AET.mo$val) , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate( temp, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					resMeans[nv+st_mo-1+12] <- aggregate( temp <- ifelse( AET.mo$val == 0, 0, (Esoil.mo$top + Esoil.mo$bottom) / AET.mo$val) , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1+12] <- aggregate( temp, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+24				}			#61				if(any(simulation_timescales=="monthly") & aon$monthlyPETratios){					if(print.debug) print("Aggregation of monthlyPETratios")					if(!exists("PET.mo")) PET.mo <- get_PET_mo(sc)					if(!exists("Esoil.mo")) Esoil.mo <- get_Response_aggL(sc, sw_evsoil, "mo", 10, FUN=sum)					if(!exists("transp.mo")) transp.mo <- get_Response_aggL(sc, sw_transp, "mo", 10, FUN=sum)					resMeans[nv+st_mo-1] <- aggregate( temp <- ifelse( PET.mo$val == 0, 0, (transp.mo$top + transp.mo$bottom) / PET.mo$val) , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1] <- aggregate( temp, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					resMeans[nv+st_mo-1+12] <- aggregate( temp <- ifelse( PET.mo$val == 0, 0, (Esoil.mo$top + Esoil.mo$bottom) / PET.mo$val) , by=list(simTime2$month_ForEachUsedMonth), FUN=mean)[,2]					resSDs[nv+st_mo-1+12] <- aggregate( temp, by=list(simTime2$month_ForEachUsedMonth), FUN=sd)[,2]					nv <- nv+24				}				#---Aggregation: Potential regeneration				#regeneration: accountNSHemispheres_agg			#62				if(any(simulation_timescales=="daily")  & aon$dailyRegeneration_bySWPSnow) {					if(print.debug) print("Aggregation of dailyRegeneration_bySWPSnow")					if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- list(val=-1/10*slot(slot(runData[[sc]],sw_swp),"Day"))	#no vwcdy available!					swp.surface <- swpmatric.dy.all$val[simTime$index.usedy, 3]					if(!exists("SWE.dy")) SWE.dy <- get_SWE_dy(sc)					regenerationThisYear_YN <- function(x){						# calculate season doys						snowcover <- ifelse(x[,2]>0, 1, 0)						r <- rle(snowcover)						rseries <- ifelse(r$values==0, 1:length(r$values), 0)						then <- which(rseries==rseries[rseries>0][which.max(r$lengths[rseries>0])])						if(typeof(season.start) == "character"){ #calculate last day of the longest snowpack							if(then==1){								season.start <- 1							} else {								season.start <- cumsum(r$lengths)[then-1]							}						}						if(typeof(season.end) == "character"){ #calculate first day of the longest snowpack							season.end <- min(c(cumsum(r$lengths)[then]+1, length(snowcover)))						}						if(length(season.start:season.end) > 0){							swp.season <- x[season.start:season.end,1]							gs <- rle(ifelse(swp.season>=germination.swp.surface, 1, 0))							es <- rle(ifelse(swp.season>=establishment.swp.surface, 1, 0))							reg <- 0							# get vector of establishment starts and ends							establishment.start.dos <- establishment.end.dos <- NULL							for(esi in 1:length(es$lengths)){								if(es$lengths[esi] >= establishment.duration & es$values[esi] > 0){									establishment.start.dos <- c(establishment.start.dos, ifelse(esi == 1, 1, cumsum(es$lengths)[esi-1]+1))									establishment.end.dos <- c(establishment.end.dos, cumsum(es$lengths)[esi])								}							}							# check if any germination period matches up with an establishment period							if(length(establishment.end.dos) > 0){								for(gsi in 1:length(gs$lengths)){									if(gs$lengths[gsi] >= germination.duration & gs$values[gsi] > 0){										germination.start.dos <- ifelse(gsi == 1, 1, cumsum(gs$lengths)[gsi-1]+1)										germination.end.dos <- cumsum(gs$lengths)[gsi]										if( any( ((germination.start.dos + germination.duration >= establishment.start.dos) &															(germination.start.dos + germination.duration + establishment.duration <= establishment.end.dos)) |														((germination.end.dos + establishment.delay >= establishment.start.dos) &															(germination.end.dos + establishment.delay + establishment.duration <= establishment.end.dos)) ) ){											reg <- reg + 1										}									}								}							}						} else {							reg <- 0						}						return (ifelse(reg>0, 1, 0))					}					resMeans[nv] <- mean(temp <- c(by(data=data.frame(swp.surface, SWE.dy$val), INDICES=simTime2$year_ForEachUsedDay_NSadj, FUN=regenerationThisYear_YN )))					resSDs[nv] <- sd(temp)					nv <- nv+1					rm(swp.surface)				}				#Artemisia tridentata regeneration according to factor model (2012-02-15, drs), call for every regeneration species				#accountNSHemispheres_agg: param$Doy_SeedDispersalStart0 must be set correctly\			#63				if(any(simulation_timescales=="daily")  & aon$dailyRegeneration_GISSM & no.species_regeneration > 0){					if(print.debug) print("Aggregation of dailyRegeneration_GISSM")					#---Access daily data, which do not depend on specific species parameters, i.e., start of season					if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- list(val=-1/10*slot(slot(runData[[sc]],sw_swp),"Day"))	#no vwcdy available!					temp.snow <- slot(slot(runData[[sc]],sw_snow),"Day")					temp.temp <- slot(slot(runData[[sc]],sw_temp),"Day")					TmeanJan <- mean(temp.temp[simTime$index.usedy, 5][simTime2$month_ForEachUsedDay_NSadj==1], na.rm=TRUE)	#mean January (N-hemisphere)/July (S-hemisphere) air temperature based on normal 'doy'					temp.soiltemp <- slot(slot(runData[[sc]],sw_soiltemp),"Day")					if(inherits(temp.soiltemp, "try-error") || any(is.na(temp.soiltemp[, -(1:2)])) || all(temp.soiltemp[, -(1:2)] == 0)){						use.soiltemp <- FALSE	#flag whether soil temperature output is available or not (and then air temperature is used instead of top soil temperature)					} else {						use.soiltemp <- TRUE	#currently we have only mean daily soil temperatures and not min/max which we need fo the model					}					#---Functional relationships					#Function to convert soil depth to soil layer					SoilLayer_at_SoilDepth <- function(depth_cm){						return( pmax(1, pmin(length(layers_depth), 1+findInterval(depth_cm-0.01, layers_depth))) )					}					#Function to calculate for each day of the year, duration in days of upcoming favorable conditions accounting for consequences.unfavorable=0 (if conditions become unfavorable, then restart the count), =1 (resume)					calculate_DurationFavorableConditions <- function(RYyear, consequences.unfavorable){						conditions <- Germination_DuringFavorableConditions[index.year <- RYyear_ForEachUsedDay==RYyear]						doys <- 1:sum(index.year)						doys[!conditions] <- NA	#calculate only for favorable days						out <- rep(NA, times=sum(index.year))						if(consequences.unfavorable == 0){#if conditions become unfavorable, then restart the count afterwards							temp.rle <- rle(conditions)							if(sum(!temp.rle$values) > 0){								temp.unfavorable_startdoy <- c((1 + c(0, cumsum(temp.rle$lengths)))[!temp.rle$values], 1 + sum(index.year)) #add starts for odd- and even-lengthed rle								if(temp.rle$values[1]){#first rle period is favorable									temp.rle$values <- rep(temp.unfavorable_startdoy, each=2)								} else {#first rle period is unfavorable									temp.rle$values <- rep(temp.unfavorable_startdoy[-1], each=2)								}								temp.rle$values <- temp.rle$values[1:length(temp.rle$lengths)]							} else {#every day is favorable								temp.rle$values <- length(conditions)+1							}							out <- inverse.rle(temp.rle) - doys	#difference to next following start of a period of unfavorable conditions						} else if(consequences.unfavorable == 1){#if conditions become unfavorable, then resume the count afterwards							if((temp <- sum(conditions)) > 0){								count <- temp:1							} else {#every day is unfavorable								count <- vector("numeric", length=0)							}							out <- napredict(na.action(na.exclude(doys)), count)	#sum of following favorable conditions in this year						}						return(out)					}					#Function to estimate time to germinate for each day of a given year and conditions (temperature, top soil SWP)					calculate_TimeToGerminate_modifiedHardegree2006NLR <- function(RYyear){						#values for current year						conditions <- Germination_DuringFavorableConditions[index.year <- RYyear_ForEachUsedDay==RYyear]						Tgerm.year <- soilTmeanSnow[index.year]						SWPgerm.year <- swp.TopMean[index.year]						durations <- LengthDays_FavorableConditions[index.year]	#consequences of unfavorable conditions coded in here						doys.favorable <- (doys.padded <- 1:sum(index.year))[conditions]						doys.padded[!conditions] <- NA						#function determining time to germinate for a given day						nrec.max <- 10						rec.delta <- 1						a <- max(sqrt(.Machine$double.eps), param$Hardegree_a)						b <- param$Hardegree_b						d <- max(sqrt(.Machine$double.eps), ifelse((temp <- param$Hardegree_d) == 1, ifelse(runif(1) > 0.5, 1 + .Machine$double.eps, 1 - .Machine$double.neg.eps), temp))						temp.c <- ifelse(param$Hardegree_c != 0, param$Hardegree_c, sign(runif(1)-0.5) * sqrt(.Machine$double.eps))						get_modifiedHardegree2006NLR <- function(RYdoy, Estimate_TimeToGerminate){							for(nrec in 1:nrec.max){								Estimate_TimeToGerminate <- Estimate_TimeToGerminate.oldEstimate <- max(0, round(Estimate_TimeToGerminate, 0))								Tgerm <- mean(Tgerm.year[RYdoy:(RYdoy + Estimate_TimeToGerminate - 1)], na.rm=TRUE)								SWPgerm <- mean(SWPgerm.year[RYdoy:(RYdoy + Estimate_TimeToGerminate - 1)], na.rm=TRUE)								temp.c.lim <- -(Tgerm-b)*(d^2-1)/d								if(temp.c > 0){									c <- ifelse(temp.c > temp.c.lim, temp.c, temp.c.lim + sqrt(.Machine$double.eps))								} else if(temp.c < 0){									c <- ifelse(temp.c < temp.c.lim, temp.c, temp.c.lim - sqrt(.Machine$double.eps))								}								#NLR model (eq.5) in Hardegree SP (2006) Predicting Germination Response to Temperature. I. Cardinal-temperature Models and Subpopulation-specific Regression. Annals of Botany, 97, 1115-1125.								temp <- a * exp(-log(2)/log(d)^2 * log(1 + (Tgerm - b)*(d^2 - 1)/(c * d))^2)								#drs addition to time to germinate dependent on mean January temperature and soil water potential								temp <- 1/temp + param$TimeToGerminate_k1_meanJanTemp * TmeanJan + param$TimeToGerminate_k2_meanJanTempXIncubationTemp * TmeanJan * Tgerm + param$TimeToGerminate_k3_IncubationSWP * SWPgerm								Estimate_TimeToGerminate <- max(1, round(temp, 0) )								#break if convergence or not enough time in this year								if(abs(Estimate_TimeToGerminate - Estimate_TimeToGerminate.oldEstimate) <= rec.delta | RYdoy + Estimate_TimeToGerminate - 1 > 365) break							}							if(nrec >= nrec.max){								out <- round(mean(c(Estimate_TimeToGerminate, Estimate_TimeToGerminate.oldEstimate)), 0)							} else {								out <- Estimate_TimeToGerminate							}							out <- ifelse(out <= durations[RYdoy] & RYdoy + out <= 365, out, NA) #test whether enough time to germinate							return(out)						}						TimeToGerminate.favorable <- sapply(doys.favorable, FUN=function(fd) get_modifiedHardegree2006NLR(RYdoy=fd, Estimate_TimeToGerminate=1))						if(length(TimeToGerminate.favorable) == 0){							TimeToGerminate.favorable <- vector("numeric", length=0)						}						return(napredict(na.action(na.exclude(doys.padded)), TimeToGerminate.favorable))					}					#Function to calculate mortality under conditions and checks survival limit					calculate_SeedlingMortality_ByCondition <- function(kill.conditions, max.duration.before.kill){						do.vector <- function(kill.vector, max.duration.before.kill){							doys <- 1:length(kill.vector)							doys[!kill.vector] <- NA	#calculate only for kill days							temp.rle <- rle(kill.vector)							if(sum(!temp.rle$values) > 0){								temp.startdoy <- (1 + c(0, cumsum(temp.rle$lengths)))[!temp.rle$values]								if(temp.rle$values[1]){									temp.rle$values <- rep(temp.startdoy, each=2)								} else {									temp.rle$values <- rep(temp.startdoy[-1], each=2)								}								temp.rle$values <- temp.rle$values[1:length(temp.rle$lengths)]							} else {#every day is kill free								temp.rle$values <- length(kill.vector)+1							}							kill.durations <- inverse.rle(temp.rle) - doys							mortality <- rep(FALSE, times=length(kill.vector))							mortality[kill.durations > max.duration.before.kill] <- TRUE							return(mortality)						}						if(length(dim(kill.conditions)) > 0){ #i.e., is.matrix, columns=soil layers							out <- apply(kill.conditions, MARGIN=2, FUN=function(x) do.vector(kill.vector=x, max.duration.before.kill))						} else {							out <- do.vector(kill.conditions, max.duration.before.kill)						}						return(out)					}					#Function to calculate favorable conditions for seedling growth for each day of a given year					calculate_SuitableGrowthThisYear_UnderCondition <- function(favorable.conditions, consequences.unfavorable){						out <- rep(NA, times=length(favorable.conditions))						if(consequences.unfavorable == 0){#if conditions become unfavorable, then stop growth for rest of season							temp.rle <- rle(favorable.conditions)							temp.firstFavorable.index <- which(temp.rle$values)[1]							if(!is.na(temp.firstFavorable.index) && temp.firstFavorable.index < length(temp.rle$values)){								temp.rle$values[(temp.firstFavorable.index+1):length(temp.rle$values)] <- FALSE								out <- inverse.rle(temp.rle)							} else { #nothing changed, either because all days are either favorable or unfavorable or because first favorable period is also the last in the season								out <- favorable.conditions							}						} else if(consequences.unfavorable == 1){#if conditions become unfavorable, then resume growth afterwards							out <- favorable.conditions						}						return(out)					}					#Function to calculate rooting depth at given age					SeedlingRootingDepth <- function(age, P0, K, r){						depth <- K * P0 * exp(r * age) / (K + P0 * (exp(r * age) - 1))	#[age] = days, [P0, K, r] = mm						depth <- pmax(0, depth)						return(depth/10)	#cm					}					#Function that checks whether all relevant (those with roots) soil layers are under conditions of mortality (kill.conditions) for each day of a given year					get_KilledBySoilLayers <- function(relevantLayers, kill.conditions){						temp <- data.frame(relevantLayers, kill.conditions)						return( apply(temp, MARGIN=1, FUN=function(x) {if(!is.na(x[1])){return(all(as.logical(x[2:(2 + x[1] - 1)])))} else {return(NA)} } ) )					}					#Loop through each species					prev.Doy_SeedDispersalStart <- 0					for(sp in 1:no.species_regeneration){						param <- data.frame(t(param.species_regeneration[,sp]))						#Regeneration year=RY: RYdoy=1 == start of seed dispersal = start of 'regeneration year'						Doy_SeedDispersalStart <- max(round(param$Doy_SeedDispersalStart0 + param$SeedDispersalStart_DependencyOnMeanTempJanuary * TmeanJan, 0) %% 365, 1)						moveByDays <- ifelse(Doy_SeedDispersalStart ==  1, 1, max(as.numeric(as.POSIXlt(paste(simTime$useyrs[1] - 1, "-12-31", sep="")) - as.POSIXlt(paste(simTime$useyrs[1] - 1, "-01-01", sep=""))) + 1 - (Doy_SeedDispersalStart - 1) %% 365, 1))						#Calculate regeneration year dates						if(startyr > simstartyr){#start earlier to complete RY							RY.index.usedy <- c(((st <- simTime$index.usedy[1])-moveByDays):(st-1), simTime$index.usedy[-(((et <- length(simTime$index.usedy))-moveByDays+1):et)]) #index indicating which rows of the daily SoilWat output is used							RYyear_ForEachUsedDay <- simTime2$year_ForEachUsedDay	#'regeneration year' for each used day							RYdoy_ForEachUsedDay <- simTime2$doy_ForEachUsedDay	#'doy of the regeneration year' for each used day						} else if(!(startyr > simstartyr)){#start later to get a complete RY							RY.index.usedy <- simTime$index.usedy[-c(1:(Doy_SeedDispersalStart - 1), (((et <- length(simTime$index.usedy))-moveByDays+1):et))]							RYyear_ForEachUsedDay <- simTime2$year_ForEachUsedDay[-which(simTime2$year_ForEachUsedDay == simTime2$year_ForEachUsedDay[1])]							RYdoy_ForEachUsedDay <- simTime2$doy_ForEachUsedDay[-which(simTime2$year_ForEachUsedDay == simTime2$year_ForEachUsedDay[1])]						}						year_ForEachUsedRYDay <- c(rep(simTime$useyrs[1] - 1, times=moveByDays), RYyear_ForEachUsedDay[-(((et <- length(RYyear_ForEachUsedDay))-moveByDays+1):et)])	#normal year for each used 'doy of the regeneration year'						doy_ForEachUsedRYDay <- c(((st <- simTime$index.usedy[1])-moveByDays):(st-1), RYdoy_ForEachUsedDay[-(((et <- length(RYdoy_ForEachUsedDay))-moveByDays+1):et)])	#normal doy for each used 'doy of the regeneration year'						RY.useyrs <- unique(RYyear_ForEachUsedDay)	#list of 'regeneration years' that are used for aggregation						#Access daily data, the first time and afterwards only if Doy_SeedDispersalStart is different from value of previous species						if(sp == 1 || Doy_SeedDispersalStart != prev.Doy_SeedDispersalStart){							swp <- swpmatric.dy.all$val[RY.index.usedy, 2 + ld]							if(length(ld) == 1) swp <- matrix(swp, ncol=1)							snow <- temp.snow[RY.index.usedy, 3]*10 #mm swe in snowpack							airTminSnow <- ifelse(snow > 0, param$Temp_ExperiencedUnderneathSnowcover, temp.temp[RY.index.usedy, 4])							airTmax <- temp.temp[RY.index.usedy, 3]							if(use.soiltemp){								soilTmeanSnow <- ifelse(snow > 0, param$Temp_ExperiencedUnderneathSnowcover, temp.soiltemp[RY.index.usedy, 3])								soilTminSnow <- ifelse(snow > 0, param$Temp_ExperiencedUnderneathSnowcover, temp.soiltemp[RY.index.usedy, 3])								soilTmax <- temp.soiltemp[RY.index.usedy, 3]							} else {								soilTmeanSnow <- ifelse(snow > 0, param$Temp_ExperiencedUnderneathSnowcover, temp.temp[RY.index.usedy, 5])								soilTminSnow <- airTminSnow								soilTmax <- airTmax							}						}						#----GERMINATION						#---1. Germination periods: sequence of days with favorable conditions for germination defined by upper/lower limits						#Maximal temperature for germination						Germination_AtBelowTmax <- soilTmax <= param$Temp_MaximumForGermination						#Minimal temperature for germination						Germination_AtAboveTmin <- soilTminSnow >= param$Temp_MinimumForGermination						#Minimum soil water for germination in relevant soil layer						SoilLayers_RelevantToGermination <- SoilLayer_at_SoilDepth(param$SoilDepth_RelevantToGermination)						if(length(SoilLayers_RelevantToGermination) == 1){							Germination_AtMoreThanTopSWPmin <- swp[, SoilLayers_RelevantToGermination] >= param$SWP_MinimumForGermination							swp.TopMean <- swp[, SoilLayers_RelevantToGermination]						} else {							Germination_AtMoreThanTopSWPmin <- apply(swp[, SoilLayers_RelevantToGermination], MARGIN=1, FUN=function(x) all(x >= param$SWP_MinimumForGermination))							swp.TopMean <- apply(swp[, SoilLayers_RelevantToGermination], MARGIN=1, FUN=mean, na.rm=TRUE)						}						#Put all limits together						Germination_DuringFavorableConditions <- Germination_AtBelowTmax & Germination_AtAboveTmin & Germination_AtMoreThanTopSWPmin						#---2. Time to germinate						#for each day with favorable conditions, determine whether period of favorable conditions (resumed or reset if broken) is long enough for successful completion of germination under current mean conditions						LengthDays_FavorableConditions <- unlist(lapply(RY.useyrs, FUN=function(y) calculate_DurationFavorableConditions(RYyear=y, consequences.unfavorable=param$GerminationPeriods_0ResetOr1Resume)))						Germination_TimeToGerminate <- unlist(lapply(RY.useyrs, FUN=function(y) calculate_TimeToGerminate_modifiedHardegree2006NLR(RYyear=y)))						Germination_RestrictedByTimeToGerminate <- rep(FALSE, times=length(Germination_TimeToGerminate))						Germination_RestrictedByTimeToGerminate[Germination_DuringFavorableConditions & is.na(Germination_TimeToGerminate)] <- TRUE						#---3. Successful germinations						GerminationSuccess_Initiated <- !is.na(Germination_TimeToGerminate)						temp <- padded <- rep(FALSE, times=length(GerminationSuccess_Initiated))						germ.starts <- (1:length(temp))[GerminationSuccess_Initiated]						germ.durs <- Germination_TimeToGerminate[GerminationSuccess_Initiated] - 1						if(param$GerminationPeriods_0ResetOr1Resume == 1){							temp.wait <- na.exclude(unlist(lapply(1:length(temp), FUN=function(t)													{														if(!is.na(Germination_TimeToGerminate[t])){															t3 <- which((t2 <- na.exclude(t1 <- LengthDays_FavorableConditions[t:length(LengthDays_FavorableConditions)]))[Germination_TimeToGerminate[t]] == t1)[1]															out <- sum(is.na(t1[1:t3]))														} else {															out <- NA														}														return(out)													})))							germ.durs <- germ.durs + temp.wait						}						emergence.doys <- germ.starts + germ.durs #index of start of successful germinations + time to germinate (including wait time during unfavorable conditions if 'resume')						temp[emergence.doys] <- TRUE						padded[!GerminationSuccess_Initiated] <- NA						Germination_Emergence.doys <- napredict(na.action(na.exclude(padded)), emergence.doys)						Germination_Emergence <- temp						#----SEEDLING SURVIVAL						#---1. Seedling survival periods:						#	mortality = !survival: days with conditions which kill a seedling, defined by upper/lower limits						#	growth: days with conditions which allows a seedling to grow (here, roots), defined by upper/lower limits						SeedlingMortality_UnderneathSnowCover <- calculate_SeedlingMortality_ByCondition(kill.conditions=(snow > param$SWE_MaximumForSeedlingGrowth), max.duration.before.kill=param$Days_SnowCover_MaximumForSeedlingSurvival)						SeedlingMortality_ByTmin <- calculate_SeedlingMortality_ByCondition(kill.conditions=(airTminSnow < param$Temp_MinimumForSeedlingSurvival), max.duration.before.kill=0)						SeedlingMortality_ByTmax <- calculate_SeedlingMortality_ByCondition(kill.conditions=(airTmax > param$Temp_MaximumForSeedlingSurvival), max.duration.before.kill=0)						SeedlingMortality_ByChronicSWPMax <- calculate_SeedlingMortality_ByCondition(kill.conditions=(swp > param$SWP_ChronicMaximumForSeedlingSurvival), max.duration.before.kill=param$Days_ChronicMaximumForSeedlingSurvival)						SeedlingMortality_ByChronicSWPMin <- calculate_SeedlingMortality_ByCondition(kill.conditions=(swp < param$SWP_ChronicMinimumForSeedlingSurvival), max.duration.before.kill=param$Days_ChronicMinimumForSeedlingSurvival)						SeedlingMortality_ByAcuteSWPMin <- calculate_SeedlingMortality_ByCondition(kill.conditions=(swp < param$SWP_AcuteMinimumForSeedlingSurvival), max.duration.before.kill=0)						SeedlingGrowth_AbsenceOfSnowCover <- (snow <= param$SWE_MaximumForSeedlingGrowth)						SeedlingGrowth_AtAboveTmin <- (airTminSnow >= param$Temp_MinimumForSeedlingGrowth)						SeedlingGrowth_AtBelowTmax <- (airTmax <= param$Temp_MaximumForSeedlingGrowth)						#---2. Grow and kill the seedlings						SeedlingSurvival_1stSeason <- Seedling_Starts <- Germination_Emergence #TRUE=seedling that germinated on that day and survives until end of season; FALSE=no germination or seedling dies during the first season						SeedlingMortality_CausesByYear <- matrix(data=0, nrow=length(RY.useyrs), ncol=9)						colnames(SeedlingMortality_CausesByYear) <- paste("Seedlings1stSeason.Mortality.", c("UnderneathSnowCover", "ByTmin", "ByTmax", "ByChronicSWPMax", "ByChronicSWPMin", "ByAcuteSWPMin",										"DuringStoppedGrowth.DueSnowCover", "DuringStoppedGrowth.DueTmin", "DuringStoppedGrowth.DueTmax"), sep="")						for(y in seq_along(RY.useyrs)){#for each year							RYDoys_SeedlingStarts_ThisYear <- which(Seedling_Starts[index.thisYear <- RYyear_ForEachUsedDay == RY.useyrs[y]])							if(length(RYDoys_SeedlingStarts_ThisYear) > 0){#if there are any germinations								#init values for this year								no.days <- sum(index.thisYear)								thisYear_SeedlingMortality_UnderneathSnowCover <- SeedlingMortality_UnderneathSnowCover[index.thisYear]								thisYear_SeedlingMortality_ByTmin <- SeedlingMortality_ByTmin[index.thisYear]								thisYear_SeedlingMortality_ByTmax <- SeedlingMortality_ByTmax[index.thisYear]								thisYear_SeedlingMortality_ByChronicSWPMax <- SeedlingMortality_ByChronicSWPMax[index.thisYear, ]								thisYear_SeedlingMortality_ByChronicSWPMin <- SeedlingMortality_ByChronicSWPMin[index.thisYear, ]								thisYear_SeedlingMortality_ByAcuteSWPMin <- SeedlingMortality_ByAcuteSWPMin[index.thisYear, ]								thisYear_SeedlingGrowth_AbsenceOfSnowCover <- SeedlingGrowth_AbsenceOfSnowCover[index.thisYear]								thisYear_SeedlingGrowth_AtAboveTmin <- SeedlingGrowth_AtAboveTmin[index.thisYear]								thisYear_SeedlingGrowth_AtBelowTmax <- SeedlingGrowth_AtBelowTmax[index.thisYear]								for(sg_RYdoy in RYDoys_SeedlingStarts_ThisYear){#for each seedling indexed by day of germination									#init values for this seedling and season									index.thisSeedlingSeason <- (temp <- (1:no.days))[temp > sg_RYdoy]									killed_byCauses_onRYdoy <- rep(NA, times=6)	#book-keeping of mortality causes									names(killed_byCauses_onRYdoy) <- colnames(SeedlingMortality_CausesByYear)[1:6]									stopped_byCauses_onRYdoy <- rep(NA, times=3)	#book-keeping of causes why growth stopped									names(stopped_byCauses_onRYdoy) <- colnames(SeedlingMortality_CausesByYear)[7:9]									#Establish days of growth (=TRUE) and surviving, but no growth (=FALSE)									thisSeedlingGrowing <- rep(TRUE, no.days)									if(sg_RYdoy > 1) thisSeedlingGrowing[1:(sg_RYdoy-1)] <- FALSE	#seedling germinated on sg_RYdoy, hence it cannot grow before germination day									#Check growth under above-ground conditions									#Snow cover									thisSeedlingGrowth_AbsenceOfSnowCover <- calculate_SuitableGrowthThisYear_UnderCondition(favorable.conditions=thisSeedlingGrowing & thisYear_SeedlingGrowth_AbsenceOfSnowCover, consequences.unfavorable=param$SeedlingGrowth_0StopOr1Resume)									if(sum(temp <- !thisSeedlingGrowth_AbsenceOfSnowCover[index.thisSeedlingSeason]) > 0) stopped_byCauses_onRYdoy["Seedlings1stSeason.Mortality.DuringStoppedGrowth.DueSnowCover"] <- sg_RYdoy + which(temp)[1]									#Minimum temperature									thisSeedlingGrowth_AtAboveTmin <- calculate_SuitableGrowthThisYear_UnderCondition(favorable.conditions=thisSeedlingGrowing & thisYear_SeedlingGrowth_AtAboveTmin, consequences.unfavorable=param$SeedlingGrowth_0StopOr1Resume)									if(sum(temp <- !thisSeedlingGrowth_AtAboveTmin[index.thisSeedlingSeason]) > 0) stopped_byCauses_onRYdoy["Seedlings1stSeason.Mortality.DuringStoppedGrowth.DueTmin"] <- sg_RYdoy + which(temp)[1]									#Maximum temperature									thisSeedlingGrowth_AtBelowTmax <- calculate_SuitableGrowthThisYear_UnderCondition(favorable.conditions=thisSeedlingGrowing & thisYear_SeedlingGrowth_AtBelowTmax, consequences.unfavorable=param$SeedlingGrowth_0StopOr1Resume)									if(sum(temp <- !thisSeedlingGrowth_AtBelowTmax[index.thisSeedlingSeason]) > 0) stopped_byCauses_onRYdoy["Seedlings1stSeason.Mortality.DuringStoppedGrowth.DueTmax"] <- sg_RYdoy + which(temp)[1]									#Updated days of growth or surviving									thisSeedlingGrowing <- thisSeedlingGrowing & thisSeedlingGrowth_AbsenceOfSnowCover & thisSeedlingGrowth_AtAboveTmin & thisSeedlingGrowth_AtBelowTmax									thisSeedlingLivingButNotGrowing <- !thisSeedlingGrowing									if(sg_RYdoy > 1) thisSeedlingLivingButNotGrowing[1:(sg_RYdoy-1)] <- FALSE	#seedling germinated on sg_RYdoy, hence it cannot live before germination day									#Book-keeping survival under above-ground conditions									if(sum(temp <- thisYear_SeedlingMortality_UnderneathSnowCover[index.thisSeedlingSeason]) > 0) killed_byCauses_onRYdoy["Seedlings1stSeason.Mortality.UnderneathSnowCover"] <- sg_RYdoy + which(temp)[1] - 1									if(sum(temp <- thisYear_SeedlingMortality_ByTmin[index.thisSeedlingSeason]) > 0) killed_byCauses_onRYdoy["Seedlings1stSeason.Mortality.ByTmin"] <- sg_RYdoy + which(temp)[1] - 1									if(sum(temp <- thisYear_SeedlingMortality_ByTmax[index.thisSeedlingSeason]) > 0) killed_byCauses_onRYdoy["Seedlings1stSeason.Mortality.ByTmax"] <- sg_RYdoy + which(temp)[1] - 1									#If not killed (yet) then grow and check survival below-ground									if(all(is.na(killed_byCauses_onRYdoy))){										#Grow: estimate rooting depth for this seedling for each day of this year										thisSeedling_thisYear_RootingDepth <- rep(NA, times=no.days)										if((temp <- sum(thisSeedlingGrowing)) > 0){											thisSeedlingGrowing_AgeDays <- 1:temp											thisSeedlingGrowing_RootingDepth <- SeedlingRootingDepth(thisSeedlingGrowing_AgeDays, param$Seedling_SoilDepth.PO, param$Seedling_SoilDepth.K, param$Seedling_SoilDepth.r)											thisSeedling_thisYear_RootingDepth[thisSeedlingGrowing] <- thisSeedlingGrowing_RootingDepth											if(sum(thisSeedlingLivingButNotGrowing, na.rm=TRUE) > 0){ #for days when growth stopped then copy relevant soil depth												stopg <- addDepths <- rle(thisSeedlingLivingButNotGrowing)												RYDoys_stopg <- c(1, cumsum(stopg$lengths))												for(p in seq(along=stopg$values)[stopg$values]){													if(is.na(thisSeedling_thisYear_RootingDepth[RYDoys_stopg[p]])){														if(is.na(thisSeedling_thisYear_RootingDepth[1 + RYDoys_stopg[p+1]])){															add.values <- param$Seedling_SoilDepth.K														} else {															add.values <- thisSeedling_thisYear_RootingDepth[1 + RYDoys_stopg[p+1]]														}													} else {														add.values <- thisSeedling_thisYear_RootingDepth[RYDoys_stopg[p]]													}													addDepths$values[p] <- add.values												}												RYDoys_addDepths <- inverse.rle(addDepths)												thisSeedling_thisYear_RootingDepth <- ifelse(RYDoys_addDepths > 0, RYDoys_addDepths, thisSeedling_thisYear_RootingDepth)											}										} else {											thisSeedling_thisYear_RootingDepth[thisSeedlingLivingButNotGrowing] <- param$Seedling_SoilDepth.PO/10										}										thisSeedling_thisYear_RootingSoilLayers <- SoilLayer_at_SoilDepth(thisSeedling_thisYear_RootingDepth)										#Check survival under chronic SWPMax										thisSeedling_thisYear_SeedlingMortality_ByChronicSWPMax <- get_KilledBySoilLayers(relevantLayers=thisSeedling_thisYear_RootingSoilLayers, kill.conditions=thisYear_SeedlingMortality_ByChronicSWPMax)										if(sum(temp <- thisSeedling_thisYear_SeedlingMortality_ByChronicSWPMax[index.thisSeedlingSeason]) > 0) killed_byCauses_onRYdoy["Seedlings1stSeason.Mortality.ByChronicSWPMax"] <- sg_RYdoy + which(temp)[1] - 1										#Check survival under chronic SWPMin										thisSeedling_thisYear_SeedlingMortality_ByChronicSWPMin <- get_KilledBySoilLayers(relevantLayers=thisSeedling_thisYear_RootingSoilLayers, kill.conditions=thisYear_SeedlingMortality_ByChronicSWPMin)										if(sum(temp <- thisSeedling_thisYear_SeedlingMortality_ByChronicSWPMin[index.thisSeedlingSeason]) > 0) killed_byCauses_onRYdoy["Seedlings1stSeason.Mortality.ByChronicSWPMin"] <- sg_RYdoy + which(temp)[1] - 1										#Check survival under acute SWPMin										thisSeedling_thisYear_SeedlingMortality_ByAcuteSWPMin <- get_KilledBySoilLayers(relevantLayers=thisSeedling_thisYear_RootingSoilLayers, kill.conditions=thisYear_SeedlingMortality_ByAcuteSWPMin)										if(sum(temp <- thisSeedling_thisYear_SeedlingMortality_ByAcuteSWPMin[index.thisSeedlingSeason]) > 0) killed_byCauses_onRYdoy["Seedlings1stSeason.Mortality.ByAcuteSWPMin"] <- sg_RYdoy + which(temp)[1] - 1									}									#If killed then establish which factor killed first and if and how growth was stopped before kill									if(any(!is.na(killed_byCauses_onRYdoy))){										kill.factor <- which.min(killed_byCauses_onRYdoy)										SeedlingMortality_CausesByYear[y, kill.factor] <- SeedlingMortality_CausesByYear[y, kill.factor] + 1										if(any(!is.na(stopped_byCauses_onRYdoy)) && (killed_byCauses_onRYdoy[kill.factor] > stopped_byCauses_onRYdoy[(stop.factor <- which.min(stopped_byCauses_onRYdoy))])){											SeedlingMortality_CausesByYear[y, 6+stop.factor] <- SeedlingMortality_CausesByYear[y, 6+stop.factor] + 1										}										SeedlingSurvival_1stSeason[RYyear_ForEachUsedDay == RY.useyrs[y]][sg_RYdoy] <- FALSE									}								}							} else {#no germination during this year -> no seedlings to grow or die								SeedlingMortality_CausesByYear[y, ] <- NA							}						}#end of year loop of seedling growth						#---Aggregate output						temp1 <- data.frame(Germination_Emergence, SeedlingSurvival_1stSeason)						temp2 <- data.frame(!Germination_AtBelowTmax, !Germination_AtAboveTmin, !Germination_AtMoreThanTopSWPmin, !Germination_DuringFavorableConditions, Germination_RestrictedByTimeToGerminate)						#Fraction of years with success						resMeans[nv:(nv+1)] <- apply(temp <- (res1.yr <- aggregate(temp1, by=list(year_ForEachUsedRYDay), FUN=sum))[simTime$index.useyr, -1] > 0, MARGIN=2, FUN=mean)						resSDs[nv:(nv+1)] <- apply(temp, MARGIN=2, FUN=sd)						#Periods with no successes						resMeans[(nv+2):(nv+4)] <- quantile((rleGerm <- rle(temp[, 1]))$lengths[!rleGerm$values], probs=c(0.05, 0.5, 0.95), type=7)						resMeans[(nv+5):(nv+7)] <- quantile((rleSling <- rle(temp[, 2]))$lengths[!rleSling$values], probs=c(0.05, 0.5, 0.95), type=7)						#Mean number of days per year with success						resMeans[(nv+8):(nv+9)] <- apply(res1.yr[simTime$index.useyr, -1], MARGIN=2, FUN=mean)						resSDs[(nv+8):(nv+9)] <- apply(res1.yr[simTime$index.useyr, -1], MARGIN=2, FUN=sd)						#Days of year (in normal count) of most frequent successes among years: #toDoy <- function(x) sort(ifelse((temp <- x+Doy_SeedDispersalStart-1) > 365, temp-365,temp)) #convert to normal doys						res1.dy <- aggregate(temp1, by=list(doy_ForEachUsedRYDay), FUN=sum)[, -1]						get.DoyMostFrequentSuccesses <- function(doys){							res1.max <- sapply(1:2, FUN=function(x) quantile(doys[doys[, x]>0, x], probs=c(0.1, 1), type=7))							get.DoyAtLevel <- function(x, level) which(x == level & x > 0)							if(all(!temp1[, 1])){#no successful germination								germ.doy <- list(NA, NA)							} else {								germ.doy <- lapply(1:2, FUN=function(x) get.DoyAtLevel(doys[, 1], res1.max[x, 1]))							}							if(all(!temp1[, 2])){#no successful seedlings								sling.doy <- list(NA, NA)							} else {								sling.doy <- lapply(1:2, FUN=function(x) get.DoyAtLevel(doys[, 2], res1.max[x, 2]))							}							res1.max <- list(germ.doy, sling.doy)							return( unlist(lapply(res1.max, FUN=function(x) c(min(x[[1]]), median(x[[2]]), max(x[[1]])))) )						}						resMeans[(nv+10):(nv+15)] <- get.DoyMostFrequentSuccesses(res1.dy)						#Mean number of days when germination is restricted due to conditions						resMeans[(nv+16):(nv+20)] <- apply((res2.yr <- aggregate(temp2, by=list(year_ForEachUsedRYDay), FUN=sum))[simTime$index.useyr, -1], MARGIN=2, FUN=mean)						resSDs[(nv+16):(nv+20)] <- apply(res2.yr[simTime$index.useyr, -1], MARGIN=2, FUN=sd)						#Mean time to germinate in days						resMeans[nv+21] <- mean((res3.yr <- aggregate(Germination_TimeToGerminate, by=list(year_ForEachUsedRYDay), FUN=mean, na.rm=TRUE))[simTime$index.useyr, -1], na.rm=TRUE)						resSDs[nv+21] <- sd(res3.yr[simTime$index.useyr, -1], na.rm=TRUE)						#Mean number of days per year of different types of mortalities						resMeans[(nv+22):(nv+30)] <- apply(SeedlingMortality_CausesByYear, MARGIN=2, FUN=mean, na.rm=TRUE) #if value==NA, then no germinations that year						resSDs[(nv+22):(nv+30)] <- apply(SeedlingMortality_CausesByYear, MARGIN=2, FUN=sd, na.rm=TRUE) #if value==NA, then no germinations that year						nv <- nv+31						#---Aggregate time series output						if(any(ouput_aggregated_ts=="Regeneration")){							#Table with data for every year							res1.yr.doy <- t(simplify2array(by(temp1, INDICES=year_ForEachUsedRYDay, FUN=function(x) get.DoyMostFrequentSuccesses(x))))[simTime$index.useyr, ]							res.yr <- data.frame(data.frame(res1.yr, res2.yr[, -1], res3.yr[, -1])[simTime$index.useyr, ], SeedlingMortality_CausesByYear, res1.yr.doy)							temp.header2 <- c("DaysWith_GerminationSuccess", "DaysWith_SeedlingSurvival1stSeason",									"Days_GerminationRestrictedByTmax", "Days_GerminationRestrictedByTmin", "Days_GerminationRestrictedBySWPmin", "Days_GerminationRestrictedByAnyCondition", "Days_GerminationRestrictedByTimeToGerminate",									"MeanDays_TimeToGerminate",									paste("Days", colnames(SeedlingMortality_CausesByYear), sep="_"),									paste(rep(c("Start90%", "Median", "End90%"), times=2), rep(c("DoyMostFrequent_GerminationSuccess", "DoyMostFrequent_SeedlingSurvival1stSeason"), each=3), sep="_"))							colnames(res.yr) <- c("Year", temp.header2)							write.csv(res.yr, file=file.path(dir.at, paste("Scenario", formatC(sc-1, width=2, format="d", flag="0"), "_", climate.conditions[sc], "_", i_labels, "_", colnames(param.species_regeneration)[sp], "_Regeneration.csv", sep="")))							#Plot with data for every day							pdf(file=file.path(dir.at, paste("Scenario", formatC(sc-1, width=2, format="d", flag="0"), "_", climate.conditions[sc], "_", i_labels, "_", colnames(param.species_regeneration)[sp], "_Regeneration.pdf", sep="")),									width=max(4, 2*length(simTime$index.useyr)), height=4.5)							op <- par(mar=c(1, 3, 0.1, 0.1), mgp=c(2, 0.5, 0), las=1)							ylim <- c(-17.5, max(max(snow, na.rm=TRUE), max(Germination_TimeToGerminate, na.rm=TRUE)))							p.cex <- max(0.5, min(1, exp(-0.01 * ylim[2]) + 0.5))							xp <- 1:length(snow) + Doy_SeedDispersalStart-1							plot(xp, snow, type="l", ylim=ylim, xlab="Year", ylab="SWE (mm), Time to germinate (days)", axes=FALSE)							axis(1, pos=ylim[1], at=365*(1:(length(simTime$index.useyr))), labels=simTime$useyr)							axis(2, pos=par("usr")[1], at=(temp <- axTicks(2))[temp>=0])							lines(xp, Germination_TimeToGerminate, col="red", type="b", pch=19, cex=p.cex/5)							points(xp, ifelse(SeedlingSurvival_1stSeason, 0, NA), col="green", pch=19)							x0.temp <- (temp <- data.frame(xp, ifelse(GerminationSuccess_Initiated, -7.5, NA)))[complete.cases(temp), ]							x1.temp <- (temp <- data.frame(Germination_Emergence.doys + Doy_SeedDispersalStart-1, ifelse(GerminationSuccess_Initiated, -2.5, NA)))[complete.cases(temp), ]							segments(x0=x0.temp[, 1], y0=x0.temp[, 2], x1=x1.temp[, 1], y1=x1.temp[, 2], col="blue")							points(xp, ifelse(Germination_RestrictedByTimeToGerminate, -10, NA), col="black", pch=4, cex=p.cex)							points(xp, ifelse(!Germination_AtAboveTmin, -12.5, NA), col=gray(0.3), pch=4, cex=p.cex)							points(xp, ifelse(!Germination_AtMoreThanTopSWPmin, -15, NA), col=gray(0.7), pch=4, cex=p.cex)							mtext(i_labels)							legend("topright", legend=c("SWE", "Time to germinate", "Seedling survival", "Emergence", "Too short favorable conditions", "Too cold", "Too dry"),									bty="n", lty=c(1, 1, -1, 1, -1, -1, -1), pch=c(-1, -1, 19, -1, 4, 4, 4), col=c("black", "red", "green", "blue", "black", gray(0.3), gray(0.7)), merge=TRUE)							par(op)							dev.off()						}						#Prepare next species						prev.Doy_SeedDispersalStart <- Doy_SeedDispersalStart					}#end of species loop				}				#64 Daniel's version				if(any(simulation_timescales=="daily") & aon$dailyThermalDryPeriods){					if (print.debug) print("Aggregation of dailyThermalDryPeriods (version drs)")					if (!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)					if (!exists("swcbulk.dy")) swcbulk.dy <- get_Response_aggL(sc, sw_swcbulk, "dy", 10, sum)					thermal <- temp.dy$mean > 0					adjDays <- simTime2$doy_ForEachUsedDay_NSadj[1] - simTime2$doy_ForEachUsedDay[1]					SWCcritsT_mm <- SWPtoVWC(SWPcrit_MPa, texture$sand.top, texture$clay.top) * 10 * sum(layers_width[topL])					if (length(bottomL) > 0 && !identical(bottomL, 0))						SWCcritsB_mm <- SWPtoVWC(SWPcrit_MPa, texture$sand.bottom, texture$clay.bottom) * 10 * sum(layers_width[bottomL])										for (icrit in seq_along(SWPcrit_MPa)) {						thermaldry.top <- thermal & swcbulk.dy$top >= SWCcritsT_mm[icrit]						thermaldry.bottom <- if (length(bottomL) > 0 && !identical(bottomL, 0)) {								thermal & swcbulk.dy$bottom >= SWCcritsT_mm[icrit]							} else {								rep(FALSE, length(thermaldry.top))							}												temp <- aggregate(cbind(thermaldry.top, thermaldry.bottom),									by = list(simTime2$year_ForEachUsedDay_NSadj),									FUN = function(x) max.duration(x, return_doys = TRUE))												resMeans[nv:(nv+3)] <- c(							apply(temp$thermaldry.top[, 2:3, drop = FALSE], 2, circ.mean, int = 365),							apply(temp$thermaldry.bottom[, 2:3, drop = FALSE], 2, circ.mean, int = 365))						resSDs[nv:(nv+3)] <- c(							apply(temp$thermaldry.top[, 2:3, drop = FALSE], 2, circ.sd, int = 365),							apply(temp$thermaldry.bottom[, 2:3, drop = FALSE], 2, circ.sd, int = 365))						nv <- nv+4					}					rm(thermal, adjDays, SWCcritsT_mm, thermaldry.top)					if (length(bottomL) > 0 && !identical(bottomL, 0))						rm(SWCcritsB_mm, thermaldry.bottom)				}       #65				if(any(simulation_timescales=="daily") & aon$dailyWarmDays){				  if(print.debug) print("Aggregation of dailyWarmDays")				  if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)				  				  WarmDays <- lapply(Tmean_crit_C, FUN = function(x) {aggregate(temp.dy$mean > x, by=list(simTime2$year_ForEachUsedDay), FUN=function(x) sum(x) )[, 2]})				  resMeans[nv:(nv+length(Tmean_crit_C)-1)] <- unlist(lapply(WarmDays, mean))				  resSDs[nv:(nv++length(Tmean_crit_C)-1)] <- unlist(lapply(WarmDays, sd))				  nv <- nv+length(Tmean_crit_C)					  rm(WarmDays)				}				#66				if(any(simulation_timescales=="daily") & aon$dailyDegreeDaysCnt){	#Degree days based on daily temp				  if(print.debug) print("Aggregation of dailyDegreeDaysCnt")				  if(!exists("vwcmatric.dy.all")) vwcmatric.dy.all <- get_Response_aggL(sc, sw_vwcmatric, "dyAll", 1, FUN=weighted.mean, weights=layers_width)				  if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- get_SWPmatric_aggL(vwcmatric.dy.all)						  if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)				  if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)				  if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)				  				  temp.dy.all <- swpmatric.dy.all$val[which(vwcmatric.dy.all$val[,1] %in% simTime2$year_ForEachUsedDay),3:10]  # seems for airtemperature no dy.all is available, where to get it??				  				  baseagg <- lapply(Tmean_crit_C, FUN=function(x) {aggregate(ifelse(temp.dy$mean > x ,1, 0), by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]})				  ddaycnt <- unlist(lapply(baseagg, FUN = mean))				  				  resMeans[nv:(nv+length(ddaycnt)-1)] <- ddaycnt				  resSDs[nv:(nv+length(ddaycnt)-1)] <- unlist(lapply(baseagg, FUN = sd))				  nv <- nv+length(ddaycnt)				  				  for (i in Tmean_crit_C) {				    for (j in SWPcrit_MPa) {				      				      degdaycnt <- ifelse(temp.dy$mean > i & swpmatric.dy$bottom < j,1, 0)				      temp <- aggregate(degdaycnt, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2] # Number of days with temp > Tmean_crit_C and bottomsoil layers < SWPcrit_MPa				      				      resMeans[nv] <- mean(temp)				      resSDs[nv] <- sd(temp)				      nv <- nv+1				      				      degdaycnt <- ifelse(temp.dy$mean > i & swpmatric.dy$bottom > j,1, 0)				      temp <- aggregate(degdaycnt, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2] # Number of days with temp > Tmean_crit_C and bottomsoil layers > SWPcrit_MPa				      				      resMeans[nv] <- mean(temp)				      resSDs[nv] <- sd(temp)				      nv <- nv+1				      				      degdaycnt <- ifelse(temp.dy$mean > i & swpmatric.dy$top < j,1, 0)				      temp <- aggregate(degdaycnt, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2] # Number of days with temp > Tmean_crit_C and topoil layers < SWPcrit_MPa				      				      resMeans[nv] <- mean(temp)				      resSDs[nv] <- sd(temp)				      nv <- nv+1				      				      degdaycnt <- ifelse(temp.dy$mean > i & swpmatric.dy$top > j,1, 0)				      temp <- aggregate(degdaycnt, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2] # Number of days with temp > Tmean_crit_C and topsoil layers > SWPcrit_MPa				      				      resMeans[nv] <- mean(temp)				      resSDs[nv] <- sd(temp)				      nv <- nv+1				      				      degdaycnt <- ifelse(temp.dy$mean > i &  apply(temp.dy.all, 1, FUN = function(x) all(x < j)),1,0)				      temp <- aggregate(degdaycnt, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]				      				      resMeans[nv] <- mean(temp)				      resSDs[nv] <- sd(temp)				      nv <- nv+1				      				      degdaycnt <- ifelse(temp.dy$mean > i &  apply(temp.dy.all, 1, FUN = function(x) all(x > j)),1,0)				      temp <- aggregate(degdaycnt, by=list(simTime2$year_ForEachUsedDay), FUN=sum)[, 2]				      				      resMeans[nv] <- mean(temp)				      resSDs[nv] <- sd(temp)				      nv <- nv+1				    }				  }				  rm( temp.dy.all)				}			#67				if(any(simulation_timescales=="daily") & aon$dailyTMaxTenDayMean){				  if(print.debug) print("Aggregation of dailyTMaxTenDayMean")				  if(!exists("vwcmatric.dy.all")) vwcmatric.dy.all <- get_Response_aggL(sc, sw_vwcmatric, "dyAll", 1, FUN=weighted.mean, weights=layers_width)				  if(!exists("swpmatric.dy.all")) swpmatric.dy.all <- get_SWPmatric_aggL(vwcmatric.dy.all) #swp.dy.all is required to get all layers				  if(!exists("vwcmatric.dy")) vwcmatric.dy <- get_Response_aggL(sc, sw_vwcmatric, "dy", 1, FUN=weighted.mean, weights=layers_width)				  if(!exists("swpmatric.dy")) swpmatric.dy <- get_SWPmatric_aggL(vwcmatric.dy)				  if(!exists("temp.dy")) temp.dy <- get_Temp_dy(sc)				  all_soiltemp <- swpmatric.dy.all$val[which(swpmatric.dy.all$val[,1] %in% simTime2$year_ForEachUsedDay),3:10]  # seems for airtemperature no dy.all is available, where to get it??				  ma <- array(NA,c(length(temp.dy$max), 3))				  ma[,1] <- temp.dy$max				  ma[,2] <- swpmatric.dy$top				  ma[,3] <- swpmatric.dy$bottom				  toptenmean <- aggregate(temp.dy$max, by= list(simTime2$year_ForEachUsedDay),FUN= function(x) mean(sort(x, decreasing = TRUE)[1:10]))$x				  resMeans[nv] <- mean(toptenmean)				  resSDs[nv] <- sd(toptenmean)				  nv <- nv+1				   		      topovercrit <- lapply(SWPcrit_MPa, FUN=function(icrit) {		          my_idx <- which(ma[,2] > icrit)		          if (length(ma[my_idx]) == 0) {		            topovercrit2 <- 0		          }   else {		            topovercrit2 <- aggregate(ma[my_idx,1], by = list(simTime2$year_ForEachUsedDay[my_idx]),FUN= function(x) {		              mean(sort(x, decreasing = TRUE)[1:10])		            })$x		          }		          topovercrit2		      })		      resMeans[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(topovercrit, mean) )		      resSDs[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(topovercrit, sd) )		      nv <- nv + length(SWPcrit_MPa)          topundercrit <- lapply(SWPcrit_MPa, FUN=function(icrit) {              my_idx <- which(ma[,2] < icrit)              if (length(ma[my_idx]) == 0) {                topundercrit2 <- 0              }   else {                topundercrit2 <- aggregate(ma[my_idx,1], by = list(simTime2$year_ForEachUsedDay[my_idx]),FUN= function(x) {                  mean(sort(x, decreasing = TRUE)[1:10])                })$x              }              topundercrit2          })          resMeans[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(topundercrit, mean) )          resSDs[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(topundercrit, sd))          nv <- nv + length(SWPcrit_MPa)          botovercrit <- lapply(SWPcrit_MPa, FUN=function(icrit) {              my_idx <- which(ma[,3] > icrit)              if (length(ma[my_idx]) == 0) {                botovercrit2 <- 0              }   else {                botovercrit2 <- aggregate(ma[my_idx,1], by = list(simTime2$year_ForEachUsedDay[my_idx]),FUN= function(x) {                  mean(sort(x, decreasing = TRUE)[1:10])                })$x              }              botovercrit2          })          resMeans[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(botovercrit, mean))          resSDs[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(botovercrit, sd))          nv <- nv + length(SWPcrit_MPa)          botundercrit <- lapply(SWPcrit_MPa, FUN=function(icrit) {              my_idx <- which(ma[,3] > icrit)              if (length(ma[my_idx]) == 0) {                botundercrit2 <- 0              }   else {                botundercrit2 <- aggregate(ma[my_idx,1], by = list(simTime2$year_ForEachUsedDay[my_idx]),FUN= function(x) {                  mean(sort(x, decreasing = TRUE)[1:10])                })$x              }              botundercrit2          })          resMeans[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(botundercrit, mean))          resSDs[nv:(nv + length(SWPcrit_MPa)-1)] <- unlist(lapply(botundercrit, sd))          nv <- nv + length(SWPcrit_MPa)          allovercrit <- lapply(SWPcrit_MPa, FUN=function(icrit) {              i_suitable <- which(apply(all_soiltemp, 1, FUN = function(x) {                all(x > icrit)              }))              if (length(i_suitable) == 0) {                allovercrit2 <- 0              } else {                allovercrit2 <- aggregate(ma[i_suitable, 1],                                          by = list(simTime2$year_ForEachUsedDay[i_suitable]),FUN= function(x) {                                            mean(sort(x, decreasing = TRUE)[1:10])                                          })$x              }              allovercrit2          })          resMeans[nv:(nv+length(SWPcrit_MPa) -1)] <- unlist(lapply(allovercrit,mean))          resSDs[nv:(nv+length(SWPcrit_MPa) -1)] <- unlist(lapply(allovercrit, sd))          nv <- nv + length(SWPcrit_MPa)          allundercrit <- lapply(SWPcrit_MPa, FUN=function(icrit) {              i_suitable <- which(apply(all_soiltemp, 1, FUN = function(x) {                all(x < icrit)              }))              if (length(i_suitable) == 0) {                allundercrit2 <- 0              } else {                allundercrit2 <- aggregate(ma[i_suitable, 1],                                         by = list(simTime2$year_ForEachUsedDay[i_suitable]),                                         FUN= function(x) {                                          mean(sort(x, decreasing = TRUE)[1:10])                                         })$x             }             allundercrit2          })          resMeans[nv:(nv+length(SWPcrit_MPa) -1)] <- unlist(lapply(allundercrit,mean))          resSDs[nv:(nv+length(SWPcrit_MPa) -1)] <- unlist(lapply(allundercrit, sd))          nv <- nv + length(SWPcrit_MPa)				  rm(ma, toptenmean, all_soiltemp, topovercrit, topundercrit, botovercrit, botundercrit, allovercrit, allundercrit)				}				#---Aggregation: done with options				#temporaly save aggregate data				P_id <- it_Pid(i_sim, sc)								if (dbOverallColumns > 0 && dbOverallColumns == (nv - 1)) {					resMeans[!is.finite(resMeans)] <- "NULL"					resSDs[!is.finite(resSDs)] <- "NULL"					temp1 <- paste0(c(P_id, resMeans[1:(nv-1)]), collapse = ",")					temp2 <- paste0(c(P_id, resSDs[1:(nv-1)]), collapse = ",")				} else {					temp1 <- temp2 <- P_id				}				SQL1 <- paste0("INSERT INTO \"aggregation_overall_mean\" VALUES (", temp1, ");")				SQL2 <- paste0("INSERT INTO \"aggregation_overall_sd\" VALUES (", temp2, ");")								if(length(SQL) == 0) {					SQL <- paste(SQL1, SQL2, sep="\n")				} else {					SQL <- paste(SQL, SQL1, SQL2, sep="\n")				}			}			#Daily Output			if(any(simulation_timescales=="daily") && daily_no > 0){				dailyList <- list()				SQLc <- ""				#aggregate for each response variable				for (doi in 1:daily_no) {					if(print.debug) print(paste("Aggregation of mean daily outputs:", doi))					if(!continueAfterAbort | (continueAfterAbort & !isdone.dailyAggs[doi, sc])){						#check to see if we are on SWA						if(regexpr("SWAbulk", output_aggregate_daily[doi]) > 0){							agg.resp <- "SWAbulk"							index.SWPcrit <- -as.numeric(sub("kPa", "", sub("SWAbulkatSWPcrit", "", output_aggregate_daily[doi])))/1000						} else {							agg.resp <- output_aggregate_daily[doi]						}						agg.analysis <- switch(EXPR=agg.resp, AET=1, Transpiration=2, EvaporationSoil=1, EvaporationSurface=1, EvaporationTotal=1, VWCbulk=2, VWCmatric=2, SWCbulk=2, SWPmatric=2, SWAbulk=2, Snowpack=1, Rain=1, Snowfall=1, Snowmelt=1, SnowLoss=1, Infiltration=1, DeepDrainage=1, PET=1, TotalPrecipitation=1, TemperatureMin=1, TemperatureMax=1, SoilTemperature=2, Runoff=1)						agg.no <- ifelse(agg.analysis == 1, 1, aggLs_no)						res.dailyMean <- res.dailySD <- rep(NA, times=ifelse(agg.analysis == 1, 1, ifelse(AggLayer.daily, agg.no, SoilLayer_MaxNo)) * 366)						scaler <- switch(EXPR=output_aggregate_daily[doi], SWPmatric=1, VWCbulk=1, VWCmatric=1, TemperatureMin=1, TemperatureMax=1, SoilTemperature=1, 10) 	# SWP: -bar => MPa (but, since calculated via VWC, needs be same as VWC); VWC: # cm/cm -> m3/m3; default: cm => mm						#read in data unless Exclude_ClimateAmbient						if(!Exclude_ClimateAmbient) {							if(agg.resp == "EvaporationTotal"){								temp1 <- slot(slot(runData[[sc]],sw_evsoil),"Day")								temp2 <- slot(slot(runData[[sc]],sw_evapsurface),"Day")							} else {#"VWCbulk","VWCmatric", "SWCbulk", "SWPmatric","SWAbulk"								agg.file <- switch(EXPR=agg.resp,										AET=sw_aet,										Transpiration=sw_transp,										EvaporationSoil=sw_evsoil,										EvaporationSurface=sw_evapsurface,										VWCbulk=sw_vwcbulk,										VWCmatric=sw_vwcmatric,										SWCbulk=sw_swcbulk,										SWPmatric=sw_vwcmatric,#TODO: this was sw_vwc so can we just do sw_swpmatric?										SWAbulk=sw_swcbulk,#TODO: this was sw_swc so can we just do sw_swa?										Snowpack=sw_snow,										Rain=sw_precip,										Snowfall=sw_precip,										Snowmelt=sw_precip,										SnowLoss=sw_precip,										Infiltration=sw_inf_soil,										DeepDrainage=sw_deepdrain,										PET=sw_pet,										TotalPrecipitation=sw_precip,										TemperatureMin=sw_temp,										TemperatureMax=sw_temp,										SoilTemperature=sw_soiltemp,										Runoff=sw_runoff)								temp1 <- slot(slot(runData[[sc]],agg.file),"Day")							}							#extract data and aggregate into layers if requested							agg.dat <- NULL							if(agg.analysis == 1){ #no layers								if( any(!is.na(match(agg.resp, c("AET", "EvaporationSurface", "Snowpack", "Rain", "Snowfall", "Snowmelt", "SnowLoss", "Infiltration", "DeepDrainage", "PET", "TotalPrecipitation", "TemperatureMin", "TemperatureMax","Runoff")))) ){									agg.column <- switch(EXPR=agg.resp, AET=3, EvaporationSurface=3, Snowpack=3, Rain=4, Snowfall=5, Snowmelt=6, SnowLoss=7, Infiltration=3, DeepDrainage=3, PET=3, TotalPrecipitation=3, TemperatureMin=4, TemperatureMax=3,Runoff=3)									agg.dat[[1]] <- temp1[simTime$index.usedy, agg.column]								}								if(agg.resp == "EvaporationTotal"){									if((colN <- ncol(temp1)) > 3){										agg.dat[[1]] <- apply(temp1[simTime$index.usedy, 3:colN], 1, sum) + temp2[simTime$index.usedy, 3]									} else {										agg.dat[[1]] <- temp1[simTime$index.usedy, 3] + temp2[simTime$index.usedy, 3]									}								}								if(agg.resp == "EvaporationSoil"){									if((colN <- ncol(temp1)) > 3){										agg.dat[[1]] <- apply(temp1[simTime$index.usedy, 3:colN], 1, sum)									} else {										agg.dat[[1]] <- temp1[simTime$index.usedy, 3]									}								}							} else {#deal with soil layers: either each or 1-4 aggregated soil layers								if( any(!is.na(match(agg.resp, c("VWCbulk", "VWCmatric", "SWPmatric", "SoilTemperature")))) ){ #aggregate by functions that are weighted by depths of soil layers									agg.agg <- weighted.mean									agg.w <- layers_width								} else if( any(!is.na(match(agg.resp, c("Transpiration", "SWCbulk", "SWAbulk")))) ){#aggregate by simple functions									agg.agg <- sum									agg.w <- rep(0, times=length(layers_width))								}								for(al in 1:aggLs_no){									if(length(aggLs[[al]]) > 1) {										agg.dat[[al]] <- apply(temp1[simTime$index.usedy, 2 + aggLs[[al]]], 1, agg.agg, w=agg.w[aggLs[[al]]])									} else {										if(!(is.null(aggLs[[al]]) | length(aggLs[[al]]) == 0)) {											agg.dat[[al]]  <- temp1[simTime$index.usedy, 2 + aggLs[[al]]]										}									}								}							}							#calculate mean/SD daily values							for(al in 1:agg.no){								ir <- (al - 1) * 366 + 1:366								res.dailyMean[ir] <- aggregate(scaler * agg.dat[[al]], by=list(simTime2$doy_ForEachUsedDay), FUN=mean)[, 2]								if(agg.resp == "SWPmatric"){ ##post-aggregate calculation of SWP: convert VWC to SWP									res.dailyMean[ir] <- VWCtoSWP(res.dailyMean[ir], textureDAgg$sand[al], textureDAgg$clay[al])									res.dailySD[ir] <- 0 #was NA now 0								} else {									res.dailySD[ir] <- aggregate(scaler * agg.dat[[al]], by=list(simTime2$doy_ForEachUsedDay), FUN=sd)[, 2]								}							}							#post-aggregate calculation of SWA based on SWC for each SWPcrit							if(agg.resp == "SWAbulk"){								swc.swpcrit.layers <- layers_width * 10 * SWPtoVWC(index.SWPcrit, sand, clay)								for(al in 1:agg.no){									ir <- (al - 1) * 366 + 1:366									if(length(aggLs[[al]]) > 1){										swc.swpcrit <- sum(swc.swpcrit.layers[aggLs[[al]]])									} else {										swc.swpcrit <- swc.swpcrit.layers[aggLs[[al]]]									}									res.dailyMean[ir] <- ifelse((temp.res <- res.dailyMean[ir] - swc.swpcrit) > 0, temp.res, 0)	#SD is same as for SWC								}							}						}						#temporary save daily data						P_id <- it_Pid(i_sim, sc)						#save(agg.analysis, aggLs_no, P_id, header, sc, agg.resp, res.dailyMean, res.dailySD, file=file.path(dir.out, paste(mpi.comm.rank(),"of",mpi.comm.size(),"_sc_",sc,"_doi_",doi,".r",sep="")))						if(agg.analysis == 1){							res.dailyMean[!is.finite(res.dailyMean)] <- "NULL"							res.dailySD[!is.finite(res.dailySD)] <- "NULL"							SQL1 <- paste0("INSERT INTO ",paste("aggregation_doy_", output_aggregate_daily[doi], "_Mean", sep=""), " VALUES ", paste0("(",sapply(1:agg.no, FUN=function(x) {paste0(P_id,",",paste0(res.dailyMean[((x*366)-365):(x*366)],collapse=","))}), ")", sep="", collapse = ","), ";", sep="")							SQL2 <- paste0("INSERT INTO ",paste("aggregation_doy_", output_aggregate_daily[doi], "_SD", sep=""),   " VALUES ", paste0("(",sapply(1:agg.no, FUN=function(x) {paste0(P_id,",",paste0(res.dailySD[((x*366)-365):(x*366)],collapse=","))}), ")", sep="", collapse = ","), ";", sep="")							SQL <- paste(SQL, SQL1, SQL2, sep="\n")						} else {							#save(res.dailyMean,agg.no,header,header.names,P_id, res.dailySD,agg.analysis, aggLs_no,aggLs,agg.resp,layers_width,file=file.path(dir.out, "readThis.r"))							res.dailyMean[!is.finite(res.dailyMean)] <- "NULL"							res.dailySD[!is.finite(res.dailySD)] <- "NULL"							SQL1 <- paste0("INSERT INTO ",paste("aggregation_doy_", output_aggregate_daily[doi], "_Mean", sep=""), " VALUES ", paste0("(",sapply(1:agg.no, FUN=function(x) {paste0(P_id,",", x,",",paste0(res.dailyMean[((x*366)-365):(x*366)],collapse=","))}), ")", sep="", collapse = ","), ";", sep="")							SQL2 <- paste0("INSERT INTO ",paste("aggregation_doy_", output_aggregate_daily[doi], "_SD", sep=""),   " VALUES ", paste0("(",sapply(1:agg.no, FUN=function(x) {paste0(P_id,",", x,",",paste0(res.dailySD[((x*366)-365):(x*366)],collapse=","))}), ")", sep="", collapse = ","), ";", sep="")							SQL <- paste(SQL, SQL1, SQL2, sep="\n")						}					}#end if continueAfterAbort				}#doi loop			}#end if daily output			if(tasks$aggregate > 0L && length(SQL) > 0 && sc == 1){				#Clear SQL				SQLcurrent <- SQL				SQL <- character(0)			}		} #end loop through scenarios	} #end if do aggregate	if(tasks$aggregate > 0L && (length(SQL) > 0 || length(SQLcurrent) > 0)){		tasks$aggregate <- 2L		if(length(SQLcurrent) > 0) write(SQLcurrent, dbTempFileCurrent, append=TRUE)		if(length(SQL) > 0) write(SQL, dbTempFile, append=TRUE)	}	if(all(unlist(tasks) != 0)){		#ETA estimation		dt <- difftime(Sys.time(), time.sys, units="secs")		times <- read.csv(file=file.path(dir.out, timerfile), header=FALSE, colClasses=c("NULL", "numeric"))		if(!be.quiet) print(paste(i_sim, ":", i_labels, "done in", round(dt, 2), units(dt), ":", round(nrow(times)/runsN_total*100, 2), "% complete, ETA =", Sys.time()+ceiling((runsN_total-(nrow(times)-1))/workersN)*mean(unlist(c(times, dt)), na.rm=TRUE) ))		write.table(data.frame(i=i_sim,dt=dt), file=file.path(dir.out, timerfile), append=TRUE, sep=",", dec=".", col.names=FALSE,row.names=FALSE)	} else {		print(paste(i_sim, ":", i_labels, " unsuccessful:", paste(names(tasks), "=", tasks, collapse=", ")))	}	return(1)} #end do_OneSite()#------------------------	work <- function() {		# Note the use of the tag for sent messages:		#     1=ready_for_task, 2=done_task, 3=exiting		# Note the use of the tag for received messages:		#     1=task, 2=done_tasks		junk <- 0		done <- 0		while (done != 1) {			# Signal being ready to receive a new task			mpi.send.Robj(junk,0,1)			# Receive a task			dataForRun <- mpi.recv.Robj(mpi.any.source(),mpi.any.tag())			task_info <- mpi.get.sourcetag()			tag <- task_info[2]			if (tag == 1) {				print(dataForRun$i_sim)				if(dataForRun$do_OneSite) result <- do_OneSite(i_sim=dataForRun$i_sim, i_labels=dataForRun$labels, i_SWRunInformation=dataForRun$SWRunInformation, i_sw_input_soillayers=dataForRun$sw_input_soillayers, i_sw_input_treatments=dataForRun$sw_input_treatments, i_sw_input_cloud=dataForRun$sw_input_cloud, i_sw_input_prod=dataForRun$sw_input_prod, i_sw_input_site=dataForRun$sw_input_site, i_sw_input_soils=dataForRun$sw_input_soils, i_sw_input_weather=dataForRun$sw_input_weather, i_sw_input_climscen=dataForRun$sw_input_climscen, i_sw_input_climscen_values=dataForRun$sw_input_climscen_values)				# Send a results message back to the master				#print(results)				mpi.send.Robj(list(i=dataForRun$i_sim,r=result),0,2)			} else if (tag == 2) {				done <- 1			}			# We'll just ignore any unknown messages		}		mpi.send.Robj(junk,0,3)	}}#--------------------------------------------------------------------------------------------------##------------------------RUN RSOILWAT# print system informationprint(temp <- sessionInfo())if (check.blas && grepl("darwin", temp$platform)) { # apparently this works only on Mac OS X	blas <- system2(command = file.path(Sys.getenv()[["R_HOME"]], "R"), args = "CMD config BLAS_LIBS", stdout = TRUE)	blas <- sub("-L/", "/", (strsplit(blas, split=" ")[[1]][1]))	lapack <- system2(command = file.path(Sys.getenv()[["R_HOME"]], "R"), args = "CMD config LAPACK_LIBS", stdout = TRUE)	lapack <- sub("-L/", "/", (strsplit(lapack, split=" ")[[1]][1]))	get_ls <- if(identical(blas, lapack)) list(blas) else list(blas, lapack)	temp <- lapply(get_ls, FUN = function(x) print(system2(command = "ls", args = paste("-l", x), stdout = TRUE)))	print("Check linked BLAS library:") # http://simplystatistics.org/2016/01/21/parallel-blas-in-r/#	print(system.time({ x <- replicate(5e3, rnorm(5e3)); tcrossprod(x) }))	# Example values:	# Apple's Accelerate framework:	#   user  system elapsed	# 14.755   0.268   3.423	# ATLAS 3.10.2_2:	#   user  system elapsed	# 22.218   0.647   3.340	# Built-in reference BLAS:	#   user  system elapsed	# 59.289   0.465  59.173}# run the simulation experimentif(actionWithSoilWat && runsN_todo > 0){	swDataFromFiles <- sw_inputDataFromFiles(dir=dir.sw.in,files.in=swFilesIn) #This acts for the basis for all runs.	if (length(swDataFromFiles@weatherHistory) > 0)		swDataFromFiles@weatherHistory <- list(swClear(swDataFromFiles@weatherHistory[[1]])) # we don't need the example weather data; the code will get weather data separately	#Used for weather from files	filebasename <- basename(swFiles_WeatherPrefix(swDataFromFiles))	#objects to export	list.export <- c("filebasename","Tmax_crit_C","Tmin_crit_C", "increment_soiltemperature_deltaX_cm", "name.OutputDB","getScenarioWeatherDataFromDatabase","getCurrentWeatherDataFromDatabase","ExtractGriddedDailyWeatherFromMaurer2002_NorthAmerica", "create_filename_for_Maurer2002_NorthAmerica", "ExtractGriddedDailyWeatherFromDayMet_NorthAmerica", "dir.ex.daymet", "get_DayMet_NorthAmerica", "get_DayMet_cellID", "climate.conditions","dir.sw.in.tr","dbWeatherDataFile","dir.ex.maurer2002","AggLayer.daily","Depth_TopLayers","Depth_FirstAggLayer.daily","Depth_SecondAggLayer.daily","Depth_ThirdAggLayer.daily","Depth_FourthAggLayer.daily","adjustLayersDepth", "getLayersWidth", "setLayerSequence", "sw_dailyC4_TempVar","sw_SiteClimate_Ambient","PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996", "AdjMonthlyBioMass","siteparamin","soilsin","weatherin","cloudin","prodin","estabin","tr_input_TranspCoeff_Code","transferExpDesignToInput","sw_input_experimentals","getStartYear","get.month","adjust.WindspeedHeight","circ.mean","circ.range","circ.sd","dir.create2","do_OneSite","endDoyAfterDuration","EstimateInitialSoilTemperatureForEachSoilLayer","get.LookupEvapCoeffFromTable","get.LookupSnowDensityFromTable","get.LookupTranspRegionsFromTable","max.duration","setAggSoilLayerForAggDailyResponses","simTiming","simTiming_ForEachUsedTimeUnit","startDoyOfDuration","SWPtoVWC","TranspCoeffByVegType","VWCtoSWP",			"work", "do_OneSite", "accountNSHemispheres_veg","AggLayer.daily","be.quiet","bin.prcpfreeDurations","bin.prcpSizes","climate.conditions","continueAfterAbort","datafile.windspeedAtHeightAboveGround","adjust.soilDepth","DegreeDayBase","Depth_TopLayers","dir.out","dir.sw.runs","endyr","estabin","establishment.delay","establishment.duration","establishment.swp.surface","exec_c_prefix","filebasename.WeatherDataYear","germination.duration","germination.swp.surface","growing.season.threshold.tempC","makeInputForExperimentalDesign","ouput_aggregated_ts","output_aggregate_daily","parallel_backend","parallel_runs","print.debug","saveRsoilwatInput", "saveRsoilwatOutput","season.end","season.start","shrub.fraction.limit","simstartyr","simulation_timescales","startyr","sw_aet","sw_deepdrain","sw_evapsurface","sw_evsoil","sw_hd","sw_inf_soil","sw_interception","sw_percolation","sw_pet","sw_precip","sw_runoff","sw_snow","sw_soiltemp","sw_swabulk","sw_swamatric","sw_swcbulk","sw_swpmatric","sw_temp","sw_transp","sw_vwcbulk","sw_vwcmatric","sw.inputs","sw.outputs","swcsetupin","swFilesIn","swOutSetupIn","SWPcrit_MPa","yearsin","dbOverallColumns","aon","create_experimentals","create_treatments","daily_no","dir.out.temp","dirname.sw.runs.weather","do.GetClimateMeans","ExpInput_Seperator","lmax","no.species_regeneration","param.species_regeneration","pcalcs","runsN_sites","runsN_todo","runsN_total", "scenario_No","simTime","simTime_ForEachUsedTimeUnit_North","simTime_ForEachUsedTimeUnit_South","SoilLayer_MaxNo","SoilWat.windspeedAtHeightAboveGround","st_mo","sw_input_climscen_use","sw_input_climscen_values_use","sw_input_cloud_use","sw_input_experimentals_use","sw_input_prod_use","sw_input_site_use","sw_input_soils_use","sw_input_weather_use","swDataFromFiles","counter.digitsN","timerfile","tr_cloud","tr_files","tr_input_climPPT","tr_input_climTemp","tr_input_EvapCoeff","tr_input_shiftedPPT","tr_input_SnowD","tr_input_TranspCoeff","tr_input_TranspRegions","tr_prod","tr_site","tr_soil","tr_VegetationComposition","tr_weather","expN","workersN", "it_Pid", "it_exp", "it_site", "runsN_master")	list.export <- ls()[ls() %in% list.export]	#ETA calculation	if(!be.quiet) print(paste("SWSF simulation runs:", runsN_todo, "out of", runsN_total, " runs will be carried out on", workersN, "cores: started at", t1 <- Sys.time()))	inputDataToSave <- list()	if(parallel_runs && parallel_init){		#call the simulations depending on parallel backend		if(identical(parallel_backend, "mpi")) {			workersN <- (mpi.comm.size() - 1)			exportObjects(list.export)			mpi.bcast.cmd(library(Rsoilwat31,quietly = TRUE))			mpi.bcast.cmd(library(circular,quietly = TRUE))			mpi.bcast.cmd(library(SPEI,quietly = TRUE))			mpi.bcast.cmd(library(RSQLite,quietly = TRUE))			#mpi.bcast.cmd(con<-DBI::dbConnect(RSQLite::SQLite(),dbWeatherDataFile))			mpi.bcast.cmd(work())			junk <- 0			closed_slaves <- 0			runs.completed <- 1			#sTag <- c("Ready for task", "Done with Task", "Exiting")			while(closed_slaves < workersN) {tryCatch({				complete <- mpi.recv.Robj(mpi.any.source(),mpi.any.tag())				complete_info <- mpi.get.sourcetag()				slave_id <- complete_info[1]				tag <- complete_info[2]				#print(paste("From:", slave_id, "tag:", tag, "Message:", complete))				if (tag == 1) {					temp <- Sys.time() - t.overall					units(temp) <- "secs"					temp <- as.double(temp)					# slave is ready for a task. Give it the next task, or tell it tasks					# are done if there are none.					if ((runs.completed <= length(runIDs_todo)) & (temp < MaxDoOneSiteTime)) {						# Send a task, and then remove it from the task list						i_site <- it_site(runIDs_todo[runs.completed])						i_labels <- labels[i_site]						i_SWRunInformation <- SWRunInformation[i_site, ]						i_sw_input_soillayers <- sw_input_soillayers[i_site, ]						i_sw_input_treatments <- sw_input_treatments[i_site, ]						i_sw_input_cloud <- sw_input_cloud[i_site, ]						i_sw_input_prod <- sw_input_prod[i_site, ]						i_sw_input_site <- sw_input_site[i_site, ]						i_sw_input_soils <- sw_input_soils[i_site, ]						i_sw_input_weather <- sw_input_weather[i_site, ]						i_sw_input_climscen <- sw_input_climscen[i_site, ]						i_sw_input_climscen_values <- sw_input_climscen_values[i_site, ]						dataForRun <- list(do_OneSite=TRUE, i_sim=runIDs_todo[runs.completed], labels=i_labels, SWRunInformation=i_SWRunInformation, sw_input_soillayers=i_sw_input_soillayers, sw_input_treatments=i_sw_input_treatments, sw_input_cloud=i_sw_input_cloud, sw_input_prod=i_sw_input_prod, sw_input_site=i_sw_input_site, sw_input_soils=i_sw_input_soils, sw_input_weather=i_sw_input_weather, sw_input_climscen=i_sw_input_climscen, sw_input_climscen_values=i_sw_input_climscen_values)						mpi.send.Robj(dataForRun, slave_id, 1);						print(paste("Slave:", slave_id, "Run:", runIDs_todo[runs.completed], "started at", Sys.time()))						runs.completed <- runs.completed + 1					} else {						mpi.send.Robj(junk, slave_id, 2)					}				} else if (tag == 2) {					# The message contains results. Do something with the results.					# Store them in the data structure					inputDataToSave[[complete$i]] <- complete$r					#print(paste("Run: ", complete, "at", Sys.time()))				} else if (tag == 3) {					# A slave has closed down.					closed_slaves <- closed_slaves + 1					print(paste("Slave Closed:", slave_id))				} else if (tag == 4) {					#The slave had a problem with Soilwat record Slave number and the Run number.					print("Problem with run")					write.csv(x=data.frame(Slave=slave_id,Run=complete), file=file.path(dir.out, "ProblemRuns.csv"), append=TRUE,row.names<-FALSE,col.names=TRUE)				}}, interrupt=function(interrupt) {	print("Ctrl-C caught bringing work to an end.")	print(interrupt)	MaxDoOneSiteTime <<- 0})			}			mpi.bcast.cmd(rm(list=ls())) #do not remove 'ls(all=TRUE)' because there are important .XXX objects that are important for proper slave functioning!			mpi.bcast.cmd(gc())			print(runs.completed)		}		if(identical(parallel_backend, "snow")){			snow::clusterEvalQ(cl, library(circular,quietly=TRUE)) 	#load any packages necessary for do_OneSite(): none as of July 24, 2012			snow::clusterEvalQ(cl, library(SPEI,quietly=TRUE))			snow::clusterEvalQ(cl, library(RSQLite,quietly=TRUE))			snow::clusterEvalQ(cl, library(Rsoilwat31,quietly=TRUE))			export_obj_local <- list.export[list.export %in% ls(name=environment())]			export_obj_in_parent <- list.export[list.export %in% ls(name=parent.frame())]			export_obj_in_parent <- export_obj_in_parent[!(export_obj_in_parent %in% export_obj_local)]			export_obj_in_globenv <- list.export[list.export %in% ls(name=.GlobalEnv)]			export_obj_in_globenv <- export_obj_in_globenv[!(export_obj_in_globenv %in% c(export_obj_local, export_obj_in_parent))]			stopifnot(c(export_obj_local, export_obj_in_parent, export_obj_in_globenv) %in% list.export)			if(length(export_obj_local) > 0) snow::clusterExport(cl, export_obj_local, envir=environment())			if(length(export_obj_in_parent) > 0) snow::clusterExport(cl, export_obj_in_parent, envir=parent.frame())			if(length(export_obj_in_globenv) > 0) snow::clusterExport(cl, export_obj_in_globenv, envir=.GlobalEnv)			snow::clusterEvalQ(cl, dbConnected <- FALSE)			runs.completed <- foreach(i_sim=runIDs_todo, .combine="+", .inorder=FALSE) %dopar% {				i_site <- it_site(i_sim)				do_OneSite(i_sim=i_sim, i_labels=labels[i_site], i_SWRunInformation=SWRunInformation[i_site, ], i_sw_input_soillayers=sw_input_soillayers[i_site, ], i_sw_input_treatments=sw_input_treatments[i_site, ], i_sw_input_cloud=sw_input_cloud[i_site, ], i_sw_input_prod=sw_input_prod[i_site, ], i_sw_input_site=sw_input_site[i_site, ], i_sw_input_soils=sw_input_soils[i_site, ], i_sw_input_weather=sw_input_weather[i_site, ], i_sw_input_climscen=sw_input_climscen[i_site, ], i_sw_input_climscen_values=sw_input_climscen_values[i_site, ])			}			snow::clusterEvalQ(cl, rm(list=ls()))			snow::clusterEvalQ(cl, gc())		}		if(identical(parallel_backend, "multicore")){			runs.completed <- foreach(i_sim=runIDs_todo, .combine="+", .inorder=FALSE, .noexport=list.noexport) %dopar% {				i_site <- it_site(i_sim)				do_OneSite(i_sim=i_sim, i_labels=labels[i_site], i_SWRunInformation=SWRunInformation[i_site, ], i_sw_input_soillayers=sw_input_soillayers[i_site, ], i_sw_input_treatments=sw_input_treatments[i_site, ], i_sw_input_cloud=sw_input_cloud[i_site, ], i_sw_input_prod=sw_input_prod[i_site, ], i_sw_input_site=sw_input_site[i_site, ], i_sw_input_soils=sw_input_soils[i_site, ], i_sw_input_weather=sw_input_weather[i_site, ], i_sw_input_climscen=sw_input_climscen[i_site, ], i_sw_input_climscen_values=sw_input_climscen_values[i_site, ])			}		}	} else { #call the simulations in serial		runs.completed <- 0		runs.completed <- foreach(i_sim=runIDs_todo, .combine="+", .inorder=FALSE) %do% {			i_site <- it_site(i_sim)			do_OneSite(i_sim=i_sim, i_labels=labels[i_site], i_SWRunInformation=SWRunInformation[i_site, ], i_sw_input_soillayers=sw_input_soillayers[i_site, ], i_sw_input_treatments=sw_input_treatments[i_site, ], i_sw_input_cloud=sw_input_cloud[i_site, ], i_sw_input_prod=sw_input_prod[i_site, ], i_sw_input_site=sw_input_site[i_site, ], i_sw_input_soils=sw_input_soils[i_site, ], i_sw_input_weather=sw_input_weather[i_site, ], i_sw_input_climscen=sw_input_climscen[i_site, ], i_sw_input_climscen_values=sw_input_climscen_values[i_site, ])		}		#Best for debugging#		setwd(dir.prj)#		exeEnv <- new.env()#		for(n in list.export) assign(x=n,value=get(n,globalenv()), envir=exeEnv)##		for(i_sim in runIDs_todo) {#			i_site <- it_site(i_sim)##			assign(x="runs.completed", value=0, envir=exeEnv)#			assign(x="i_sim",value=i_sim,envir=exeEnv)#			assign(x="i_labels",value=labels[i_site],envir=exeEnv)#			assign(x="i_SWRunInformation",value=SWRunInformation[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_soillayers",value=sw_input_soillayers[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_treatments",value=sw_input_treatments[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_cloud",value=sw_input_cloud[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_prod",value=sw_input_prod[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_site",value=sw_input_site[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_soils",value=sw_input_soils[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_weather",value=sw_input_weather[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_climscen",value=sw_input_climscen[i_site, ],envir=exeEnv)#			assign(x="i_sw_input_climscen_values",value=sw_input_climscen_values[i_site, ],envir=exeEnv)##			save(list=ls(exeEnv),file="test.Rdata", envir=exeEnv)#			rm(list=ls(all=TRUE))#			load("test.Rdata")##			do_OneSite(i_sim=i_sim, i_labels=i_labels, i_SWRunInformation=i_SWRunInformation, i_sw_input_soillayers=i_sw_input_soillayers,#							i_sw_input_treatments=i_sw_input_treatments, i_sw_input_cloud=i_sw_input_cloud, i_sw_input_prod=i_sw_input_prod, i_sw_input_site=i_sw_input_site, i_sw_input_soils=i_sw_input_soils,#							i_sw_input_weather=i_sw_input_weather, i_sw_input_climscen=i_sw_input_climscen, i_sw_input_climscen_values=i_sw_input_climscen_values)#			runs.completed <- runs.completed + do_OneSite(i_sim=i_sim, i_labels=labels[i_site], i_SWRunInformation=SWRunInformation[i_site, ], i_sw_input_soillayers=sw_input_soillayers[i_site, ], i_sw_input_treatments=sw_input_treatments[i_site, ], i_sw_input_cloud=sw_input_cloud[i_site, ], i_sw_input_prod=sw_input_prod[i_site, ], i_sw_input_site=sw_input_site[i_site, ], i_sw_input_soils=sw_input_soils[i_site, ], i_sw_input_weather=sw_input_weather[i_site, ], i_sw_input_climscen=sw_input_climscen[i_site, ], i_sw_input_climscen_values=sw_input_climscen_values[i_site, ])#		}	}	#save(inputDataToSave,file=file.path(dir.out,paste("swInputData_",head(runIDs_todo,n=1),"_",head(runIDs_todo,n=1)+runs.completed,".R",sep="")),compress=TRUE)	if(!be.quiet) print(paste("SWSF simulation runs: completed with", runs.completed, "runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))} else {	runs.completed <- 0}#------------------------#------------------------if (any(actions == "concatenate")) {	t1 <- Sys.time()	if(!be.quiet) print(paste("Inserting Data from Temp SQL files into Database", ": started at", t1))	temp <- as.double(difftime(t1, t.overall, units = "secs"))		if (temp <= (MinTimeConcat - 36000) || !parallel_runs || !identical(parallel_backend, "mpi")) {#need at least 10 hours for anything useful		#Connect to the Database		con <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)				do_DBCurrent <- copyCurrentConditionsFromTempSQL || copyCurrentConditionsFromDatabase		reset_DBCurrent <- copyCurrentConditionsFromTempSQL && (cleanDB || !file.exists(name.OutputDBCurrent))		if (reset_DBCurrent) file.copy(from = name.OutputDB, to = name.OutputDBCurrent)				if (do_DBCurrent) con2 <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDBCurrent)		if (reset_DBCurrent) dbGetQuery(con2, "DELETE FROM runs WHERE scenario_id != 1;") # DROP ALL ROWS THAT ARE NOT CURRENT FROM HEADER		out_tables <- DBI::dbListTables(con)		out_tables_aggr <- grep("aggregation_", out_tables, value = TRUE)				# Prepare output databases		set_PRAGMAs(con, PRAGMA_settings1)		if (do_DBCurrent) set_PRAGMAs(con2, PRAGMA_settings1)		# Locate temporary SQL files		theFileList <- list.files(path = dir.out.temp, pattern = "SQL",			full.names = FALSE, recursive = TRUE, include.dirs = FALSE, ignore.case = FALSE)		completedFiles <- if (file.exists(file.path(dir.out.temp,concatFile))) {				basename(readLines(file.path(dir.out.temp, concatFile)))			} else {				character(0)			}		if (any(theFileList %in% completedFiles)) {			theFileList <- theFileList[-which(theFileList %in% completedFiles)]#remove any already inserted files from list		}				# Add data to SQL databases		for	(j in seq_along(theFileList)) {			tDB1 <- Sys.time()			if (print.debug) {				print(paste(j,": started at ", tDB1, sep = ""))			}			tDB <- as.double(difftime(tDB1, t.overall, units = "secs"))			if (tDB > (MaxRunDurationTime - MaxConcatTime) && parallel_runs && identical(parallel_backend, "mpi")) {#figure need at least 8 minutes for big ones  ( not run in parallel				break			}						OK <- TRUE			# Read SQL statements from temporary file			sql_cmds <- readLines(file.path(dir.out.temp, theFileList[j]))			add_to_DBCurrent <- copyCurrentConditionsFromTempSQL && grepl("SQL_Current", theFileList[j])						# Check what has already been inserted to the tables# NOTE(drs): assuming that every table has the same set of P_id inserted!			pids_inserted <- DBI::dbGetQuery(con, paste0("SELECT P_id FROM ", out_tables_aggr[1], ";"))[, 1]			if (add_to_DBCurrent)				pids2_inserted <- DBI::dbGetQuery(con2, paste0("SELECT P_id FROM ", out_tables_aggr[1], ";"))[, 1]						# Send SQL statements to database			OK <- OK && DBI::dbBegin(con)			if (add_to_DBCurrent) OK <- OK && DBI::dbBegin(con2)# NOTE(drs): 'concatenation' may be much faster if temporary text files are not constructed# around SQL insert statements, but instead as data.frames. Data.frames could be much faster# checked for duplicate P_id entries and could be inserted all at once with RSQLite::dbWriteTable()			for (k in seq_along(sql_cmds)) {				# Determine P_id				id_start <- as.integer(regexpr(" VALUES (", sql_cmds[k], fixed = TRUE))				id_end <- as.integer(regexpr(",", sql_cmds[k], fixed = TRUE))				if (id_end < 0)					id_end <- as.integer(regexpr(")", sql_cmds[k], fixed = TRUE))								if (any(id_start < 1, id_end <= id_start)) {					print(paste0("P_id not found in file ", sQuote(theFileList[j]), " on line ", k, ": ", substr(sql_cmds[k], 1, 100)))					next()				}								id <- as.integer(substr(sql_cmds[k], 9 + id_start, -1 + id_end))				# NOTE(drs): assuming duplicate pids do not show up in the same temporary file				do_insert <- !(id %in% pids_inserted)				do_insert2 <- if (add_to_DBCurrent) !(id %in% pids2_inserted) else FALSE												if (do_insert) {					res <- try(DBI::dbSendQuery(con, sql_cmds[k]))					OK <- OK && !inherits(res, "try-error")				}				if (do_insert2) {					res <- try(DBI::dbSendQuery(con2, sql_cmds[k]))					OK <- OK && !inherits(res, "try-error")				}									if (!OK) break			}						if (OK) {				OK <- OK && DBI::dbCommit(con)				if (add_to_DBCurrent) OK <- OK && DBI::dbCommit(con2)			} else {				DBI::dbRollback(con)				if (add_to_DBCurrent) DBI::dbRollback(con2)			}						# Clean up and report			if (OK) {				write(file.path(dir.out.temp, theFileList[j]), file = file.path(dir.out.temp,concatFile), append = TRUE)				if (deleteTmpSQLFiles)					try(file.remove(file.path(dir.out.temp, theFileList[j])), silent = TRUE)			}			if (print.debug) {				tDB <- round(difftime(Sys.time(), tDB1, units = "secs"), 2)				print(paste("    ended at", Sys.time(), "after", tDB, "s"))			}		}		if (!be.quiet) print(paste("Database complete in :",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))		if(copyCurrentConditionsFromDatabase & !copyCurrentConditionsFromTempSQL) {			if(!be.quiet) print(paste("Database is copied and subset to ambient condition: start at ",  Sys.time()))			#Get sql for tables and index			resSQL<-dbSendQuery(con, "SELECT sql FROM sqlite_master WHERE type='table' ORDER BY name;")			sqlTables <- fetch(resSQL,n=-1)			sqlTables <- unlist(sqlTables)			sqlTables <- sqlTables[-grep(pattern="sqlite_sequence",sqlTables)]			dbClearResult(resSQL)			resIndex<-dbSendQuery(con, "SELECT sql FROM sqlite_master WHERE type='view' ORDER BY name;")			sqlView <- fetch(resIndex,n=-1)			dbClearResult(resIndex)			sqlView<-unlist(sqlView)			sqlView <- sqlView[!is.na(sqlView)]			Tables <- dbListTables(con)			Tables <- Tables[-grep(pattern="sqlite_sequence",Tables)]			con <- DBI::dbConnect(RSQLite::SQLite(), name.OutputDBCurrent)			for(i in 1:length(sqlTables)) {#Create the tables				res<-dbSendQuery(con, sqlTables[i])				dbClearResult(res)			}			dbGetQuery(con, sqlView)			con <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)			#Get Tables minus ones we do not want			Tables <- dbListTables(con)			Tables <- Tables[-grep(pattern="sqlite_sequence",Tables)]			Tables <- Tables[-(which(Tables %in% headerTables))]			writeLines(text=paste(".mode insert ", Tables, "\n.out ", Tables,".sql\nSELECT * FROM ",Tables," WHERE P_id IN (SELECT P_id FROM runs WHERE scenario_id = 1 ORDER BY P_id);",sep=""),con="dump.txt")			lines <- c("PRAGMA cache_size = 400000;","PRAGMA synchronous = 1;","PRAGMA locking_mode = EXCLUSIVE;","PRAGMA temp_store = MEMORY;","PRAGMA auto_vacuum = NONE;")			writeLines(text=c(lines,paste(".read ",Tables,".sql",sep="")),con="insert.txt")			system(paste("cat dump.txt | sqlite3 ", shQuote(name.OutputDB)))			system(paste("cat insert.txt | sqlite3 ", shQuote(name.OutputDBCurrent)))			unlink(paste(Tables,".sql",sep=""))			Tables <- dbListTables(con)			Tables <- Tables[-grep(pattern="sqlite_sequence",Tables)]			Tables <- Tables[(which(Tables %in% headerTables[-1]))]			writeLines(text=paste(".mode insert ", Tables, "\n.out ", Tables,".sql\nSELECT * FROM ",Tables,";",sep=""),con="dump.txt")			lines <- c("PRAGMA cache_size = 400000;","PRAGMA synchronous = 1;","PRAGMA locking_mode = EXCLUSIVE;","PRAGMA temp_store = MEMORY;","PRAGMA auto_vacuum = NONE;")			writeLines(text=c(lines,paste(".read ",Tables,".sql",sep="")),con="insert.txt")			system(paste("cat dump.txt | sqlite3 ", shQuote(name.OutputDB)))			system(paste("cat insert.txt | sqlite3 ", shQuote(name.OutputDBCurrent)))			unlink(paste(Tables,".sql",sep=""))			unlink(c("dump.txt","insert.txt"))		}				DBI::dbDisconnect(con)		if (do_DBCurrent) DBI::dbDisconnect(con2)	} else {		print(paste("Need more than ", MinTimeConcat," seconds to put SQL in Database.",sep=""))	}}#--------------------------------------------------------------------------------------------------##------------------------CHECK COMPLETENESS OF OUTPUT FILES AND SIMULATIONSt.check <- Sys.time()if(checkCompleteness){	if(!be.quiet) print(paste("SWSF checks simulations and output: started at", t.check))	headerTables <- c("runs","sqlite_sequence","header","run_labels","scenario_labels","sites","experimental_labels","treatments","simulation_years","weatherfolders")	checkForMissing <- function(Table, database){		con <- DBI::dbConnect(RSQLite::SQLite(), dbname = database)		sql <- paste("SELECT runs.P_id FROM runs LEFT JOIN ",Table," ON (runs.P_id=",Table,".P_id) WHERE ",Table,".P_id is NULL ORDER BY runs.P_id",sep="")		mP_ids <- dbGetQuery(con, sql)$P_id		if(length(mP_ids) > 0)			save(mP_ids,file=paste(database,"_",Table,"_missing_P_ids.RData"))		return(length(mP_ids))	}	library(RSQLite,quietly = TRUE)	con <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)	Tables <- dbListTables(con) #get a list of tables	Tables <- Tables[-which(Tables %in% headerTables)]	if(parallel_runs && parallel_init){		#call the simulations depending on parallel backend		if(identical(parallel_backend, "mpi")) {			workersN <- (mpi.comm.size() - 1)			mpi.bcast.cmd(library(RSQLite,quietly = TRUE))			numberMissing <- mpi.applyLB(x=Tables, fun=checkForMissing, database=name.OutputDB)			TotalMissing <- sum(unlist(numberMissing))			print(paste("dbTables.sqlite3 is missing : ",TotalMissing,"",sep=""))			numberMissing <- mpi.applyLB(x=Tables, fun=checkForMissing, database=name.OutputDBCurrent)			TotalMissing <- sum(unlist(numberMissing))			print(paste("dbTables_current.sqlite3 is missing : ",TotalMissing,"",sep=""))		} else if(identical(parallel_backend, "snow")) {			snow::clusterEvalQ(cl, library(RSQLite,quietly = TRUE))			numberMissing <- foreach(i = 1:length(Tables), .combine="+", .inorder=FALSE) %dopar% checkForMissing(Tables[i], database=name.OutputDB)			print(paste("dbTables.sqlite3 is missing : ",numberMissing,"",sep=""))			numberMissing <- foreach(i = 1:length(Tables), .combine="+", .inorder=FALSE) %dopar% checkForMissing(Tables[i], database=name.OutputDBCurrent)			print(paste("dbTables_current.sqlite3 is missing : ",numberMissing,"",sep=""))		}	} else {		numberMissing <- foreach(table=Tables, .combine="+", .inorder=FALSE) %do% {			checkForMissing(table, database=name.OutputDB)		}		print(paste("dbTables.sqlite3 is missing : ",numberMissing,"",sep=""))		numberMissing <- foreach(table=Tables, .combine="+", .inorder=FALSE) %do% {			checkForMissing(table, database=name.OutputDBCurrent)		}		print(paste("dbTables.sqlite3 is missing : ",numberMissing,"",sep=""))	}	all.complete <- complete.aggregations & complete.simulations	#do check here: still need to implement	if(!all.complete) print("Not all simulations or aggregations were successful: please, check logs")} else {	all.complete <- TRUE	#assume all is good}#timing of checkdelta.check <- difftime(Sys.time(), t.check, units="secs")if(!be.quiet & checkCompleteness) print(paste("SWSF checks simulations and output: ended after", round(delta.check, 2), "s"))#--------------------------------------------------------------------------------------------------##------------------------ENSEMBLE GENERATIONt.ensembles <- Sys.time()	#timing of ensemble calculationif(do.ensembles && all.complete && (actionWithSoilWat && runs.completed == runsN_todo || actionWithSWSFOutput && !actionWithSoilWat) ){	if(!be.quiet) print(paste("SWSF calculates ensembles: started at", t.ensembles))	#save(ensembles.maker,ensemble.levels, ensemble.families, file=file.path(dir.out, "ensembleObjects.r"))	calc.ensembles <- function(dat, elevels){ #dat must be three-dimensional object with dims=(runs, outputs, scenarios); runs and/or scenarios can be 1 or larger		doRanks <- function(x){			temp <- sort.int(x, na.last=NA, index.return=TRUE)			return(c(temp$x[elevels], temp$ix[elevels]))		}		res <- NULL		col.names <- colnames(dat)		if(dim(dat)[3] == 1){ #only one scenario; i.e., all levels are identical to the scenario			temp <- array(data=rep(unlist(dat), each=3), dim=c(length(elevels), dim(dat)[1], dim(dat)[2]))			res <- array(data=1, dim=c(2*length(elevels), dim(dat)[1], dim(dat)[2]))			res[1:length(elevels),,] <- temp		} else {			if(dim(dat)[1] > 1){				res <- apply(dat[,,], MARGIN = c(1,2), doRanks)			} else { #only one run=site				res <- apply(dat[,,], MARGIN = 1, doRanks)				res <- array(data=res, dim=c(2*length(elevels), 1, dim(dat)[2]))			}		}		#returned object: array with 3 dims: 1. dim = 1:length(elevels) are the ensembles at the ensemble.levels; the second set of rows are the ranked GCMs; 2. dim = runs/sites; 3. dim = aggregated variables		dimnames(res) <- list(NULL, NULL, col.names)		return(res)	}	collect_EnsembleFromScenarios <- function(Table){		con <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)		#########TIMING#########		TableTimeStop <- Sys.time() - t.overall		units(TableTimeStop) <- "secs"		TableTimeStop <- as.double(TableTimeStop)		print(paste("Table: ",Table,": started at ",TableTime<-Sys.time(),sep=""))		#########FUNCTIONS######		doWrite <- function(dat, headerInfo, elevel, outfile){			#add info to			name <- ensemble.family			if(is.vector(dat)) {				dat <- cbind(headerInfo, t(dat))			} else {				dat <- cbind(headerInfo, dat)			}			dbBegin(conn=conEnsembleDB)			dbGetPreparedQuery(conEnsembleDB, paste("INSERT INTO ",outfile," VALUES (",paste(paste(":",colnames(dat),sep=""),collapse=", "),");",sep=""), bind.data=dat)			dbCommit(conn=conEnsembleDB)			written<-1			#written <- dbWriteTable(conEnsembleDB, name=outfile, dat, row.names=FALSE,append=TRUE)#			if(written)				return(1)			else				return(0)		}		read.scenarios <- function(Table, start, stop, ensemble.family, export.header=TRUE){			#Read first file			columns<-dbListFields(con,Table)[-1]			if(Layers<-any(temp<-grepl(pattern = "Soil_Layer",x=columns))) columns<-columns[-temp]			columns<-paste("\"",columns,"\"", sep="",collapse = ", ")			sqlString <- paste("SELECT '",Table,"'.P_id AS P_id, header.Scenario AS Scenario, ",columns," FROM '", Table, "' INNER JOIN header ON '",Table,"'.P_id=header.P_id WHERE header.P_id BETWEEN ",start," AND ",stop," AND header.Scenario LIKE '%", tolower(ensemble.family), "%'", " ORDER BY P_id;", sep="")			res <- dbSendQuery(con, sqlString)			dataScen.Mean <- fetch(res, n=-1) #dataToQuantilize get the data from the query n=-1 to get all rows			dbClearResult(res)			columnCutoff <- match("Scenario", colnames(dataScen.Mean))			if(export.header) {				sqlString <- paste("SELECT '", Table,"'.P_id AS P_id ",if(Layers) ", Soil_Layer ","FROM '",Table,"',header WHERE '",Table,"'.P_id=header.P_id AND header.P_id BETWEEN ",start," AND ",stop," AND header.Scenario = 'Current' ORDER BY P_id;",sep="")				res <- dbSendQuery(con, sqlString)				headerInfo <- fetch(res, n=-1) #dataToQuantilize get the data from the query n=-1 to get all rows				dbClearResult(res)			}			col.names <- colnames(dataScen.Mean[,-(1:columnCutoff)])			#We have all the scenarios in the family. We need to get unique scenario names and group them by that			data.temp <- lapply(unique(dataScen.Mean$Scenario), function (x) dataScen.Mean[dataScen.Mean$Scenario == x,-(1:columnCutoff)])			data.temp <- array(data=unlist(data.temp), dim=c(nrow(data.temp[[1]]), ncol(data.temp[[1]]), length(data.temp)) )			colnames(data.temp) <- col.names			class(data.temp) <- "numeric"			if(export.header) {				return(list(headerInfo=headerInfo, data.scen=data.temp))			} else {				return(list(data.scen=data.temp))			}		}		if(!(TableTimeStop > (MaxRunDurationTime-1*60)) | !parallel_runs | !identical(parallel_backend,"mpi")) {#figure need at least 3 hours for big ones			tfile <- file.path(dir.out, paste("dbEnsemble_",sub(pattern="_Mean", replacement="", Table, ignore.case=TRUE),".sqlite3",sep=""))			conEnsembleDB <- DBI::dbConnect(RSQLite::SQLite(), dbname=tfile)			nfiles <- 0			#Grab x rows at a time			SQL <- paste("SELECT MAX(P_id) FROM '",Table,"';",sep="")			maxP_id <- as.integer(dbGetQuery(con,SQL))			maxRun_id <- (maxP_id/scenario_No)			for(j in 1:length(ensemble.families)) {				EnsembleTimeStop <- Sys.time() - t.overall				units(EnsembleTimeStop) <- "secs"				EnsembleTimeStop <- as.double(EnsembleTimeStop)				if((EnsembleTimeStop > (MaxRunDurationTime-1*60)) & parallel_runs & identical(parallel_backend,"mpi")) {#figure need at least 4 hours for a ensemble					break				}				print(paste("Table: ",Table,", Ensemble: ",ensemble.families[j]," started at ",EnsembleTime <- Sys.time(),sep=""))				ensemble.family=ensemble.families[j]				EnsembleFamilyLevelTables<-paste(ensemble.family,"_rank_",formatC(ensemble.levels, width=2, flag="0"),"_",c("means","sds",if(save.scenario.ranks) "scenarioranks"),sep="")				LastPid <- integer(length=length(EnsembleFamilyLevelTables))				for(i in 1:length(LastPid)) {					SQL <- paste("SELECT MAX(P_id) FROM '",EnsembleFamilyLevelTables[i],"';",sep="")					LastPid[i] <- as.integer(dbGetQuery(conEnsembleDB,SQL))+(scenario_No-1)#Need to add all the scenarios because last P_id will always be Current				}				if(any(is.na(LastPid))) { #If any of the tables are empty we need to start at the beginning					minRun_id <- 1				} else {					minRun_id <- (min(LastPid)/scenario_No)+1 #This is already done so we add one				}				#########################				for(i in seq(minRun_id,maxRun_id,ensembleCollectSize)) {					start <- (i-1)*scenario_No+1					stop <- (min(i+ensembleCollectSize-1,maxRun_id)-1)*scenario_No+scenario_No					dataScen.Mean <- read.scenarios(Table=Table,start=start,stop=stop, ensemble.family=ensemble.family, export.header=TRUE)					Table <- sub(pattern="Mean", replacement="SD", Table)					dataScen.SD <- read.scenarios(Table=Table,start=start,stop=stop, ensemble.family=ensemble.family, export.header=FALSE)					Table <- sub(pattern="SD", replacement="Mean", Table)					#get ensembles for non-SD file					dataEns.Mean <- calc.ensembles(dat=dataScen.Mean$data.scen, elevels=ensemble.levels)					#Lookup SD values from scenarios based on ranks determined from taking ensembles of the means					if(length(dim(dataEns.Mean[(length(ensemble.levels) + 1):(2*length(ensemble.levels)),,])) == 2) {						lookup <- aperm(dataEns.Mean[(length(ensemble.levels) + 1):(2*length(ensemble.levels)),,], perm=c(2,1))						make <- array(c(lookup, dataScen.SD$data.scen), dim=c(nrow(lookup), length(ensemble.levels) + dim(dataScen.SD$data.scen)[3]))						dataEns.SD <- apply(make, MARGIN=1, FUN=function(lookANDscen) lookANDscen[(length(ensemble.levels)+1):dim(make)[2]][lookANDscen[1:length(ensemble.levels)]])						dimnames(dataEns.SD)[2] <- dimnames(dataScen.SD$data.scen)[2]					} else {						lookup <- aperm(dataEns.Mean[(length(ensemble.levels) + 1):(2*length(ensemble.levels)),,], perm=c(2,3,1))						make <- array(c(lookup, dataScen.SD$data.scen), dim=c(nrow(lookup), ncol(lookup), length(ensemble.levels) + dim(dataScen.SD$data.scen)[3]))						dataEns.SD <- apply(make, MARGIN=c(1,2), FUN=function(lookANDscen) lookANDscen[(length(ensemble.levels)+1):dim(make)[3]][lookANDscen[1:length(ensemble.levels)]])						dimnames(dataEns.SD)[3] <- dimnames(dataScen.SD$data.scen)[2]					}					#write ensemble files					ntemp <- 0					for(k in 1:length(ensemble.levels)){						outputs <- paste(ensemble.family,"_rank_",formatC(ensemble.levels[k], width=2, flag="0"),"_",c("means","sds","scenarioranks"),sep="")						ntemp <- ntemp + doWrite(dat=dataEns.Mean[k,,], headerInfo=dataScen.Mean$headerInfo, elevel=ensemble.levels[k], outfile=paste("'",outputs[1],"'",sep=""))						if(length(dim(dataEns.Mean[(length(ensemble.levels) + 1):(2*length(ensemble.levels)),,])) == 2) {							ntemp <- ntemp + doWrite(dat=dataEns.SD[k,], headerInfo=dataScen.Mean$headerInfo, elevel=ensemble.levels[k], outfile=paste("'",outputs[2],"'",sep=""))						} else {							ntemp <- ntemp + doWrite(dat=dataEns.SD[k,,], headerInfo=dataScen.Mean$headerInfo, elevel=ensemble.levels[k], outfile=paste("'",outputs[2],"'",sep=""))						}						if(save.scenario.ranks) ntemp <- ntemp + doWrite(dat=dataEns.Mean[length(ensemble.levels) + k,,], headerInfo=dataScen.Mean$headerInfo, elevel=ensemble.levels[k], outfile=paste("'",outputs[3],"'",sep=""))					}					if(i == 1) nfiles <- nfiles + ntemp					print(paste("          ",i,":",min(i+ensembleCollectSize-1,maxRun_id)," of ",maxRun_id," done.",sep=""))				}				#########################				temp2<-Sys.time() - EnsembleTime				units(temp2) <- "secs"				temp2 <- as.double(temp2)				print(paste("Table: ", Table, ", Ensemble: ", ensemble.families[j], " ended at ",Sys.time(),", after ", round(temp2)," s.",sep=""))			}		}		temp2<-Sys.time() - TableTime		units(temp2) <- "secs"		temp2 <- as.double(temp2)		print(paste("Table: ", Table, " ended at ",Sys.time(),", after ",round(temp2)," s.",sep=""))		return(nfiles)	}	library(RSQLite,quietly = TRUE)	con <- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)	Tables <- dbListTables(con) #get a list of tables	Tables <- Tables[-which(Tables %in% headerTables)]	Tables <- Tables[-grep(pattern="_sd", Tables, ignore.case = T)]	if(parallel_runs && parallel_init){		#call the simulations depending on parallel backend		list.export <- c("ensembleCollectSize","Tables","save.scenario.ranks","ensemble.levels","calc.ensembles","scenario_No","MaxRunDurationTime", "collect_EnsembleFromScenarios","dir.out","ensemble.families","t.overall","parallel_runs","parallel_backend","name.OutputDB")		if(identical(parallel_backend, "mpi")) {			workersN <- (mpi.comm.size() - 1)			exportObjects(list.export)			mpi.bcast.cmd(library(RSQLite,quietly = TRUE))			ensembles.completed <- mpi.applyLB(x=Tables, fun=collect_EnsembleFromScenarios)			ensembles.completed <- sum(unlist(ensembles.completed))		} else if(identical(parallel_backend, "snow")) {			export_obj_local <- list.export[list.export %in% ls(name=environment())]			export_obj_in_parent <- list.export[list.export %in% ls(name=parent.frame())]			export_obj_in_parent <- export_obj_in_parent[!(export_obj_in_parent %in% export_obj_local)]			export_obj_in_globenv <- list.export[list.export %in% ls(name=.GlobalEnv)]			export_obj_in_globenv <- export_obj_in_globenv[!(export_obj_in_globenv %in% c(export_obj_local, export_obj_in_parent))]			stopifnot(c(export_obj_local, export_obj_in_parent, export_obj_in_globenv) %in% list.export)			if(length(export_obj_local) > 0) snow::clusterExport(cl, export_obj_local, envir=environment())			if(length(export_obj_in_parent) > 0) snow::clusterExport(cl, export_obj_in_parent, envir=parent.frame())			if(length(export_obj_in_globenv) > 0) snow::clusterExport(cl, export_obj_in_globenv, envir=.GlobalEnv)			snow::clusterEvalQ(cl, library(RSQLite,quietly = TRUE))			ensembles.completed <- foreach(i = 1:length(Tables), .combine="+", .inorder=FALSE) %dopar% collect_EnsembleFromScenarios(Tables[i])		}	} else {		ensembles.completed <- foreach(table=Tables, .combine="+", .inorder=FALSE) %do% {			collect_EnsembleFromScenarios(table)		}	}	if(ensembles.completed != (temp <- length(Tables)*ifelse(save.scenario.ranks, 3, 2)*length(ensemble.families)*length(ensemble.levels))) print("SWSF calculates ensembles: something went wrong with ensemble output: ensembles.completed = ", ensembles.completed, " instead of ", temp,".")}#timing of ensemble calculationdelta.ensembles <- difftime(Sys.time(), t.ensembles, units="secs")if(!be.quiet && do.ensembles) print(paste("SWSF calculates ensembles: ended after", round(delta.ensembles, 2), "s"))#--------------------------------------------------------------------------------------------------##------------------------OVERALL TIMINGdelta.overall <- difftime(Sys.time(), t.overall, units="secs")if(!be.quiet) print(paste("SWSF: ended after", round(delta.overall, 2), "s"))write.timer <- function(label, time_sec="", number=""){ write.table(t(c(label, time_sec, number)), file=file.path(dir.out, timerfile2), append=TRUE, sep=",", dec=".", col.names=FALSE, row.names=FALSE) }write.timer("Time_Total", time_sec=delta.overall)write.timer("Time_Check", time_sec=delta.check)write.timer("Time_Ensembles", time_sec=delta.ensembles)if(actionWithSoilWat){	times <- as.numeric(unlist(read.csv(file=file.path(dir.out, timerfile), header=FALSE, colClasses=c("NULL", "numeric"), skip=1)))	write.timer("Time_OneRun_Mean", time_sec=mean(times))	write.timer("Time_OneRun_SD", time_sec=sd(times))	write.timer("Time_OneRun_Median", time_sec=median(times))	write.timer("Time_OneRun_Min", time_sec=min(times))	write.timer("Time_OneRun_Max", time_sec=max(times))}write.timer("N_cores", number=workersN)write.timer("N_Runs", number=runs.completed)write.timer("N_SWruns", number=runs.completed * scenario_No)write.timer("N_EnsembleFiles", number=ifelse(exists("ensembles.completed"), ensembles.completed, 0))if(!be.quiet) print(paste("SWSF: ended with actions =", paste(actions, collapse=", "), "at", Sys.time()))#--------------------------------------------------------------------------------------------------##------------------------CODE CLEANUPoptions(ow)	#sets the warning option to its previous valueif(parallel_runs && parallel_init){	if(identical(parallel_backend, "mpi")) {	#clean up mpi slaves		mpi.close.Rslaves(dellog=FALSE)		mpi.exit()	}	if(identical(parallel_backend, "snow")){		snow::stopCluster(cl)	#clean up snow cluster	}}#rm(list=ls(all=TRUE))	#optional#--------------------------------------------------------------------------------------------------##--------------------------------------------------------------------------------------------------#